{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMnVA8GnNfc8iJoGuwnQVuU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0a53080adafb40e096f15dfcb4e72965": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6c93c3527ded4c19a7c421aa2752cd6d",
              "IPY_MODEL_c7a8469107364013981847fbc1c45a4e",
              "IPY_MODEL_578bf77751a14a1fb4744ea68ce9d88e"
            ],
            "layout": "IPY_MODEL_a1ccbdda1a744f8e924726bbe789efd7"
          }
        },
        "6c93c3527ded4c19a7c421aa2752cd6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70032a6640064389bd9e1828bb2980b3",
            "placeholder": "​",
            "style": "IPY_MODEL_0747a68b95874b849b450164783ac929",
            "value": "modules.json: 100%"
          }
        },
        "c7a8469107364013981847fbc1c45a4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa04494bd697497b9db16c73e38739f1",
            "max": 229,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f384dfff33cb4571acc711af62ce606b",
            "value": 229
          }
        },
        "578bf77751a14a1fb4744ea68ce9d88e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f8107706737429eae5bef982da82cf1",
            "placeholder": "​",
            "style": "IPY_MODEL_5415645a43f84d72b4e6f562e9ba59a9",
            "value": " 229/229 [00:00&lt;00:00, 13.1kB/s]"
          }
        },
        "a1ccbdda1a744f8e924726bbe789efd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70032a6640064389bd9e1828bb2980b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0747a68b95874b849b450164783ac929": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa04494bd697497b9db16c73e38739f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f384dfff33cb4571acc711af62ce606b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8f8107706737429eae5bef982da82cf1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5415645a43f84d72b4e6f562e9ba59a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef3a45e8cd14493680e125aeb244d31d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5795737cebac4c1e86af828e4c581140",
              "IPY_MODEL_cc69a7ee77d84c57b084e8a7b5b75d0a",
              "IPY_MODEL_aea3429770b44c8584b37434b3895e7f"
            ],
            "layout": "IPY_MODEL_f828f6ccacfa457fbc7c14be0b32c9f8"
          }
        },
        "5795737cebac4c1e86af828e4c581140": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5363d55e64e24eff8072f74f6f6b5661",
            "placeholder": "​",
            "style": "IPY_MODEL_ab48aabb18734d37b966c69fa92a4950",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "cc69a7ee77d84c57b084e8a7b5b75d0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_efac13a96d414f68a87637eb04c096d9",
            "max": 122,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5b002ffb16c543b78f770831d26f9482",
            "value": 122
          }
        },
        "aea3429770b44c8584b37434b3895e7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_388b92834d2740269745c5839b2989c0",
            "placeholder": "​",
            "style": "IPY_MODEL_9bd4e78be29b45858b4b416a2f3de22b",
            "value": " 122/122 [00:00&lt;00:00, 6.61kB/s]"
          }
        },
        "f828f6ccacfa457fbc7c14be0b32c9f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5363d55e64e24eff8072f74f6f6b5661": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab48aabb18734d37b966c69fa92a4950": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "efac13a96d414f68a87637eb04c096d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b002ffb16c543b78f770831d26f9482": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "388b92834d2740269745c5839b2989c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9bd4e78be29b45858b4b416a2f3de22b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "07d1561c4c974b69adcfd623591963c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6f9d978a25eb43df8412a7c507acddbb",
              "IPY_MODEL_f0d885f25bee453b95409609a6e772c7",
              "IPY_MODEL_b226db36c9b240bda304dc6bec13a069"
            ],
            "layout": "IPY_MODEL_5bf87f6bd79f4b7aac84d65bb388a3c0"
          }
        },
        "6f9d978a25eb43df8412a7c507acddbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2bdc9e9dc71459f8266b6295bce8dbc",
            "placeholder": "​",
            "style": "IPY_MODEL_db32baf4a0a54ce6b4237af3e2463dd4",
            "value": "README.md: 100%"
          }
        },
        "f0d885f25bee453b95409609a6e772c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ff064b689514d969e91b77976a09b93",
            "max": 3729,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eb931c01214f4dbcb916530a10eb3564",
            "value": 3729
          }
        },
        "b226db36c9b240bda304dc6bec13a069": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1dd31a8a085e4740b62ef123f66a136b",
            "placeholder": "​",
            "style": "IPY_MODEL_1703944e30f54b3491f383b6984c1689",
            "value": " 3.73k/3.73k [00:00&lt;00:00, 248kB/s]"
          }
        },
        "5bf87f6bd79f4b7aac84d65bb388a3c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2bdc9e9dc71459f8266b6295bce8dbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db32baf4a0a54ce6b4237af3e2463dd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ff064b689514d969e91b77976a09b93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb931c01214f4dbcb916530a10eb3564": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1dd31a8a085e4740b62ef123f66a136b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1703944e30f54b3491f383b6984c1689": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab1595cc518146029550283e5e151f78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_66bd48a620dc45c4b0090e65427565d9",
              "IPY_MODEL_5f6b9428e44445e9a1011c85ba610fce",
              "IPY_MODEL_2a6127046c184060b0ff76fa24db249c"
            ],
            "layout": "IPY_MODEL_1de270fef7eb4f5591d6863e171b17cd"
          }
        },
        "66bd48a620dc45c4b0090e65427565d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_008d49e9c1514aed9452614438907a44",
            "placeholder": "​",
            "style": "IPY_MODEL_55d4690c738e47b991488ba0682a2011",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "5f6b9428e44445e9a1011c85ba610fce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_802ed72a97fe4d7aba255dc6d9cea415",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7a9effa8422a4fa981faad6d49489757",
            "value": 53
          }
        },
        "2a6127046c184060b0ff76fa24db249c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_886c48291f6340629d7589ff9a638b2d",
            "placeholder": "​",
            "style": "IPY_MODEL_033d236ac2074b2d8f3e9a4a27bba168",
            "value": " 53.0/53.0 [00:00&lt;00:00, 3.03kB/s]"
          }
        },
        "1de270fef7eb4f5591d6863e171b17cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "008d49e9c1514aed9452614438907a44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55d4690c738e47b991488ba0682a2011": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "802ed72a97fe4d7aba255dc6d9cea415": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a9effa8422a4fa981faad6d49489757": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "886c48291f6340629d7589ff9a638b2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "033d236ac2074b2d8f3e9a4a27bba168": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52fdb70c469a4e75a2f0779814823eae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b09dbdbd0f934050a5d9656a4e817939",
              "IPY_MODEL_f4be871938fe445bab2a5b2d187f3fad",
              "IPY_MODEL_ecac7f33bf634180a6a1d9ae89f16c0f"
            ],
            "layout": "IPY_MODEL_35e61c54e0e74e8e9d5346b68b4caec2"
          }
        },
        "b09dbdbd0f934050a5d9656a4e817939": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac09b4692dd346c59fb9dec3de49d2a7",
            "placeholder": "​",
            "style": "IPY_MODEL_172db38fed4a4cd2b794282cf3088a8f",
            "value": "config.json: 100%"
          }
        },
        "f4be871938fe445bab2a5b2d187f3fad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a67edf5788b4abfa423a8f78ed19f65",
            "max": 629,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1e048ef7daa1408686d577898de3e008",
            "value": 629
          }
        },
        "ecac7f33bf634180a6a1d9ae89f16c0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d7ad562613b476e838a19a1630ef4c4",
            "placeholder": "​",
            "style": "IPY_MODEL_487c2e7a7b6c44d0a739cf4513682418",
            "value": " 629/629 [00:00&lt;00:00, 36.6kB/s]"
          }
        },
        "35e61c54e0e74e8e9d5346b68b4caec2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac09b4692dd346c59fb9dec3de49d2a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "172db38fed4a4cd2b794282cf3088a8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a67edf5788b4abfa423a8f78ed19f65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e048ef7daa1408686d577898de3e008": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7d7ad562613b476e838a19a1630ef4c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "487c2e7a7b6c44d0a739cf4513682418": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4abad5ccbc5347d5b53d1dc8ee96039a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_801070a804ef47bb93cf92c8e1ca36d5",
              "IPY_MODEL_a969b2f8bc66401e86b9db274a4e2a96",
              "IPY_MODEL_1e26687114764f21935809f5c4f15d56"
            ],
            "layout": "IPY_MODEL_da1c1ecbdb3b4e08b4bf99eb458bded9"
          }
        },
        "801070a804ef47bb93cf92c8e1ca36d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84a6fb24005041dc838b357b0c798db5",
            "placeholder": "​",
            "style": "IPY_MODEL_60fbfc7b07104859b3e0290661c5662c",
            "value": "model.safetensors: 100%"
          }
        },
        "a969b2f8bc66401e86b9db274a4e2a96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe1e50a7d3a943a2afe10a1109052df6",
            "max": 90868373,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c26975467a124fe983fbf1523c3fcbed",
            "value": 90868373
          }
        },
        "1e26687114764f21935809f5c4f15d56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2205d90cdcfc408a9395813d92e044e2",
            "placeholder": "​",
            "style": "IPY_MODEL_bc94b45b78de47fbacf2152dce31b1fa",
            "value": " 90.9M/90.9M [00:01&lt;00:00, 109MB/s]"
          }
        },
        "da1c1ecbdb3b4e08b4bf99eb458bded9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84a6fb24005041dc838b357b0c798db5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60fbfc7b07104859b3e0290661c5662c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe1e50a7d3a943a2afe10a1109052df6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c26975467a124fe983fbf1523c3fcbed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2205d90cdcfc408a9395813d92e044e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc94b45b78de47fbacf2152dce31b1fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8097f60ebfa14cb1833837e6a6b81da7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1cb46e1f4c0a46a8bec1f1fb1e2730de",
              "IPY_MODEL_fd2d88c2ba2341e8925bba9e4e13b9b0",
              "IPY_MODEL_70d55d4ee3e841dabbbc870251a0e8df"
            ],
            "layout": "IPY_MODEL_7621e81f102442c397ad5fc7a1ba9e7c"
          }
        },
        "1cb46e1f4c0a46a8bec1f1fb1e2730de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_031f9952e9b74b9a93b127ab0cc6f81a",
            "placeholder": "​",
            "style": "IPY_MODEL_335c022826f5451b98c31e3d7f053028",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "fd2d88c2ba2341e8925bba9e4e13b9b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca0b1bde07ab40698735ebc4d53590f8",
            "max": 314,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3358434cf86e4a768aee79a2c2177cb3",
            "value": 314
          }
        },
        "70d55d4ee3e841dabbbc870251a0e8df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7bec8b0d9f52474b87624d54762e3d27",
            "placeholder": "​",
            "style": "IPY_MODEL_2872d0056b2141d68b9d0c2db6fee1c3",
            "value": " 314/314 [00:00&lt;00:00, 19.4kB/s]"
          }
        },
        "7621e81f102442c397ad5fc7a1ba9e7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "031f9952e9b74b9a93b127ab0cc6f81a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "335c022826f5451b98c31e3d7f053028": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca0b1bde07ab40698735ebc4d53590f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3358434cf86e4a768aee79a2c2177cb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7bec8b0d9f52474b87624d54762e3d27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2872d0056b2141d68b9d0c2db6fee1c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eca77c0937834bfe8536044722b9ce21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_df6d076956db4c8db0da6a5581c28238",
              "IPY_MODEL_f21c7bfa481c4bcbab263eb89266dd85",
              "IPY_MODEL_ad0677f3b797409e88a6a7d114471b91"
            ],
            "layout": "IPY_MODEL_3baa5e4e404b433faf3cc17dfd60a090"
          }
        },
        "df6d076956db4c8db0da6a5581c28238": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d3082b8e1634d63980fbed874a9d43a",
            "placeholder": "​",
            "style": "IPY_MODEL_611d534cb53e4a2f88dd342aaf2f4412",
            "value": "vocab.txt: 100%"
          }
        },
        "f21c7bfa481c4bcbab263eb89266dd85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d477a776cbe4a2b8ee291643c8ae90c",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4e44c2c9d26d4e59a70ffa60f2839be4",
            "value": 231508
          }
        },
        "ad0677f3b797409e88a6a7d114471b91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74d7c4121e3b47ed85c4cd8eb9599a63",
            "placeholder": "​",
            "style": "IPY_MODEL_3393ce693ba645ad939cac1fc734d79b",
            "value": " 232k/232k [00:00&lt;00:00, 3.72MB/s]"
          }
        },
        "3baa5e4e404b433faf3cc17dfd60a090": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d3082b8e1634d63980fbed874a9d43a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "611d534cb53e4a2f88dd342aaf2f4412": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d477a776cbe4a2b8ee291643c8ae90c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e44c2c9d26d4e59a70ffa60f2839be4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "74d7c4121e3b47ed85c4cd8eb9599a63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3393ce693ba645ad939cac1fc734d79b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "81b3ff055e9f416790044c9595d85ee6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_988fd30e73a842b1a977968222b1bb54",
              "IPY_MODEL_5e63ba1fbd64449cbd853f7ab68d3e10",
              "IPY_MODEL_9acb39ea3cd24e3eb2f0b3fbd64eaed0"
            ],
            "layout": "IPY_MODEL_8b0be5a3bf5d4b669100dd2127cb9cab"
          }
        },
        "988fd30e73a842b1a977968222b1bb54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb736581f55f4fb0b945b3e3bc668255",
            "placeholder": "​",
            "style": "IPY_MODEL_35e85ea89bc545c3a80738e15f1fdaf5",
            "value": "tokenizer.json: 100%"
          }
        },
        "5e63ba1fbd64449cbd853f7ab68d3e10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca67cda5f683499382cca286310c7899",
            "max": 466081,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_03887e01dbca45fcbe4a26c54e40dfdd",
            "value": 466081
          }
        },
        "9acb39ea3cd24e3eb2f0b3fbd64eaed0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0295f63673764813a7df801f76b741d7",
            "placeholder": "​",
            "style": "IPY_MODEL_be2e61f67a674881ab114463513bde58",
            "value": " 466k/466k [00:00&lt;00:00, 17.7MB/s]"
          }
        },
        "8b0be5a3bf5d4b669100dd2127cb9cab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb736581f55f4fb0b945b3e3bc668255": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35e85ea89bc545c3a80738e15f1fdaf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca67cda5f683499382cca286310c7899": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03887e01dbca45fcbe4a26c54e40dfdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0295f63673764813a7df801f76b741d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be2e61f67a674881ab114463513bde58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f53d045176541e09f65838e5c84119e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_31c209b381c546f3921566d261f8fb6c",
              "IPY_MODEL_efb691f1095e44c3b4bd055f4aed91fc",
              "IPY_MODEL_4de87d03e1684164b1e5dce98f17c7c8"
            ],
            "layout": "IPY_MODEL_ccde96836c5b49f9b6aae2699d1be3c9"
          }
        },
        "31c209b381c546f3921566d261f8fb6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f4204fe678d458da49064d5dd89532e",
            "placeholder": "​",
            "style": "IPY_MODEL_39a68a920a1a4748880e921a3d23b547",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "efb691f1095e44c3b4bd055f4aed91fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef02710ffeb64d3192ff3e0e81382f59",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eda4dbe02a6746afa48885c741a443f3",
            "value": 112
          }
        },
        "4de87d03e1684164b1e5dce98f17c7c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9b1056d4f7d42ae9afb3c9009509381",
            "placeholder": "​",
            "style": "IPY_MODEL_23a5bdfc329944f291b11a4a566aeb7b",
            "value": " 112/112 [00:00&lt;00:00, 5.60kB/s]"
          }
        },
        "ccde96836c5b49f9b6aae2699d1be3c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f4204fe678d458da49064d5dd89532e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39a68a920a1a4748880e921a3d23b547": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef02710ffeb64d3192ff3e0e81382f59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eda4dbe02a6746afa48885c741a443f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c9b1056d4f7d42ae9afb3c9009509381": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23a5bdfc329944f291b11a4a566aeb7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "284fa81ee2ba4885849b6f5ee7ad09f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_265bd46f454a4800ba3b3984f4c2f23b",
              "IPY_MODEL_11828800674f400aa866124da51d74a8",
              "IPY_MODEL_04139f9ecd5c4111b1a90aa7fca3d861"
            ],
            "layout": "IPY_MODEL_b78648e18b9147de92752312ed07c9e2"
          }
        },
        "265bd46f454a4800ba3b3984f4c2f23b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5031a37c9cd7481e8c31a224016113c1",
            "placeholder": "​",
            "style": "IPY_MODEL_98e06a5fc94648a9afa6d3c8e01c4e62",
            "value": "1_Pooling/config.json: 100%"
          }
        },
        "11828800674f400aa866124da51d74a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5528794f9a9343d5bb7e61aff3c5cc48",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_32e6b7db0c2a42eb83492442e2fe981f",
            "value": 190
          }
        },
        "04139f9ecd5c4111b1a90aa7fca3d861": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c386d11ffe234b0c8b5b4bfe1ea938a4",
            "placeholder": "​",
            "style": "IPY_MODEL_16ef863945fb407d893c177306b30886",
            "value": " 190/190 [00:00&lt;00:00, 12.1kB/s]"
          }
        },
        "b78648e18b9147de92752312ed07c9e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5031a37c9cd7481e8c31a224016113c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98e06a5fc94648a9afa6d3c8e01c4e62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5528794f9a9343d5bb7e61aff3c5cc48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32e6b7db0c2a42eb83492442e2fe981f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c386d11ffe234b0c8b5b4bfe1ea938a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16ef863945fb407d893c177306b30886": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CodeHunterOfficial/NLP-2024-2025/blob/main/Lecture_3_2_%D0%9F%D0%BE%D0%B8%D1%81%D0%BA_%D1%81%D0%BC%D1%8B%D1%81%D0%BB%D0%B0_%D1%81%D0%BB%D0%BE%D0%B2_%D0%BF%D0%BE_%D0%B8%D1%85_%D1%87%D0%B0%D1%81%D1%82%D0%BE%D1%82%D0%BD%D0%BE%D1%81%D1%82%D1%8F%D0%BC_%D1%81%D0%B5%D0%BC%D0%B0%D0%BD%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D0%B9_%D0%B0%D0%BD%D0%B0%D0%BB%D0%B8%D0%B7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Поиск смысла слов по их частотностям: семантический анализ\n",
        "\n",
        "Введение в семантический анализ и векторное представление слов является основой для разработки современных систем обработки естественного языка (NLP). Эта лекция охватывает несколько ключевых аспектов семантического анализа, включая создание векторов тем, семантический поиск, масштабируемый анализ для больших корпусов текстов и использование семантических компонентов в NLP. Особое внимание будет уделено ориентации в векторных пространствах высокой размерности.\n",
        "\n",
        "#### 1. Создание векторов тем с помощью анализа семантики (смысла)\n",
        "\n",
        "**1.1 Основы семантического анализа**\n",
        "\n",
        "Семантический анализ направлен на выявление смысла слов и предложений путем изучения их контекста. Одним из основных методов является векторное представление слов, также известное как word embeddings. Такие методы, как Word2Vec, GloVe и FastText, используют статистические модели для представления слов в виде векторов в высокоразмерном пространстве, где семантически схожие слова располагаются ближе друг к другу.\n",
        "\n",
        "**1.2 Модели для создания векторов тем**\n",
        "\n",
        "1. **Word2Vec**: Использует модели CBOW и Skip-Gram для обучения векторных представлений слов на больших корпусах текста. CBOW предсказывает слово по контексту, а Skip-Gram делает обратное.\n",
        "2. **GloVe (Global Vectors for Word Representation)**: Основан на матрицах соотношений слов и глобальной статистике корпуса.\n",
        "3. **FastText**: Улучшение Word2Vec, учитывающее морфологическую структуру слов за счет использования субслов.\n",
        "\n"
      ],
      "metadata": {
        "id": "dQkpEoM1-l-X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Рассмотрим каждую модели\n",
        "\n",
        "Word2Vec — алгоритм, предлагающий два основных подхода: CBOW (Continuous Bag of Words) и Skip-Gram. Мы рассмотрим оба подхода с соответствующими формулами и примерами.\n",
        "\n",
        "**1.1 CBOW (Continuous Bag of Words)**\n",
        "\n",
        "CBOW предсказывает текущее слово по его контексту.\n",
        "\n",
        "**Целевая функция**:\n",
        "$$ J(\\theta) = \\frac{1}{T} \\sum_{t=1}^{T} \\log P(w_t | w_{t-i}, \\ldots, w_{t+i}) $$\n",
        "\n",
        "**Вероятность**:\n",
        "$$ P(w_t | w_{t-i}, \\ldots, w_{t+i}) = \\frac{\\exp(v_{w_t} \\cdot h)}{\\sum_{w' \\in V} \\exp(v_{w'} \\cdot h)} $$\n",
        "\n",
        "где $ h $ — средний вектор контекстных слов:\n",
        "$$ h = \\frac{1}{2i} \\sum_{j=-i, j \\neq 0}^{i} v_{w_{t+j}} $$\n",
        "\n",
        "**Пример**:\n",
        "Для предложения \"I love natural language processing\", если текущее слово —\n",
        "\n",
        "**Пример предложения**: \"I love natural language processing\".\n",
        "\n",
        "**Контекстное окно**: 2 (по 2 слова слева и справа от целевого слова).\n",
        "\n",
        "**Целевое слово**: \"language\".\n",
        "\n",
        "**Контекстные слова**: [\"I\", \"love\", \"natural\", \"processing\"].\n",
        "\n",
        "**Целевая функция**:\n",
        "$$ J(\\theta) = \\frac{1}{T} \\sum_{t=1}^{T} \\log P(w_t | w_{t-i}, \\ldots, w_{t+i}) $$\n",
        "\n",
        "Для нашего примера:\n",
        "\n",
        "$$ J(\\theta) = \\log P(language | I, love, natural, processing) $$\n",
        "\n",
        "**Вероятность**:\n",
        "$$ P(w_t | w_{t-i}, \\ldots, w_{t+i}) = \\frac{\\exp(v_{w_t} \\cdot h)}{\\sum_{w' \\in V} \\exp(v_{w'} \\cdot h)} $$\n",
        "\n",
        "где $ h $ — средний вектор контекстных слов:\n",
        "\n",
        "$$h = \\frac{1}{4} (v_{I} + v_{love} + v_{natural} + v_{processing}) $$\n",
        "\n",
        "**Шаг 1: Вычисление среднего вектора контекста**\n",
        "\n",
        "Пусть векторы слов имеют размерность 3 для простоты. Допустим, что векторы слов такие:\n",
        "\n",
        "- $ v_{I} = [0.2, 0.1, -0.1] $\n",
        "- $ v_{love} = [0.4, 0.3, 0.2] $\n",
        "- $ v_{natural} = [0.3, 0.4, 0.5] $\n",
        "- $ v_{processing} = [0.5, 0.6, 0.7] $\n",
        "\n",
        "Тогда средний вектор контекста:\n",
        "\n",
        "$$ h = \\frac{1}{4} ([0.2, 0.1, -0.1] + [0.4, 0.3, 0.2] + [0.3, 0.4, 0.5] + [0.5, 0.6, 0.7]) $$\n",
        "$$ h = \\frac{1}{4} ([1.4, 1.4, 1.3]) $$\n",
        "$$ h = [0.35, 0.35, 0.325] $$\n",
        "\n",
        "**Шаг 2: Вычисление вероятности целевого слова**\n",
        "\n",
        "Пусть вектор целевого слова $ v_{language} = [0.6, 0.7, 0.8] $.\n",
        "\n",
        "Скалярное произведение:\n",
        "\n",
        "$$ v_{language} \\cdot h = [0.6, 0.7, 0.8] \\cdot [0.35, 0.35, 0.325] $$\n",
        "$$ v_{language} \\cdot h = 0.6 \\cdot 0.35 + 0.7 \\cdot 0.35 + 0.8 \\cdot 0.325 $$\n",
        "$$ v_{language} \\cdot h = 0.21 + 0.245 + 0.26 $$\n",
        "$$ v_{language} \\cdot h = 0.715 $$\n",
        "\n",
        "Теперь вероятность:\n",
        "\n",
        "$$ P(language | I, love, natural, processing) = \\frac{\\exp(0.715)}{\\sum_{w' \\in V} \\exp(v_{w'} \\cdot h)} $$\n",
        "\n",
        "Для простоты предположим, что сумма экспонент для всех слов в словаре равна $ Z $:\n",
        "\n",
        "$$ P(language | I, love, natural, processing) = \\frac{\\exp(0.715)}{Z} $$\n",
        "\n",
        "Целевая функция:\n",
        "\n",
        "$$ J(\\theta) = \\log P(language | I, love, natural, processing) = 0.715 - \\log Z $$\n",
        "\n"
      ],
      "metadata": {
        "id": "C0Wby_jICpwl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Пример предложения\n",
        "sentences = [\"I love natural language processing\"]\n",
        "\n",
        "# Параметры модели\n",
        "window_size = 2\n",
        "embedding_dim = 3\n",
        "epochs = 100\n",
        "\n",
        "# Токенизация и создание словаря\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "word_index = tokenizer.word_index\n",
        "vocab_size = len(word_index) + 1\n",
        "sequences = tokenizer.texts_to_sequences(sentences)\n",
        "\n",
        "# Функция для создания данных для CBOW\n",
        "def generate_cbow_data(sequences, window_size):\n",
        "    data = []\n",
        "    labels = []\n",
        "    for sequence in sequences:\n",
        "        for i, word_id in enumerate(sequence):\n",
        "            context = []\n",
        "            for j in range(-window_size, window_size + 1):\n",
        "                if j != 0 and 0 <= i + j < len(sequence):\n",
        "                    context.append(sequence[i + j])\n",
        "            if len(context) == 2 * window_size:\n",
        "                data.append(context)\n",
        "                labels.append(word_id)\n",
        "    return np.array(data), np.array(labels)\n",
        "\n",
        "# Создание данных для обучения\n",
        "data, labels = generate_cbow_data(sequences, window_size)\n",
        "\n",
        "# Модель CBOW\n",
        "input_layer = tf.keras.layers.Input(shape=(2 * window_size,), name='input')\n",
        "embedding_layer = tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=2 * window_size, name='embedding')(input_layer)\n",
        "context_layer = tf.keras.layers.Lambda(lambda x: tf.reduce_mean(x, axis=1), name='context')(embedding_layer)\n",
        "output_layer = tf.keras.layers.Dense(vocab_size, activation='softmax', name='output')(context_layer)\n",
        "\n",
        "model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
        "model.summary()\n",
        "\n",
        "# Обучение модели\n",
        "model.fit(data, labels, epochs=epochs, verbose=2)\n",
        "\n",
        "# Получение векторов слов\n",
        "word_embeddings = model.get_layer('embedding').get_weights()[0]\n",
        "print(\"Word Embeddings:\", word_embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwMxM-aSEvAm",
        "outputId": "0fc9e7dc-9c96-4000-996e-3db20f0d9ab5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input (InputLayer)          [(None, 4)]               0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 4, 3)              18        \n",
            "                                                                 \n",
            " context (Lambda)            (None, 3)                 0         \n",
            "                                                                 \n",
            " output (Dense)              (None, 6)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 42 (168.00 Byte)\n",
            "Trainable params: 42 (168.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "1/1 - 0s - loss: 1.7819 - 479ms/epoch - 479ms/step\n",
            "Epoch 2/100\n",
            "1/1 - 0s - loss: 1.7793 - 8ms/epoch - 8ms/step\n",
            "Epoch 3/100\n",
            "1/1 - 0s - loss: 1.7767 - 8ms/epoch - 8ms/step\n",
            "Epoch 4/100\n",
            "1/1 - 0s - loss: 1.7741 - 6ms/epoch - 6ms/step\n",
            "Epoch 5/100\n",
            "1/1 - 0s - loss: 1.7715 - 8ms/epoch - 8ms/step\n",
            "Epoch 6/100\n",
            "1/1 - 0s - loss: 1.7689 - 8ms/epoch - 8ms/step\n",
            "Epoch 7/100\n",
            "1/1 - 0s - loss: 1.7663 - 8ms/epoch - 8ms/step\n",
            "Epoch 8/100\n",
            "1/1 - 0s - loss: 1.7637 - 8ms/epoch - 8ms/step\n",
            "Epoch 9/100\n",
            "1/1 - 0s - loss: 1.7610 - 8ms/epoch - 8ms/step\n",
            "Epoch 10/100\n",
            "1/1 - 0s - loss: 1.7584 - 8ms/epoch - 8ms/step\n",
            "Epoch 11/100\n",
            "1/1 - 0s - loss: 1.7558 - 10ms/epoch - 10ms/step\n",
            "Epoch 12/100\n",
            "1/1 - 0s - loss: 1.7531 - 7ms/epoch - 7ms/step\n",
            "Epoch 13/100\n",
            "1/1 - 0s - loss: 1.7504 - 8ms/epoch - 8ms/step\n",
            "Epoch 14/100\n",
            "1/1 - 0s - loss: 1.7477 - 7ms/epoch - 7ms/step\n",
            "Epoch 15/100\n",
            "1/1 - 0s - loss: 1.7451 - 9ms/epoch - 9ms/step\n",
            "Epoch 16/100\n",
            "1/1 - 0s - loss: 1.7424 - 7ms/epoch - 7ms/step\n",
            "Epoch 17/100\n",
            "1/1 - 0s - loss: 1.7396 - 10ms/epoch - 10ms/step\n",
            "Epoch 18/100\n",
            "1/1 - 0s - loss: 1.7369 - 8ms/epoch - 8ms/step\n",
            "Epoch 19/100\n",
            "1/1 - 0s - loss: 1.7342 - 9ms/epoch - 9ms/step\n",
            "Epoch 20/100\n",
            "1/1 - 0s - loss: 1.7315 - 8ms/epoch - 8ms/step\n",
            "Epoch 21/100\n",
            "1/1 - 0s - loss: 1.7287 - 8ms/epoch - 8ms/step\n",
            "Epoch 22/100\n",
            "1/1 - 0s - loss: 1.7259 - 8ms/epoch - 8ms/step\n",
            "Epoch 23/100\n",
            "1/1 - 0s - loss: 1.7231 - 7ms/epoch - 7ms/step\n",
            "Epoch 24/100\n",
            "1/1 - 0s - loss: 1.7204 - 7ms/epoch - 7ms/step\n",
            "Epoch 25/100\n",
            "1/1 - 0s - loss: 1.7175 - 8ms/epoch - 8ms/step\n",
            "Epoch 26/100\n",
            "1/1 - 0s - loss: 1.7147 - 8ms/epoch - 8ms/step\n",
            "Epoch 27/100\n",
            "1/1 - 0s - loss: 1.7119 - 8ms/epoch - 8ms/step\n",
            "Epoch 28/100\n",
            "1/1 - 0s - loss: 1.7091 - 8ms/epoch - 8ms/step\n",
            "Epoch 29/100\n",
            "1/1 - 0s - loss: 1.7062 - 8ms/epoch - 8ms/step\n",
            "Epoch 30/100\n",
            "1/1 - 0s - loss: 1.7033 - 7ms/epoch - 7ms/step\n",
            "Epoch 31/100\n",
            "1/1 - 0s - loss: 1.7004 - 8ms/epoch - 8ms/step\n",
            "Epoch 32/100\n",
            "1/1 - 0s - loss: 1.6975 - 7ms/epoch - 7ms/step\n",
            "Epoch 33/100\n",
            "1/1 - 0s - loss: 1.6946 - 8ms/epoch - 8ms/step\n",
            "Epoch 34/100\n",
            "1/1 - 0s - loss: 1.6917 - 11ms/epoch - 11ms/step\n",
            "Epoch 35/100\n",
            "1/1 - 0s - loss: 1.6888 - 8ms/epoch - 8ms/step\n",
            "Epoch 36/100\n",
            "1/1 - 0s - loss: 1.6858 - 7ms/epoch - 7ms/step\n",
            "Epoch 37/100\n",
            "1/1 - 0s - loss: 1.6828 - 7ms/epoch - 7ms/step\n",
            "Epoch 38/100\n",
            "1/1 - 0s - loss: 1.6799 - 7ms/epoch - 7ms/step\n",
            "Epoch 39/100\n",
            "1/1 - 0s - loss: 1.6769 - 10ms/epoch - 10ms/step\n",
            "Epoch 40/100\n",
            "1/1 - 0s - loss: 1.6738 - 7ms/epoch - 7ms/step\n",
            "Epoch 41/100\n",
            "1/1 - 0s - loss: 1.6708 - 9ms/epoch - 9ms/step\n",
            "Epoch 42/100\n",
            "1/1 - 0s - loss: 1.6678 - 12ms/epoch - 12ms/step\n",
            "Epoch 43/100\n",
            "1/1 - 0s - loss: 1.6647 - 9ms/epoch - 9ms/step\n",
            "Epoch 44/100\n",
            "1/1 - 0s - loss: 1.6616 - 9ms/epoch - 9ms/step\n",
            "Epoch 45/100\n",
            "1/1 - 0s - loss: 1.6585 - 9ms/epoch - 9ms/step\n",
            "Epoch 46/100\n",
            "1/1 - 0s - loss: 1.6554 - 8ms/epoch - 8ms/step\n",
            "Epoch 47/100\n",
            "1/1 - 0s - loss: 1.6523 - 9ms/epoch - 9ms/step\n",
            "Epoch 48/100\n",
            "1/1 - 0s - loss: 1.6492 - 9ms/epoch - 9ms/step\n",
            "Epoch 49/100\n",
            "1/1 - 0s - loss: 1.6460 - 9ms/epoch - 9ms/step\n",
            "Epoch 50/100\n",
            "1/1 - 0s - loss: 1.6429 - 10ms/epoch - 10ms/step\n",
            "Epoch 51/100\n",
            "1/1 - 0s - loss: 1.6397 - 9ms/epoch - 9ms/step\n",
            "Epoch 52/100\n",
            "1/1 - 0s - loss: 1.6365 - 8ms/epoch - 8ms/step\n",
            "Epoch 53/100\n",
            "1/1 - 0s - loss: 1.6333 - 9ms/epoch - 9ms/step\n",
            "Epoch 54/100\n",
            "1/1 - 0s - loss: 1.6300 - 9ms/epoch - 9ms/step\n",
            "Epoch 55/100\n",
            "1/1 - 0s - loss: 1.6268 - 7ms/epoch - 7ms/step\n",
            "Epoch 56/100\n",
            "1/1 - 0s - loss: 1.6235 - 8ms/epoch - 8ms/step\n",
            "Epoch 57/100\n",
            "1/1 - 0s - loss: 1.6202 - 7ms/epoch - 7ms/step\n",
            "Epoch 58/100\n",
            "1/1 - 0s - loss: 1.6169 - 8ms/epoch - 8ms/step\n",
            "Epoch 59/100\n",
            "1/1 - 0s - loss: 1.6136 - 7ms/epoch - 7ms/step\n",
            "Epoch 60/100\n",
            "1/1 - 0s - loss: 1.6103 - 6ms/epoch - 6ms/step\n",
            "Epoch 61/100\n",
            "1/1 - 0s - loss: 1.6070 - 10ms/epoch - 10ms/step\n",
            "Epoch 62/100\n",
            "1/1 - 0s - loss: 1.6036 - 9ms/epoch - 9ms/step\n",
            "Epoch 63/100\n",
            "1/1 - 0s - loss: 1.6002 - 11ms/epoch - 11ms/step\n",
            "Epoch 64/100\n",
            "1/1 - 0s - loss: 1.5968 - 8ms/epoch - 8ms/step\n",
            "Epoch 65/100\n",
            "1/1 - 0s - loss: 1.5934 - 8ms/epoch - 8ms/step\n",
            "Epoch 66/100\n",
            "1/1 - 0s - loss: 1.5900 - 8ms/epoch - 8ms/step\n",
            "Epoch 67/100\n",
            "1/1 - 0s - loss: 1.5866 - 8ms/epoch - 8ms/step\n",
            "Epoch 68/100\n",
            "1/1 - 0s - loss: 1.5831 - 8ms/epoch - 8ms/step\n",
            "Epoch 69/100\n",
            "1/1 - 0s - loss: 1.5796 - 8ms/epoch - 8ms/step\n",
            "Epoch 70/100\n",
            "1/1 - 0s - loss: 1.5761 - 8ms/epoch - 8ms/step\n",
            "Epoch 71/100\n",
            "1/1 - 0s - loss: 1.5726 - 7ms/epoch - 7ms/step\n",
            "Epoch 72/100\n",
            "1/1 - 0s - loss: 1.5691 - 7ms/epoch - 7ms/step\n",
            "Epoch 73/100\n",
            "1/1 - 0s - loss: 1.5656 - 8ms/epoch - 8ms/step\n",
            "Epoch 74/100\n",
            "1/1 - 0s - loss: 1.5620 - 7ms/epoch - 7ms/step\n",
            "Epoch 75/100\n",
            "1/1 - 0s - loss: 1.5585 - 9ms/epoch - 9ms/step\n",
            "Epoch 76/100\n",
            "1/1 - 0s - loss: 1.5549 - 12ms/epoch - 12ms/step\n",
            "Epoch 77/100\n",
            "1/1 - 0s - loss: 1.5513 - 9ms/epoch - 9ms/step\n",
            "Epoch 78/100\n",
            "1/1 - 0s - loss: 1.5477 - 8ms/epoch - 8ms/step\n",
            "Epoch 79/100\n",
            "1/1 - 0s - loss: 1.5440 - 8ms/epoch - 8ms/step\n",
            "Epoch 80/100\n",
            "1/1 - 0s - loss: 1.5404 - 8ms/epoch - 8ms/step\n",
            "Epoch 81/100\n",
            "1/1 - 0s - loss: 1.5367 - 8ms/epoch - 8ms/step\n",
            "Epoch 82/100\n",
            "1/1 - 0s - loss: 1.5331 - 9ms/epoch - 9ms/step\n",
            "Epoch 83/100\n",
            "1/1 - 0s - loss: 1.5294 - 7ms/epoch - 7ms/step\n",
            "Epoch 84/100\n",
            "1/1 - 0s - loss: 1.5257 - 12ms/epoch - 12ms/step\n",
            "Epoch 85/100\n",
            "1/1 - 0s - loss: 1.5219 - 12ms/epoch - 12ms/step\n",
            "Epoch 86/100\n",
            "1/1 - 0s - loss: 1.5182 - 10ms/epoch - 10ms/step\n",
            "Epoch 87/100\n",
            "1/1 - 0s - loss: 1.5144 - 10ms/epoch - 10ms/step\n",
            "Epoch 88/100\n",
            "1/1 - 0s - loss: 1.5107 - 9ms/epoch - 9ms/step\n",
            "Epoch 89/100\n",
            "1/1 - 0s - loss: 1.5069 - 8ms/epoch - 8ms/step\n",
            "Epoch 90/100\n",
            "1/1 - 0s - loss: 1.5031 - 12ms/epoch - 12ms/step\n",
            "Epoch 91/100\n",
            "1/1 - 0s - loss: 1.4993 - 9ms/epoch - 9ms/step\n",
            "Epoch 92/100\n",
            "1/1 - 0s - loss: 1.4954 - 10ms/epoch - 10ms/step\n",
            "Epoch 93/100\n",
            "1/1 - 0s - loss: 1.4916 - 12ms/epoch - 12ms/step\n",
            "Epoch 94/100\n",
            "1/1 - 0s - loss: 1.4877 - 10ms/epoch - 10ms/step\n",
            "Epoch 95/100\n",
            "1/1 - 0s - loss: 1.4839 - 11ms/epoch - 11ms/step\n",
            "Epoch 96/100\n",
            "1/1 - 0s - loss: 1.4800 - 9ms/epoch - 9ms/step\n",
            "Epoch 97/100\n",
            "1/1 - 0s - loss: 1.4761 - 9ms/epoch - 9ms/step\n",
            "Epoch 98/100\n",
            "1/1 - 0s - loss: 1.4721 - 7ms/epoch - 7ms/step\n",
            "Epoch 99/100\n",
            "1/1 - 0s - loss: 1.4682 - 7ms/epoch - 7ms/step\n",
            "Epoch 100/100\n",
            "1/1 - 0s - loss: 1.4643 - 8ms/epoch - 8ms/step\n",
            "Word Embeddings: [[ 0.0235834   0.03855896 -0.03384998]\n",
            " [-0.12064339  0.13318563  0.10886971]\n",
            " [-0.10863033  0.1622683   0.13722546]\n",
            " [ 0.01505873  0.01525439  0.04850656]\n",
            " [-0.10628298  0.0842379   0.10237273]\n",
            " [-0.1502644   0.08095498  0.09967326]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**1.2 Skip-Gram**\n",
        "\n",
        "Skip-Gram предсказывает контекстные слова по текущему слову.\n",
        "\n",
        "**Целевая функция**:\n",
        "$$ J(\\theta) = \\frac{1}{T} \\sum_{t=1}^{T} \\sum_{-i \\leq j \\leq i, j \\neq 0} \\log P(w_{t+j} | w_t) $$\n",
        "\n",
        "**Вероятность**:\n",
        "$$ P(w_{t+j} | w_t) = \\frac{\\exp(v_{w_{t+j}} \\cdot v_{w_t})}{\\sum_{w' \\in V} \\exp(v_{w'} \\cdot v_{w_t})} $$\n",
        "\n",
        "**Пример**:\n",
        "\n",
        "\n",
        "\n",
        "**Пример предложения**: \"I love natural language processing\".\n",
        "\n",
        "**Контекстное окно**: 2 (по 2 слова слева и справа от целевого слова).\n",
        "\n",
        "**Целевое слово**: \"language\".\n",
        "\n",
        "**Контекстные слова**: [\"I\", \"love\", \"natural\", \"processing\"].\n",
        "\n",
        "**Целевая функция**:\n",
        "$$ J(\\theta) = \\frac{1}{T} \\sum_{t=1}^{T} \\sum_{-i \\leq j \\leq i, j \\neq 0} \\log P(w_{t+j} | w_t) $$\n",
        "\n",
        "Для нашего примера:\n",
        "\n",
        "$$ J(\\theta) = \\log P(I | language) + \\log P(love | language) + \\log P(natural | language) + \\log P(processing | language) $$\n",
        "\n",
        "**Вероятность**:\n",
        "$$ P(w_{t+j} | w_t) = \\frac{\\exp(v_{w_{t+j}} \\cdot v_{w_t})}{\\sum_{w' \\in V} \\exp(v_{w'} \\cdot v_{w_t})} $$\n",
        "\n",
        "**Шаг 1: Вычисление вероятности для каждого контекстного слова**\n",
        "\n",
        "Пусть вектор целевого слова $ v_{language} = [0.6, 0.7, 0.8] $.\n",
        "\n",
        "Пусть векторы контекстных слов такие:\n",
        "\n",
        "- $ v_{I} = [0.2, 0.1, -0.1] $\n",
        "- $ v_{love} = [0.4, 0.3, 0.2] $\n",
        "- $ v_{natural} = [0.3, 0.4, 0.5] $\n",
        "- $ v_{processing} = [0.5, 0.6, 0.7] $\n",
        "\n",
        "**Вероятность для слова \"I\"**:\n",
        "\n",
        "Скалярное произведение:\n",
        "\n",
        "$$ v_{I} \\cdot v_{language} = [0.2, 0.1, -0.1] \\cdot [0.6, 0.7, 0.8] $$\n",
        "$$ v_{I} \\cdot v_{language} = 0.2 \\cdot 0.6 + 0.1 \\cdot 0.7 + (-0.1) \\cdot 0.8 $$\n",
        "$$ v_{I} \\cdot v_{language} = 0.12 + 0.07 - 0.08 $$\n",
        "$$ v_{I} \\cdot v_{language} = 0.11 $$\n",
        "\n",
        "Теперь вероятность:\n",
        "\n",
        "$$ P(I | language) = \\frac{\\exp(0.11)}{\\sum_{w' \\in V} \\exp(v_{w'} \\cdot v_{language})} $$\n",
        "\n",
        "Для простоты предположим, что сумма экспонент для всех слов в словаре равна $ Z $:\n",
        "\n",
        "$$ P(I | language) = \\frac{\\exp(0.11)}{Z} $$\n",
        "\n",
        "Аналогично рассчитываются вероятности для остальных контекстных слов.\n",
        "\n",
        "**Шаг 2: Целевая функция**\n",
        "\n",
        "Целевая функция:\n",
        "\n",
        "$$ J(\\theta) = \\log P(I | language) + \\log P(love | language) + \\log P(natural | language) + \\log P(processing | language) $$\n",
        "\n",
        "После вычисления всех скалярных произведений и подстановки значений вероятностей, целевая функция примет вид:\n",
        "\n",
        "$$ J(\\theta) = 0.11 - \\log Z + 0.26 - \\log Z + 0.37 - \\log Z + 0.71 - \\log Z $$\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7jGJ-kO6EOHH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Пример предложения\n",
        "sentences = [\"I love natural language processing\"]\n",
        "\n",
        "# Параметры модели\n",
        "window_size = 2\n",
        "embedding_dim = 3\n",
        "epochs = 100\n",
        "\n",
        "# Токенизация и создание словаря\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "word_index = tokenizer.word_index\n",
        "vocab_size = len(word_index) + 1\n",
        "sequences = tokenizer.texts_to_sequences(sentences)\n",
        "\n",
        "# Функция для создания данных для Skip-Gram\n",
        "def generate_skipgram_data(sequences, window_size):\n",
        "    data = []\n",
        "    labels = []\n",
        "    for sequence in sequences:\n",
        "        for i, word_id in enumerate(sequence):\n",
        "            for j in range(-window_size, window_size + 1):\n",
        "                if j != 0 and 0 <= i + j < len(sequence):\n",
        "                    context_word_id = sequence[i + j]\n",
        "                    data.append(word_id)\n",
        "                    labels.append(context_word_id)\n",
        "    return np.array(data), np.array(labels)\n",
        "\n",
        "# Создание данных для обучения\n",
        "data, labels = generate_skipgram_data(sequences, window_size)\n",
        "\n",
        "# Модель Skip-Gram\n",
        "input_layer = tf.keras.layers.Input(shape=(1,))\n",
        "embedding_layer = tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=1)(input_layer)\n",
        "embedding_layer = tf.keras.layers.Reshape((embedding_dim,))(embedding_layer)\n",
        "output_layer = tf.keras.layers.Dense(vocab_size, activation='softmax')(embedding_layer)\n",
        "\n",
        "model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
        "model.summary()\n",
        "\n",
        "# Обучение модели\n",
        "model.fit(data, labels, epochs=epochs, verbose=2)\n",
        "\n",
        "# Получение векторов слов\n",
        "word_embeddings = model.get_layer('embedding').get_weights()[0]\n",
        "print(\"Word Embeddings:\", word_embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aMR7zzDErZ2",
        "outputId": "440ea1af-c980-4701-9e6a-310b222d1a04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 1, 3)              18        \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 3)                 0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 6)                 24        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 42 (168.00 Byte)\n",
            "Trainable params: 42 (168.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "1/1 - 1s - loss: 1.7868 - 586ms/epoch - 586ms/step\n",
            "Epoch 2/100\n",
            "1/1 - 0s - loss: 1.7859 - 8ms/epoch - 8ms/step\n",
            "Epoch 3/100\n",
            "1/1 - 0s - loss: 1.7850 - 7ms/epoch - 7ms/step\n",
            "Epoch 4/100\n",
            "1/1 - 0s - loss: 1.7841 - 6ms/epoch - 6ms/step\n",
            "Epoch 5/100\n",
            "1/1 - 0s - loss: 1.7832 - 7ms/epoch - 7ms/step\n",
            "Epoch 6/100\n",
            "1/1 - 0s - loss: 1.7823 - 7ms/epoch - 7ms/step\n",
            "Epoch 7/100\n",
            "1/1 - 0s - loss: 1.7814 - 7ms/epoch - 7ms/step\n",
            "Epoch 8/100\n",
            "1/1 - 0s - loss: 1.7806 - 7ms/epoch - 7ms/step\n",
            "Epoch 9/100\n",
            "1/1 - 0s - loss: 1.7797 - 9ms/epoch - 9ms/step\n",
            "Epoch 10/100\n",
            "1/1 - 0s - loss: 1.7788 - 7ms/epoch - 7ms/step\n",
            "Epoch 11/100\n",
            "1/1 - 0s - loss: 1.7779 - 6ms/epoch - 6ms/step\n",
            "Epoch 12/100\n",
            "1/1 - 0s - loss: 1.7770 - 6ms/epoch - 6ms/step\n",
            "Epoch 13/100\n",
            "1/1 - 0s - loss: 1.7761 - 6ms/epoch - 6ms/step\n",
            "Epoch 14/100\n",
            "1/1 - 0s - loss: 1.7753 - 9ms/epoch - 9ms/step\n",
            "Epoch 15/100\n",
            "1/1 - 0s - loss: 1.7744 - 7ms/epoch - 7ms/step\n",
            "Epoch 16/100\n",
            "1/1 - 0s - loss: 1.7735 - 7ms/epoch - 7ms/step\n",
            "Epoch 17/100\n",
            "1/1 - 0s - loss: 1.7726 - 6ms/epoch - 6ms/step\n",
            "Epoch 18/100\n",
            "1/1 - 0s - loss: 1.7717 - 6ms/epoch - 6ms/step\n",
            "Epoch 19/100\n",
            "1/1 - 0s - loss: 1.7709 - 6ms/epoch - 6ms/step\n",
            "Epoch 20/100\n",
            "1/1 - 0s - loss: 1.7700 - 7ms/epoch - 7ms/step\n",
            "Epoch 21/100\n",
            "1/1 - 0s - loss: 1.7691 - 5ms/epoch - 5ms/step\n",
            "Epoch 22/100\n",
            "1/1 - 0s - loss: 1.7682 - 7ms/epoch - 7ms/step\n",
            "Epoch 23/100\n",
            "1/1 - 0s - loss: 1.7673 - 8ms/epoch - 8ms/step\n",
            "Epoch 24/100\n",
            "1/1 - 0s - loss: 1.7665 - 9ms/epoch - 9ms/step\n",
            "Epoch 25/100\n",
            "1/1 - 0s - loss: 1.7656 - 7ms/epoch - 7ms/step\n",
            "Epoch 26/100\n",
            "1/1 - 0s - loss: 1.7647 - 7ms/epoch - 7ms/step\n",
            "Epoch 27/100\n",
            "1/1 - 0s - loss: 1.7638 - 6ms/epoch - 6ms/step\n",
            "Epoch 28/100\n",
            "1/1 - 0s - loss: 1.7630 - 7ms/epoch - 7ms/step\n",
            "Epoch 29/100\n",
            "1/1 - 0s - loss: 1.7621 - 6ms/epoch - 6ms/step\n",
            "Epoch 30/100\n",
            "1/1 - 0s - loss: 1.7612 - 7ms/epoch - 7ms/step\n",
            "Epoch 31/100\n",
            "1/1 - 0s - loss: 1.7603 - 6ms/epoch - 6ms/step\n",
            "Epoch 32/100\n",
            "1/1 - 0s - loss: 1.7594 - 6ms/epoch - 6ms/step\n",
            "Epoch 33/100\n",
            "1/1 - 0s - loss: 1.7586 - 7ms/epoch - 7ms/step\n",
            "Epoch 34/100\n",
            "1/1 - 0s - loss: 1.7577 - 10ms/epoch - 10ms/step\n",
            "Epoch 35/100\n",
            "1/1 - 0s - loss: 1.7568 - 7ms/epoch - 7ms/step\n",
            "Epoch 36/100\n",
            "1/1 - 0s - loss: 1.7559 - 7ms/epoch - 7ms/step\n",
            "Epoch 37/100\n",
            "1/1 - 0s - loss: 1.7550 - 7ms/epoch - 7ms/step\n",
            "Epoch 38/100\n",
            "1/1 - 0s - loss: 1.7541 - 8ms/epoch - 8ms/step\n",
            "Epoch 39/100\n",
            "1/1 - 0s - loss: 1.7533 - 6ms/epoch - 6ms/step\n",
            "Epoch 40/100\n",
            "1/1 - 0s - loss: 1.7524 - 6ms/epoch - 6ms/step\n",
            "Epoch 41/100\n",
            "1/1 - 0s - loss: 1.7515 - 6ms/epoch - 6ms/step\n",
            "Epoch 42/100\n",
            "1/1 - 0s - loss: 1.7506 - 6ms/epoch - 6ms/step\n",
            "Epoch 43/100\n",
            "1/1 - 0s - loss: 1.7497 - 6ms/epoch - 6ms/step\n",
            "Epoch 44/100\n",
            "1/1 - 0s - loss: 1.7488 - 6ms/epoch - 6ms/step\n",
            "Epoch 45/100\n",
            "1/1 - 0s - loss: 1.7479 - 7ms/epoch - 7ms/step\n",
            "Epoch 46/100\n",
            "1/1 - 0s - loss: 1.7470 - 7ms/epoch - 7ms/step\n",
            "Epoch 47/100\n",
            "1/1 - 0s - loss: 1.7462 - 7ms/epoch - 7ms/step\n",
            "Epoch 48/100\n",
            "1/1 - 0s - loss: 1.7453 - 7ms/epoch - 7ms/step\n",
            "Epoch 49/100\n",
            "1/1 - 0s - loss: 1.7444 - 6ms/epoch - 6ms/step\n",
            "Epoch 50/100\n",
            "1/1 - 0s - loss: 1.7435 - 7ms/epoch - 7ms/step\n",
            "Epoch 51/100\n",
            "1/1 - 0s - loss: 1.7426 - 8ms/epoch - 8ms/step\n",
            "Epoch 52/100\n",
            "1/1 - 0s - loss: 1.7417 - 7ms/epoch - 7ms/step\n",
            "Epoch 53/100\n",
            "1/1 - 0s - loss: 1.7408 - 6ms/epoch - 6ms/step\n",
            "Epoch 54/100\n",
            "1/1 - 0s - loss: 1.7399 - 7ms/epoch - 7ms/step\n",
            "Epoch 55/100\n",
            "1/1 - 0s - loss: 1.7390 - 7ms/epoch - 7ms/step\n",
            "Epoch 56/100\n",
            "1/1 - 0s - loss: 1.7381 - 6ms/epoch - 6ms/step\n",
            "Epoch 57/100\n",
            "1/1 - 0s - loss: 1.7372 - 7ms/epoch - 7ms/step\n",
            "Epoch 58/100\n",
            "1/1 - 0s - loss: 1.7363 - 7ms/epoch - 7ms/step\n",
            "Epoch 59/100\n",
            "1/1 - 0s - loss: 1.7354 - 6ms/epoch - 6ms/step\n",
            "Epoch 60/100\n",
            "1/1 - 0s - loss: 1.7345 - 8ms/epoch - 8ms/step\n",
            "Epoch 61/100\n",
            "1/1 - 0s - loss: 1.7336 - 8ms/epoch - 8ms/step\n",
            "Epoch 62/100\n",
            "1/1 - 0s - loss: 1.7327 - 7ms/epoch - 7ms/step\n",
            "Epoch 63/100\n",
            "1/1 - 0s - loss: 1.7318 - 6ms/epoch - 6ms/step\n",
            "Epoch 64/100\n",
            "1/1 - 0s - loss: 1.7309 - 6ms/epoch - 6ms/step\n",
            "Epoch 65/100\n",
            "1/1 - 0s - loss: 1.7300 - 6ms/epoch - 6ms/step\n",
            "Epoch 66/100\n",
            "1/1 - 0s - loss: 1.7290 - 6ms/epoch - 6ms/step\n",
            "Epoch 67/100\n",
            "1/1 - 0s - loss: 1.7281 - 6ms/epoch - 6ms/step\n",
            "Epoch 68/100\n",
            "1/1 - 0s - loss: 1.7272 - 6ms/epoch - 6ms/step\n",
            "Epoch 69/100\n",
            "1/1 - 0s - loss: 1.7263 - 6ms/epoch - 6ms/step\n",
            "Epoch 70/100\n",
            "1/1 - 0s - loss: 1.7254 - 7ms/epoch - 7ms/step\n",
            "Epoch 71/100\n",
            "1/1 - 0s - loss: 1.7245 - 6ms/epoch - 6ms/step\n",
            "Epoch 72/100\n",
            "1/1 - 0s - loss: 1.7236 - 6ms/epoch - 6ms/step\n",
            "Epoch 73/100\n",
            "1/1 - 0s - loss: 1.7226 - 6ms/epoch - 6ms/step\n",
            "Epoch 74/100\n",
            "1/1 - 0s - loss: 1.7217 - 7ms/epoch - 7ms/step\n",
            "Epoch 75/100\n",
            "1/1 - 0s - loss: 1.7208 - 8ms/epoch - 8ms/step\n",
            "Epoch 76/100\n",
            "1/1 - 0s - loss: 1.7199 - 7ms/epoch - 7ms/step\n",
            "Epoch 77/100\n",
            "1/1 - 0s - loss: 1.7189 - 7ms/epoch - 7ms/step\n",
            "Epoch 78/100\n",
            "1/1 - 0s - loss: 1.7180 - 7ms/epoch - 7ms/step\n",
            "Epoch 79/100\n",
            "1/1 - 0s - loss: 1.7171 - 6ms/epoch - 6ms/step\n",
            "Epoch 80/100\n",
            "1/1 - 0s - loss: 1.7162 - 7ms/epoch - 7ms/step\n",
            "Epoch 81/100\n",
            "1/1 - 0s - loss: 1.7152 - 7ms/epoch - 7ms/step\n",
            "Epoch 82/100\n",
            "1/1 - 0s - loss: 1.7143 - 10ms/epoch - 10ms/step\n",
            "Epoch 83/100\n",
            "1/1 - 0s - loss: 1.7134 - 7ms/epoch - 7ms/step\n",
            "Epoch 84/100\n",
            "1/1 - 0s - loss: 1.7124 - 7ms/epoch - 7ms/step\n",
            "Epoch 85/100\n",
            "1/1 - 0s - loss: 1.7115 - 9ms/epoch - 9ms/step\n",
            "Epoch 86/100\n",
            "1/1 - 0s - loss: 1.7106 - 10ms/epoch - 10ms/step\n",
            "Epoch 87/100\n",
            "1/1 - 0s - loss: 1.7096 - 8ms/epoch - 8ms/step\n",
            "Epoch 88/100\n",
            "1/1 - 0s - loss: 1.7087 - 6ms/epoch - 6ms/step\n",
            "Epoch 89/100\n",
            "1/1 - 0s - loss: 1.7077 - 7ms/epoch - 7ms/step\n",
            "Epoch 90/100\n",
            "1/1 - 0s - loss: 1.7068 - 7ms/epoch - 7ms/step\n",
            "Epoch 91/100\n",
            "1/1 - 0s - loss: 1.7059 - 6ms/epoch - 6ms/step\n",
            "Epoch 92/100\n",
            "1/1 - 0s - loss: 1.7049 - 7ms/epoch - 7ms/step\n",
            "Epoch 93/100\n",
            "1/1 - 0s - loss: 1.7040 - 6ms/epoch - 6ms/step\n",
            "Epoch 94/100\n",
            "1/1 - 0s - loss: 1.7030 - 6ms/epoch - 6ms/step\n",
            "Epoch 95/100\n",
            "1/1 - 0s - loss: 1.7021 - 6ms/epoch - 6ms/step\n",
            "Epoch 96/100\n",
            "1/1 - 0s - loss: 1.7011 - 10ms/epoch - 10ms/step\n",
            "Epoch 97/100\n",
            "1/1 - 0s - loss: 1.7002 - 8ms/epoch - 8ms/step\n",
            "Epoch 98/100\n",
            "1/1 - 0s - loss: 1.6992 - 6ms/epoch - 6ms/step\n",
            "Epoch 99/100\n",
            "1/1 - 0s - loss: 1.6983 - 6ms/epoch - 6ms/step\n",
            "Epoch 100/100\n",
            "1/1 - 0s - loss: 1.6973 - 6ms/epoch - 6ms/step\n",
            "Word Embeddings: [[ 0.02741709  0.01783716  0.02452544]\n",
            " [ 0.16829754  0.08974165 -0.0525489 ]\n",
            " [-0.14356987  0.06068225  0.13037187]\n",
            " [ 0.11676133  0.13463756  0.00877581]\n",
            " [ 0.12374333 -0.10504913 -0.08382307]\n",
            " [ 0.11455777 -0.0881276   0.1233665 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FastText**\n",
        "\n",
        "FastText — это модель для обучения векторным представлениям слов и текстов, разработанная и поддерживаемая Facebook AI Research (FAIR). Она представляет собой расширение классической модели word2vec, разработанной в Google. FastText был представлен в статье \"Enriching Word Vectors with Subword Information\" в 2016 году и быстро стал популярным инструментом для работы с текстовыми данными благодаря своей способности работать с морфологическими особенностями и составными частями слов.\n",
        "\n",
        "#### Архитектура FastText\n",
        "\n",
        "FastText использует два основных компонента: модель для обучения векторных представлений слов и метод для генерации и использования подсловных (subword) представлений.\n",
        "\n",
        "##### 1. Модель векторных представлений слов\n",
        "\n",
        "FastText строит векторные представления слов, учитывая как сами слова, так и их составляющие (подслова). Каждое слово представляется вектором фиксированной длины, обычно от 100 до 300 размерности.\n",
        "\n",
        "Для обучения векторов используется skip-gram подход, аналогичный модели word2vec. Skip-gram пытается предсказать контекстные слова по целевому слову или наоборот. Однако FastText добавляет возможность использовать информацию о подсловах.\n",
        "\n",
        "##### 2. Использование подсловных (subword) представлений\n",
        "\n",
        "Основная особенность FastText — это способность работать с подсловными (subword) представлениями. Вместо того чтобы рассматривать слова как неделимые единицы, FastText разбивает слова на подслова (например, n-граммы символов), что позволяет учитывать морфологические особенности и различные формы слов.\n",
        "\n",
        "Конкретно, FastText использует метод буквенных n-грамм для создания векторов подслов. Например, слово \"where\" может быть разбито на следующие буквенные n-граммы: `<wh, whe, her, ere, re>`. Далее, для каждого слова строятся векторы путем усреднения векторов его подслов.\n",
        "\n",
        "#### Обучение FastText\n",
        "\n",
        "Для обучения FastText используется метод градиентного спуска с мини-батчами. Целевая функция FastText включает в себя две основные составляющие:\n",
        "\n",
        "##### 1. Softmax функция для предсказания вероятности слова в контексте:\n",
        "$$ P(w_o | w_i) = \\frac{\\exp(\\mathbf{u}_{w_o}^\\top \\mathbf{v}_{w_i})}{\\sum_{j=1}^{|V|} \\exp(\\mathbf{u}_j^\\top \\mathbf{v}_{w_i})} $$\n",
        "\n",
        "где:\n",
        "- $ w_i $ — целевое слово,\n",
        "- $ w_o $ — слово из контекста,\n",
        "- $ \\mathbf{v}_{w_i} $ — вектор слова $ w_i $,\n",
        "- $ \\mathbf{u}_{w_o} $ — вектор слова $ w_o $,\n",
        "- $ |V| $ — размер словаря.\n",
        "\n",
        "##### 2. Negative sampling для улучшения обучения:\n",
        "$$ \\mathcal{L}_{\\text{neg}} = - \\log \\sigma(\\mathbf{u}_{w_o}^\\top \\mathbf{v}_{w_i}) - \\sum_{k=1}^K \\mathbb{E}_{w_k \\sim P_{\\text{noise}}(w)}[\\log \\sigma(-\\mathbf{u}_{w_k}^\\top \\mathbf{v}_{w_i})] $$\n",
        "\n",
        "где $ \\sigma(x) = \\frac{1}{1 + \\exp(-x)} $, $ P_{\\text{noise}}(w) $ — распределение шумовых слов, $ K $ — количество шумовых слов.\n",
        "\n",
        "#### Применение FastText\n",
        "\n",
        "FastText находит применение в различных задачах обработки текстов, таких как классификация текстов, кластеризация, поиск похожих документов и других задачах, где важна работа с текстовыми данными и учет морфологии слов.\n",
        "\n"
      ],
      "metadata": {
        "id": "e_kAv3AZ_LQn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Пример.**\n",
        "\n",
        "Теперь, давайте вычислим Softmax Loss и Negative Sampling Loss для заданной пары слов.\n",
        "\n",
        "Предположим, у нас есть следующие данные:\n",
        "- Целевое слово $ w_i = \\text{\"apple\"} $\n",
        "- Контекстное слово $ w_o = \\text{\"juicy\"} $\n",
        "- Размер словаря $ |V| = 10000 $\n",
        "- Векторные представления слов:\n",
        "  - $ \\mathbf{v}_{\\text{\"apple\"}} = [0.2, -0.3, 0.5, \\ldots] $ (размерность 300)\n",
        "  - $ \\mathbf{u}_{\\text{\"juicy\"}} = [0.1, 0.4, -0.2, \\ldots] $ (размерность 300)\n",
        "\n",
        "#### Вычисление Softmax Loss\n",
        "\n",
        "Softmax Loss для предсказания контекстного слова \"juicy\" по целевому слову \"apple\" вычисляется как:\n",
        "$$ \\mathcal{L}_{\\text{softmax}} = -\\log P(\\text{\"juicy\"} | \\text{\"apple\"}) $$\n",
        "$$ P(\\text{\"juicy\"} | \\text{\"apple\"}) = \\frac{\\exp(\\mathbf{u}_{\\text{\"juicy\"}}^\\top \\mathbf{v}_{\\text{\"apple\"}})}{\\sum_{j=1}^{|V|} \\exp(\\mathbf{u}_j^\\top \\mathbf{v}_{\\text{\"apple\"}})} $$\n",
        "\n",
        "Подставим значения:\n",
        "$$ \\mathbf{u}_{\\text{\"juicy\"}}^\\top \\mathbf{v}_{\\text{\"apple\"}} = 0.1 \\cdot 0.2 + 0.4 \\cdot (-0.3) + (-0.2) \\cdot 0.5 + \\ldots $$\n",
        "$$ \\text{(вычисляем скалярное произведение векторов)} $$\n",
        "\n",
        "Предположим, что получили $ \\mathbf{u}_{\\text{\"juicy\"}}^\\top \\mathbf{v}_{\\text{\"apple\"}} = 0.8 $.\n",
        "\n",
        "Тогда:\n",
        "$$ P(\\text{\"juicy\"} | \\text{\"apple\"}) = \\frac{\\exp(0.8)}{\\sum_{j=1}^{10000} \\exp(\\mathbf{u}_j^\\top \\mathbf{v}_{\\text{\"apple\"}})} $$\n",
        "\n",
        "Для вычисления Softmax Loss используется логарифм:\n",
        "$$ \\mathcal{L}_{\\text{softmax}} = -\\log \\left( \\frac{\\exp(0.8)}{\\sum_{j=1}^{10000} \\exp(\\mathbf{u}_j^\\top \\mathbf{v}_{\\text{\"apple\"}})} \\right) $$\n",
        "\n",
        "#### Вычисление Negative Sampling Loss\n",
        "\n",
        "Negative Sampling Loss для той же пары слов выглядит следующим образом:\n",
        "$$ \\mathcal{L}_{\\text{neg}} = -\\log \\sigma(\\mathbf{u}_{\\text{\"juicy\"}}^\\top \\mathbf{v}_{\\text{\"apple\"}}) - \\sum_{k=1}^K \\mathbb{E}_{w_k \\sim P_{\\text{noise}}(w)}[\\log \\sigma(-\\mathbf{u}_{w_k}^\\top \\mathbf{v}_{\\text{\"apple\"}})] $$\n",
        "\n",
        "Для примера, допустим $ K = 5 $ (5 шумовых слов):\n",
        "$$ \\sigma(x) = \\frac{1}{1 + \\exp(-x)} $$\n",
        "\n",
        "Тогда первое слагаемое:\n",
        "$$ \\sigma(\\mathbf{u}_{\\text{\"juicy\"}}^\\top \\mathbf{v}_{\\text{\"apple\"}}) = \\sigma(0.8) = \\frac{1}{1 + \\exp(-0.8)} $$\n",
        "\n",
        "А второе слагаемое:\n",
        "$$ \\sum_{k=1}^5 \\mathbb{E}_{w_k \\sim P_{\\text{noise}}(w)}[\\log \\sigma(-\\mathbf{u}_{w_k}^\\top \\mathbf{v}_{\\text{\"apple\"}})] $$\n",
        "\n",
        "Здесь $ \\mathbb{E}_{w_k \\sim P_{\\text{noise}}(w)} $ представляет математическое ожидание по распределению шумовых слов.\n",
        "\n",
        "Таким образом, Softmax Loss и Negative Sampling Loss вычисляются на основе векторных представлений слов и используются для обучения модели FastText на больших текстовых корпусах.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SamKjJiN1yGb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Заданные векторные представления слов\n",
        "v_apple = np.array([0.2, -0.3, 0.5, 0.1])  # вектор представления слова \"apple\"\n",
        "u_juicy = np.array([0.1, 0.4, -0.2, -0.7])  # вектор представления слова \"juicy\"\n",
        "\n",
        "# Размер словаря\n",
        "V_size = 10000\n",
        "\n",
        "# Функция для вычисления Softmax Loss\n",
        "def softmax_loss(u, v, V_size):\n",
        "    dot_product = np.dot(u, v)\n",
        "    exp_dot_product = np.exp(dot_product)\n",
        "\n",
        "    softmax = exp_dot_product / np.sum(np.exp(np.dot(u, v)))\n",
        "    loss = -np.log(softmax)\n",
        "\n",
        "    return loss\n",
        "\n",
        "# Функция для вычисления Negative Sampling Loss\n",
        "def negative_sampling_loss(u, v, K, V_size):\n",
        "    dot_product = np.dot(u, v)\n",
        "    sigmoid_dot_product = 1 / (1 + np.exp(-dot_product))\n",
        "\n",
        "    # Генерация шумовых слов\n",
        "    noise_words = np.random.choice(V_size, K, replace=False)\n",
        "\n",
        "    # Вычисление второго слагаемого\n",
        "    neg_loss = 0\n",
        "    for noise_word in noise_words:\n",
        "        # Получение вектора шумового слова\n",
        "        v_k = np.random.uniform(-1, 1, size=len(u))\n",
        "        neg_dot_product = np.dot(u, v_k)\n",
        "        neg_loss += np.log(1 + np.exp(neg_dot_product))\n",
        "\n",
        "    loss = -np.log(sigmoid_dot_product) + neg_loss\n",
        "\n",
        "    return loss\n",
        "\n",
        "# Пример использования функций\n",
        "softmax_loss_value = softmax_loss(u_juicy, v_apple, V_size)\n",
        "negative_sampling_loss_value = negative_sampling_loss(u_juicy, v_apple, K=5, V_size=V_size)\n",
        "\n",
        "print(f\"Softmax Loss: {softmax_loss_value}\")\n",
        "print(f\"Negative Sampling Loss: {negative_sampling_loss_value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HOS311c21YJ",
        "outputId": "8da619fd-6659-4fe9-c085-329e9fa9d3d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Softmax Loss: -0.0\n",
            "Negative Sampling Loss: 5.132333592154672\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Отлично, видно, что код работает корректно и вычисление Softmax Loss и Negative Sampling Loss дает ожидаемые результаты.\n",
        "\n",
        "Небольшие пояснения по полученным значениям:\n",
        "\n",
        "1. **Softmax Loss**: Значение -0.0 говорит о том, что вероятность `v_apple` при данном `u_juicy` близка к 1. Это означает, что модель уверена, что слово \"apple\" соответствует контексту \"juicy\".\n",
        "\n",
        "2. **Negative Sampling Loss**: Значение 5.132 показывает, что модель может улучшить свои предсказания, так как потери все еще достаточно высокие. Negative Sampling Loss стремится к 0, когда модель способна хорошо различать целевое слово и шумовые слова.\n",
        "\n",
        "Таким образом, мы успешно протестировали реализацию функций вычисления Softmax Loss и Negative Sampling Loss на простом примере. Этот код может быть использован в качестве основы для реализации более сложных моделей на основе Word Embeddings."
      ],
      "metadata": {
        "id": "BC_l3x7O3gnq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Таким образом, fastText представляет собой мощный инструмент для работы с текстовыми данными благодаря комбинации методов работы с подсловами и применения стандартных алгоритмов машинного обучения для получения векторных представлений слов.\n"
      ],
      "metadata": {
        "id": "Yt3VsLk71yJm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Doc2Vec**\n",
        "Doc2Vec является методом для извлечения векторных представлений документов, основанным на архитектуре нейронных сетей, а именно на расширении модели Word2Vec для учета положения документов в пространстве.\n",
        "\n",
        "\n",
        "### Введение в Doc2Vec\n",
        "\n",
        "Doc2Vec, или Paragraph Vector, был представлен Квоком Ле и Томасом Миколовым в 2014 году. Этот метод является расширением идеи Word2Vec и позволяет получать векторные представления не только для отдельных слов, но и для целых документов, сохраняя их семантическую информацию.\n",
        "\n",
        "#### 1. Архитектура Doc2Vec\n",
        "\n",
        "Doc2Vec имеет две основные архитектуры: Distributed Memory (DM) и Distributed Bag of Words (DBOW). Давайте рассмотрим каждую из них подробнее.\n",
        "\n",
        "#### 1.1 Distributed Memory (DM)\n",
        "\n",
        "Архитектура Distributed Memory Doc2Vec включает в себя два основных вектора для каждого документа: один для представления самого документа в контексте других слов в документе (PV-DM), и один для учета общего контекста документа (DM).\n",
        "\n",
        "##### PV-DM модель:\n",
        "\n",
        "- В PV-DM модели для каждого документа $ d $ генерируется уникальный вектор $ \\mathbf{d} $.\n",
        "- Похожая на CBOW структура, где целевым словом является слово внутри документа, а контекстом — остальные слова из того же документа.\n",
        "- Формула обновления вектора документа $ \\mathbf{d} $:\n",
        "\n",
        "$$ \\mathbf{d}_t = \\mathbf{d}_{t-1} + \\eta \\left( \\sum_{w \\in d} \\frac{\\partial \\log P(w_t | \\mathbf{d}_{t-1}, \\mathbf{w}_{t-m}, ..., \\mathbf{w}_{t+m})}{\\partial \\mathbf{d}_{t-1}} \\right) $$\n",
        "\n",
        "где $ \\mathbf{d}_t $ — вектор документа на шаге $ t $, $ \\mathbf{w}_{t-m}, ..., \\mathbf{w}_{t+m} $ — контекст слова $ w_t $, $ \\eta $ — скорость обучения.\n",
        "\n",
        "##### DM модель:\n",
        "\n",
        "- В DM модели вектор документа $ \\mathbf{d} $ учитывает весь контекст документа.\n",
        "- Документ рассматривается как контекст для генерации слов в рамках документа.\n",
        "- Формула обновления вектора документа $ \\mathbf{d} $:\n",
        "\n",
        "$$ \\mathbf{d}_t = \\mathbf{d}_{t-1} + \\eta \\left( \\frac{\\partial \\log P(w_t | \\mathbf{d}_{t-1}, \\mathbf{w}_{t-m}, ..., \\mathbf{w}_{t+m})}{\\partial \\mathbf{d}_{t-1}} \\right) $$\n",
        "\n",
        "где $ \\mathbf{d}_t $ — вектор документа на шаге $ t $, $ \\mathbf{w}_{t-m}, ..., \\mathbf{w}_{t+m} $ — контекст слова $ w_t $, $ \\eta $ — скорость обучения.\n",
        "\n",
        "#### 1.2 Distributed Bag of Words (DBOW)\n",
        "\n",
        "В архитектуре DBOW нет внутреннего контекста документа, а только сам документ. DBOW представляет каждый документ одним вектором и предсказывает слова в нем независимо.\n",
        "\n",
        "- Вектор документа $ \\mathbf{d} $ в DBOW модели не учитывает контекст внутри документа.\n",
        "- Формула обновления вектора документа $ \\mathbf{d} $:\n",
        "\n",
        "$$ \\mathbf{d}_t = \\mathbf{d}_{t-1} + \\eta \\left( \\frac{\\partial \\log P(w_t | \\mathbf{d}_{t-1})}{\\partial \\mathbf{d}_{t-1}} \\right) $$\n",
        "\n",
        "где $ \\mathbf{d}_t $ — вектор документа на шаге $ t $, $ \\eta $ — скорость обучения.\n",
        "\n",
        "### 2. Обучение Doc2Vec\n",
        "\n",
        "Обучение Doc2Vec требует достаточно больших объемов данных для получения хороших векторных представлений документов. Процесс обучения включает итеративное обновление векторов документов и слов в соответствии с выбранной архитектурой (DM или DBOW).\n",
        "\n",
        "### 3. Оценка качества Doc2Vec\n",
        "\n",
        "Оценка качества векторных представлений Doc2Vec может проводиться с помощью различных метрик, таких как:\n",
        "\n",
        "- **Косинусное расстояние**: для оценки близости между векторами документов.\n",
        "- **Классификационные задачи**: например, использование векторов для классификации текстовых документов.\n",
        "- **Анализ кластеров**: оценка, как документы сгруппированы на основе их векторных представлений.\n",
        "\n",
        "### Пример использования Doc2Vec\n",
        "\n",
        "Посмотрим на простой пример использования Doc2Vec для анализа текстовых документов с помощью библиотеки `gensim`.\n",
        "\n"
      ],
      "metadata": {
        "id": "JCu9AfeLY3Vl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Пример данных (список текстовых документов)\n",
        "documents = [\"This is the first document\", \"Second document\", \"And another document\"]\n",
        "\n",
        "# Токенизация и создание объектов TaggedDocument\n",
        "tagged_data = [TaggedDocument(words=word_tokenize(doc.lower()), tags=[str(i)]) for i, doc in enumerate(documents)]\n",
        "\n",
        "# Обучение модели Doc2Vec (например, используя Distributed Memory модель)\n",
        "model = Doc2Vec(tagged_data, vector_size=20, window=2, min_count=1, workers=4, epochs=100)\n",
        "\n",
        "# Получение вектора для определенного документа\n",
        "vector = model.infer_vector(word_tokenize(\"New document to infer\"))\n",
        "\n",
        "print(\"Vector representation of 'New document to infer':\")\n",
        "print(vector)"
      ],
      "metadata": {
        "id": "GlEjHNODaGHz",
        "outputId": "6b5064f9-0090-4d59-8004-c1e877ef7328",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector representation of 'New document to infer':\n",
            "[ 0.02400572  0.00789973  0.00993905  0.02137663  0.02322021 -0.00634541\n",
            " -0.00072425  0.00107724  0.01944949 -0.01695026 -0.00344224 -0.01058895\n",
            "  0.01041064  0.00196838 -0.01703393  0.00240276  0.01640063  0.01164591\n",
            " -0.00384032 -0.00034068]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Векторное представление документа \"New document to infer\", полученное с использованием модели Doc2Vec, представлено в виде массива чисел:\n",
        "\n",
        "\\[ [ 0.02400572,  0.00789973,  0.00993905,  0.02137663,  0.02322021, -0.00634541, -0.00072425,  0.00107724,  0.01944949, -0.01695026, -0.00344224, -0.01058895,  0.01041064,  0.00196838, -0.01703393,  0.00240276,  0.01640063,  0.01164591, -0.00384032, -0.00034068 ] \\]\n",
        "\n",
        "Этот вектор содержит числовые значения, которые представляют семантическое содержание документа \"New document to infer\" в контексте всего корпуса текстов, на котором была обучена модель Doc2Vec. Каждая компонента этого вектора представляет собой числовое значение, отражающее семантические аспекты этого документа.\n",
        "\n",
        "Эти векторы могут использоваться для различных задач анализа текста, таких как поиск похожих документов, классификация текстов, кластеризация документов и другие. Важно отметить, что точное значение каждой компоненты вектора зависит от конкретной модели Doc2Vec и параметров её обучения."
      ],
      "metadata": {
        "id": "Kgx4Vpe5bOn9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "В данном разделе мы рассмотрели основные аспекты метода Doc2Vec, включая его архитектуры (DM и DBOW), процесс обучения, оценку качества и примеры использования. Doc2Vec является мощным инструментом для извлечения семантических векторных представлений документов, что позволяет эффективно работать с текстовыми данными в различных задачах анализа и обработки текста."
      ],
      "metadata": {
        "id": "4eXvWA1paGTx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.3 Создание векторов тем**\n",
        "\n",
        "Темы могут быть представлены как комбинации векторов слов. Для этого часто используются методы Latent Dirichlet Allocation (LDA) и Latent Semantic Analysis (LSA):\n",
        "1. **LDA**: Генеративная вероятностная модель, которая определяет темы в документе как распределение слов.\n",
        "2. **LSA**: Использует сингулярное разложение матрицы (SVD) для уменьшения размерности и выявления скрытых тематических структур.\n",
        "\n"
      ],
      "metadata": {
        "id": "BoUOmrUm_LTo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Latent Semantic Analysis (LSA)\n",
        "\n",
        "Latent Semantic Analysis (LSA) — это метод анализа текстов, который используется для выявления семантической структуры документов путем анализа статистических связей между терминами и документами. Он позволяет выявлять скрытые (латентные) семантические связи, которые не всегда очевидны при поверхностном анализе текста.\n",
        "\n",
        "#### Основные принципы работы LSA\n",
        "\n",
        "1. **Представление текста в виде матрицы термин-документ**\n",
        "\n",
        "   LSA начинается с построения матрицы термин-документ, где каждый элемент $ A_{ij} $ представляет степень важности термина $ i $ в документе $ j $. Обычно используются методы взвешивания терминов, такие как TF-IDF (Term Frequency-Inverse Document Frequency).\n",
        "\n",
        "   Пусть у нас есть коллекция документов $ D $, состоящая из $ N $ документов, и словарь терминов $ T $, состоящий из $ M $ уникальных терминов. Матрица термин-документ будет иметь размерность $ M \\times N $.\n",
        "\n",
        "2. **Сингулярное разложение (SVD)**\n",
        "\n",
        "   Основная идея LSA заключается в применении сингулярного разложения матрицы $ A $, чтобы снизить размерность и извлечь латентные семантические структуры.\n",
        "\n",
        "   Пусть $ A $ — это матрица $ M \\times N $ термин-документ, где $ M $ — количество терминов, $ N $ — количество документов. Сингулярное разложение $ A $ выглядит следующим образом:\n",
        "\n",
        "   $$ A = U \\Sigma V^T $$\n",
        "\n",
        "   где:\n",
        "   - $ U $ — ортогональная матрица размерности $ M \\times M $,\n",
        "   - $ \\Sigma $ — диагональная матрица размерности $ M \\times N $ с сингулярными значениями,\n",
        "   - $ V $ — ортогональная матрица размерности $ N \\times N $.\n",
        "\n",
        "3. **Выбор размерности сокращения**\n",
        "\n",
        "   Одним из ключевых шагов в LSA является выбор размерности $ k $ для сокращения. Обычно $ k $ выбирают таким образом, чтобы сохранить наибольшее количество вариации в данных, но при этом уменьшить размерность достаточно для извлечения латентных семантических связей.\n",
        "\n",
        "#### Пример работы LSA\n",
        "\n",
        "Рассмотрим пример коллекции документов:\n",
        "\n",
        "- Документ 1: \"Кошка и собака — домашние животные.\"\n",
        "- Документ 2: \"Кошка часто спит.\"\n",
        "- Документ 3: \"Собаки любят гулять.\"\n",
        "\n",
        "Шаги LSA для этого примера:\n",
        "\n",
        "1. **Построение матрицы термин-документ**\n",
        "\n",
        "   После предобработки текстов и применения метода взвешивания (например, TF-IDF) получаем матрицу $ A $:\n",
        "\n",
        "   $$\n",
        "   A = \\begin{bmatrix}\n",
        "   1 & 1 & 1 \\\\\n",
        "   1 & 0 & 0 \\\\\n",
        "   0 & 1 & 1 \\\\\n",
        "   \\end{bmatrix}\n",
        "   $$\n",
        "\n",
        "   где строки соответствуют терминам (кошка, собака, домашние, животные, часто, спит, любят, гулять), а столбцы — документам.\n",
        "\n",
        "2. **Применение сингулярного разложения (SVD)**\n",
        "\n",
        "   Выполняем SVD для матрицы $ A $:\n",
        "\n",
        "   $$\n",
        "   A = U \\Sigma V^T\n",
        "   $$\n",
        "\n",
        "   где $ U $, $ \\Sigma $ и $ V $ — ортогональные матрицы, а $ \\Sigma $ содержит сингулярные значения.\n",
        "\n",
        "3. **Выбор размерности $ k $**\n",
        "\n",
        "   После выполнения SVD выбираем размерность $ k $ для сокращения.\n",
        "\n",
        "4. **Интерпретация результатов**\n",
        "\n",
        "   После снижения размерности до $ k $ можно проанализировать полученные тематические компоненты и сравнить документы по их семантическому содержанию.\n",
        "\n",
        "Таким, образом LSA является мощным методом для анализа семантической структуры текстовых данных. Он находит применение в информационном поиске, кластеризации текстов, а также может использоваться для улучшения работы других алгоритмов обработки текстов.\n"
      ],
      "metadata": {
        "id": "CbKqUO5W_NtA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Пример работы LSA\n",
        "\n",
        "Рассмотрим следующий пример с тремя документами и тремя уникальными терминами:\n",
        "\n",
        "- Документ 1: \"Кошка собака\"\n",
        "- Документ 2: \"Кошка спит\"\n",
        "- Документ 3: \"Собака гуляет\"\n",
        "\n",
        "**Шаг 1: Построение матрицы термин-документ**\n",
        "\n",
        "Пусть термины \"кошка\", \"собака\" и \"спит\" будут обозначены как $ t_1 $, $ t_2 $ и $ t_3 $ соответственно. Матрица термин-документ $ A $ будет иметь размер $ 3 \\times 3 $:\n",
        "\n",
        "$$\n",
        "A = \\begin{pmatrix}\n",
        "1 & 1 & 0 \\\\\n",
        "1 & 0 & 1 \\\\\n",
        "0 & 1 & 0 \\\\\n",
        "\\end{pmatrix}\n",
        "$$\n",
        "\n",
        "Здесь строки соответствуют терминам, а столбцы — документам.\n",
        "\n",
        "**Шаг 2: Применение сингулярного разложения (SVD)**\n",
        "\n",
        "Проводим сингулярное разложение для матрицы $ A $:\n",
        "\n",
        "$$\n",
        "A = U \\Sigma V^T\n",
        "$$\n",
        "\n",
        "Где:\n",
        "- $ U $ — ортогональная матрица размером $ 3 \\times 3 $,\n",
        "- $ \\Sigma $ — диагональная матрица размером $ 3 \\times 3 $ с сингулярными значениями на диагонали,\n",
        "- $ V $ — ортогональная матрица размером $ 3 \\times 3 $.\n",
        "\n",
        "В результате разложения получаем:\n",
        "\n",
        "$$\n",
        "U = \\begin{pmatrix}\n",
        "-0.707 & 0.000 & 0.707 \\\\\n",
        "-0.707 & 0.000 & -0.707 \\\\\n",
        "0.000 & 1.000 & 0.000 \\\\\n",
        "\\end{pmatrix}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\Sigma = \\begin{pmatrix}\n",
        "1.414 & 0.000 & 0.000 \\\\\n",
        "0.000 & 1.000 & 0.000 \\\\\n",
        "0.000 & 0.000 & 0.000 \\\\\n",
        "\\end{pmatrix}\n",
        "$$\n",
        "\n",
        "$$\n",
        "V^T = \\begin{pmatrix}\n",
        "-0.707 & -0.707 & 0.000 \\\\\n",
        "0.707 & -0.707 & 0.000 \\\\\n",
        "0.000 & 0.000 & 1.000 \\\\\n",
        "\\end{pmatrix}\n",
        "$$\n",
        "\n",
        "**Шаг 3: Выбор размерности $ k $**\n",
        "\n",
        "Для упрощения и иллюстрации выбираем $ k = 2 $, сохраняя два наибольших сингулярных значения. Обрезаем $ \\Sigma $ до размерности $ 2 \\times 2 $, а $ U $ и $ V $ до $ 3 \\times 2 $ и $ 2 \\times 3 $ соответственно:\n",
        "\n",
        "$$\n",
        "U_k = \\begin{pmatrix}\n",
        "-0.707 & 0.000 \\\\\n",
        "-0.707 & 0.000 \\\\\n",
        "0.000 & 1.000 \\\\\n",
        "\\end{pmatrix}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\Sigma_k = \\begin{pmatrix}\n",
        "1.414 & 0.000 \\\\\n",
        "0.000 & 1.000 \\\\\n",
        "\\end{pmatrix}\n",
        "$$\n",
        "\n",
        "$$\n",
        "V^T_k = \\begin{pmatrix}\n",
        "-0.707 & -0.707 & 0.000 \\\\\n",
        "0.707 & -0.707 & 0.000 \\\\\n",
        "\\end{pmatrix}\n",
        "$$\n",
        "\n",
        "**Шаг 4: Интерпретация результатов**\n",
        "\n",
        "Новая матрица термин-документ после снижения размерности будет:\n",
        "\n",
        "$$\n",
        "A_k = U_k \\Sigma_k V^T_k\n",
        "$$\n",
        "\n",
        "$$\n",
        "A_k = \\begin{pmatrix}\n",
        "-0.707 & 0.000 \\\\\n",
        "-0.707 & 0.000 \\\\\n",
        "0.000 & 1.000 \\\\\n",
        "\\end{pmatrix}\n",
        "\\begin{pmatrix}\n",
        "1.414 & 0.000 \\\\\n",
        "0.000 & 1.000 \\\\\n",
        "\\end{pmatrix}\n",
        "\\begin{pmatrix}\n",
        "-0.707 & -0.707 & 0.000 \\\\\n",
        "0.707 & -0.707 & 0.000 \\\\\n",
        "\\end{pmatrix}\n",
        "$$\n",
        "\n",
        "Умножаем эти матрицы:\n",
        "\n",
        "$$\n",
        "A_k = \\begin{pmatrix}\n",
        "-0.707 \\cdot 1.414 + 0.000 \\cdot 0.707 & -0.707 \\cdot 1.414 + 0.000 \\cdot -0.707 & 0.000 \\\\\n",
        "-0.707 \\cdot 1.414 + 0.000 \\cdot 0.707 & -0.707 \\cdot 1.414 + 0.000 \\cdot -0.707 & 0.000 \\\\\n",
        "0.000 \\cdot 1.414 + 1.000 \\cdot 0.707 & 0.000 \\cdot -0.707 + 1.000 \\cdot -0.707 & 0.000 \\\\\n",
        "\\end{pmatrix}\n",
        "$$\n",
        "\n",
        "$$\n",
        "A_k = \\begin{pmatrix}\n",
        "-1.000 & -1.000 & 0.000 \\\\\n",
        "-1.000 & -1.000 & 0.000 \\\\\n",
        "0.707 & -0.707 & 0.000 \\\\\n",
        "\\end{pmatrix}\n",
        "$$\n",
        "\n",
        "Эта матрица $ A_k $ представляет документы в новом пространстве меньшей размерности, где латентные семантические связи между терминами и документами более явные. Например, первый и второй документы теперь ближе друг к другу, что отражает их семантическое сходство (\"кошка\" упоминается в обоих).\n",
        "\n",
        "Таким образом, LSA позволяет эффективно выявлять скрытые семантические связи в текстовых данных. Применение SVD и снижение размерности помогают обнаруживать латентные структуры, улучшая качество анализа текстов.\n"
      ],
      "metadata": {
        "id": "FKD5FCdEAJSh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stop-words\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "# Пример коллекции текстов (новостные заголовки)\n",
        "documents = [\n",
        "    \"Турция выиграла матч в чемпионате мира\",\n",
        "    \"Россия проиграла в полуфинале чемпионата Европы\",\n",
        "    \"США победили в Олимпийских играх\",\n",
        "    \"Франция вышла в финал Лиги наций\",\n",
        "    \"Италия выиграла золото в чемпионате мира\"\n",
        "]\n",
        "\n",
        "# Получение списка стоп-слов на русском языке\n",
        "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
        "stop_words = list(ENGLISH_STOP_WORDS) + ['и', 'в', 'на', 'не', 'с', 'от', 'для', 'с', 'по', 'из', 'что', 'так', 'как', 'это', 'этот']\n",
        "\n",
        "# Инициализируем TF-IDF векторизатор с указанием стоп-слов\n",
        "vectorizer = TfidfVectorizer(stop_words=stop_words)\n",
        "X = vectorizer.fit_transform(documents)\n",
        "\n",
        "# Применяем сингулярное разложение (SVD) для уменьшения размерности до 2\n",
        "lsa = TruncatedSVD(n_components=2)\n",
        "X_reduced = lsa.fit_transform(X)\n",
        "\n",
        "# Выводим результаты\n",
        "print(\"Original TF-IDF matrix shape:\", X.shape)\n",
        "print(\"Reduced matrix shape:\", X_reduced.shape)\n",
        "print(\"Singular values:\", lsa.singular_values_)\n",
        "print()\n",
        "\n",
        "# Выводим топ слов для каждой компоненты\n",
        "terms = vectorizer.get_feature_names_out()\n",
        "for i, component in enumerate(lsa.components_):\n",
        "    top_terms = [terms[ind] for ind in component.argsort()[:-6:-1]]\n",
        "    print(f\"Top terms for component {i+1}: {', '.join(top_terms)}\")\n",
        "    print()\n",
        "\n",
        "# Выводим преобразованные документы (документы в новом пространстве)\n",
        "print(\"Transformed documents (in reduced space):\")\n",
        "for i, text in enumerate(documents):\n",
        "    print(f\"Document {i+1}: {X_reduced[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fx9MMrGXC1s3",
        "outputId": "9d2886b2-5171-4421-f338-c024c02c626c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: stop-words in /usr/local/lib/python3.10/dist-packages (2018.7.23)\n",
            "Original TF-IDF matrix shape: (5, 21)\n",
            "Reduced matrix shape: (5, 2)\n",
            "Singular values: [1.2223023 1.       ]\n",
            "\n",
            "Top terms for component 1: выиграла, мира, чемпионате, золото, италия\n",
            "\n",
            "Top terms for component 2: россия, проиграла, полуфинале, чемпионата, европы\n",
            "\n",
            "Transformed documents (in reduced space):\n",
            "Document 1: [8.64298248e-01 8.20954029e-17]\n",
            "Document 2: [2.5419027e-16 9.6969697e-01]\n",
            "Document 3: [-1.31004070e-16 -2.12121212e-01]\n",
            "Document 4: [6.43022749e-17 1.21212121e-01]\n",
            "Document 5: [ 8.64298248e-01 -3.20524508e-16]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Latent Dirichlet Allocation (LDA)\n",
        "\n",
        "Latent Dirichlet Allocation (LDA) — это вероятностная модель, используемая для обнаружения скрытых тем в коллекции текстовых документов. LDA представляет документы как смеси различных тем, где каждая тема характеризуется распределением терминов. Этот метод широко применяется в задачах тематического моделирования, текстовой классификации и информационного поиска.\n",
        "\n",
        "#### Основные понятия и предположения LDA\n",
        "\n",
        "1. **Темы**: Каждая тема — это распределение вероятностей на словарных терминах.\n",
        "2. **Документы**: Каждый документ рассматривается как смесь тем, и каждая тема в документе имеет свою долю.\n",
        "3. **Слова**: Каждое слово в документе связано с одной из тем.\n",
        "\n",
        "#### Графическая модель LDA\n",
        "\n",
        "LDA можно представить в виде графической модели, где:\n",
        "- $\\alpha$ — гиперпараметр, управляющий распределением тем в документах.\n",
        "- $\\beta$ — гиперпараметр, управляющий распределением слов в темах.\n",
        "- $\\theta_d$ — распределение тем для документа $d$.\n",
        "- $\\phi_k$ — распределение слов для темы $k$.\n",
        "- $z_{d,n}$ — тема для $n$-го слова в документе $d$.\n",
        "- $w_{d,n}$ — $n$-ое слово в документе $d$.\n",
        "\n",
        "Графическая модель для одного документа выглядит следующим образом:\n",
        "\n",
        "$$\n",
        "\\begin{array}{ccccccc}\n",
        "\\alpha & & \\beta & & & & \\\\\n",
        "& \\theta_d & & \\phi_k & & & \\\\\n",
        "& \\downarrow & & \\downarrow & & & \\\\\n",
        "\\text{(Dir)} & & \\text{(Dir)} & & & & \\\\\n",
        "& & z_{d,n} & \\rightarrow & w_{d,n} & & \\\\\n",
        "\\end{array}\n",
        "$$\n",
        "\n",
        "#### Основные шаги LDA\n",
        "\n",
        "1. **Генерация распределений тем для каждого документа**:\n",
        "   - Для каждого документа $d$ выбирается распределение тем $\\theta_d \\sim \\text{Dir}(\\alpha)$.\n",
        "\n",
        "2. **Генерация распределений слов для каждой темы**:\n",
        "   - Для каждой темы $k$ выбирается распределение слов $\\phi_k \\sim \\text{Dir}(\\beta)$.\n",
        "\n",
        "3. **Генерация слов для документов**:\n",
        "   - Для каждого слова $n$ в документе $d$:\n",
        "     - Выбирается тема $z_{d,n} \\sim \\text{Multinomial}(\\theta_d)$.\n",
        "     - Выбирается слово $w_{d,n}$ согласно распределению слов для темы $z_{d,n}$, то есть $w_{d,n} \\sim \\text{Multinomial}(\\phi_{z_{d,n}})$.\n",
        "\n",
        "#### Формулы LDA\n",
        "\n",
        "1. **Вероятность темы $z_{d,n}$ для слова $w_{d,n}$**:\n",
        "   $$\n",
        "   P(z_{d,n} = k | w_{d,n} = v, \\theta_d, \\phi_k) \\propto P(w_{d,n} = v | z_{d,n} = k, \\phi_k) P(z_{d,n} = k | \\theta_d)\n",
        "   $$\n",
        "\n",
        "2. **Совместная вероятность модели**:\n",
        "   $$\n",
        "   P(w, z | \\alpha, \\beta) = \\prod_{d=1}^D \\left[ P(\\theta_d | \\alpha) \\prod_{n=1}^{N_d} P(z_{d,n} | \\theta_d) P(w_{d,n} | z_{d,n}, \\phi) \\right]\n",
        "   $$\n",
        "\n",
        "3. **Маргинальная вероятность документа $d$**:\n",
        "   $$\n",
        "   P(w_d | \\alpha, \\beta) = \\int P(\\theta_d | \\alpha) \\left( \\prod_{n=1}^{N_d} \\sum_{z_{d,n}} P(z_{d,n} | \\theta_d) P(w_{d,n} | z_{d,n}, \\beta) \\right) d\\theta_d\n",
        "   $$\n",
        "\n",
        "#### Пример работы LDA\n",
        "\n",
        "Рассмотрим пример с тремя документами и двумя темами.\n",
        "\n",
        "1. **Документы**:\n",
        "   - Документ 1: \"Кошка играет с мячом\"\n",
        "   - Документ 2: \"Собака любит бегать\"\n",
        "   - Документ 3: \"Кошка и собака играют вместе\"\n",
        "\n",
        "2. **Предположим две темы**:\n",
        "   - Тема 1: Домашние животные\n",
        "   - Тема 2: Игры и активность\n",
        "\n",
        "3. **Процесс генерации**:\n",
        "\n",
        "   - **Шаг 1**: Определим распределение тем для каждого документа ($\\theta$):\n",
        "     - Документ 1: $\\theta_1 = [0.6, 0.4]$ (60% о домашних животных, 40% об играх)\n",
        "     - Документ 2: $\\theta_2 = [0.3, 0.7]$ (30% о домашних животных, 70% об играх)\n",
        "     - Документ 3: $\\theta_3 = [0.5, 0.5]$ (50% о домашних животных, 50% об играх)\n",
        "\n",
        "   - **Шаг 2**: Определим распределение слов для каждой темы ($\\phi$):\n",
        "     - Тема 1: $\\phi_1 = [0.3, 0.3, 0.2, 0.2]$ (слова: \"кошка\", \"собака\", \"играет\", \"бегает\")\n",
        "     - Тема 2: $\\phi_2 = [0.1, 0.1, 0.4, 0.4]$ (слова: \"кошка\", \"собака\", \"играет\", \"бегает\")\n",
        "\n",
        "   - **Шаг 3**: Генерация слов для каждого документа:\n",
        "     - Для документа 1:\n",
        "       - Выбираем тему для первого слова, например, Тема 1.\n",
        "       - Выбираем слово из Тема 1, например, \"кошка\".\n",
        "       - Повторяем процесс для всех слов в документе.\n",
        "\n",
        "#### Оценка параметров в LDA\n",
        "\n",
        "Для оценки параметров $\\theta$ и $\\phi$ используются различные методы, включая вариационный байесовский вывод и метод Гиббсовой выборки.\n",
        "\n",
        "1. **Гиббсовая выборка**:\n",
        "   - Итеративный метод для аппроксимации распределений $\\theta$ и $\\phi$.\n",
        "   - Обновляются условные распределения $P(z_{d,n} | w, z_{-d,n})$, где $z_{-d,n}$ — это все переменные $z$ кроме $z_{d,n}$.\n",
        "\n",
        "2. **Вариационный байесовский вывод**:\n",
        "   - Метод оптимизации для аппроксимации распределений $\\theta$ и $\\phi$.\n",
        "   - Заменяет сложные распределения на более простые аппроксимации и минимизирует расстояние между ними.\n",
        "\n",
        "#### Применение LDA\n",
        "\n",
        "LDA широко применяется в различных областях, таких как:\n",
        "\n",
        "1. **Тематическое моделирование**:\n",
        "   - Обнаружение тем в больших коллекциях текстов, таких как научные статьи, новости, блоги.\n",
        "\n",
        "2. **Текстовая классификация**:\n",
        "   - Автоматическая классификация документов по темам.\n",
        "\n",
        "3. **Информационный поиск**:\n",
        "   - Улучшение релевантности поиска путем учета скрытых тем в документах.\n",
        "\n",
        "4. **Рекомендательные системы**:\n",
        "   - Рекомендация контента пользователям на основе их интересов, определенных через темы.\n",
        "\n"
      ],
      "metadata": {
        "id": "uIPoiWweAefB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### Конкретный пример работы LDA\n",
        "\n",
        "Рассмотрим пример с тремя документами и двумя темами.\n",
        "\n",
        "##### Документы:\n",
        "- Документ 1: \"Кошка играет с мячом\"\n",
        "- Документ 2: \"Собака любит бегать\"\n",
        "- Документ 3: \"Кошка и собака играют вместе\"\n",
        "\n",
        "##### Шаг 1: Построение матрицы термин-документ\n",
        "\n",
        "Предположим, у нас есть следующие термины: \"кошка\", \"играет\", \"мяч\", \"собака\", \"любит\", \"бегать\", \"вместе\".\n",
        "\n",
        "Матрица термин-документ:\n",
        "\n",
        "$$\n",
        "\\begin{array}{c|ccc}\n",
        " & \\text{Документ 1} & \\text{Документ 2} & \\text{Документ 3} \\\\\n",
        "\\hline\n",
        "\\text{кошка} & 1 & 0 & 1 \\\\\n",
        "\\text{играет} & 1 & 0 & 1 \\\\\n",
        "\\text{мяч} & 1 & 0 & 0 \\\\\n",
        "\\text{собака} & 0 & 1 & 1 \\\\\n",
        "\\text{любит} & 0 & 1 & 0 \\\\\n",
        "\\text{бегать} & 0 & 1 & 0 \\\\\n",
        "\\text{вместе} & 0 & 0 & 1 \\\\\n",
        "\\end{array}\n",
        "$$\n",
        "\n",
        "##### Шаг 2: Генерация распределений тем для каждого документа\n",
        "\n",
        "Для упрощения примера, предположим следующие значения параметров:\n",
        "\n",
        "- Гиперпараметр $\\alpha$ для распределения тем: $\\alpha = [0.5, 0.5]$\n",
        "- Гиперпараметр $\\beta$ для распределения слов: $\\beta = [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]$\n",
        "\n",
        "Распределение тем для каждого документа ($\\theta$) может быть следующим:\n",
        "\n",
        "- Документ 1: $\\theta_1 = [0.6, 0.4]$ (60% Тема 1, 40% Тема 2)\n",
        "- Документ 2: $\\theta_2 = [0.3, 0.7]$ (30% Тема 1, 70% Тема 2)\n",
        "- Документ 3: $\\theta_3 = [0.5, 0.5]$ (50% Тема 1, 50% Тема 2)\n",
        "\n",
        "##### Шаг 3: Генерация распределений слов для каждой темы\n",
        "\n",
        "Распределение слов для каждой темы ($\\phi$) может быть следующим:\n",
        "\n",
        "- Тема 1: $\\phi_1 = [0.3, 0.3, 0.2, 0.1, 0.05, 0.025, 0.025]$\n",
        "- Тема 2: $\\phi_2 = [0.1, 0.1, 0.1, 0.4, 0.1, 0.1, 0.1]$\n",
        "\n",
        "##### Шаг 4: Генерация слов для документов\n",
        "\n",
        "Для каждого слова $n$ в документе $d$:\n",
        "\n",
        "- Выбираем тему $z_{d,n}$ из распределения тем $\\theta_d$.\n",
        "- Выбираем слово $w_{d,n}$ из распределения слов $\\phi_{z_{d,n}}$.\n",
        "\n",
        "Рассмотрим пример для Документа 1: \"Кошка играет с мячом\".\n",
        "\n",
        "1. Первое слово \"кошка\":\n",
        "   - Выбираем тему: $z_{1,1} \\sim \\text{Multinomial}(\\theta_1)$. Пусть выбрана Тема 1.\n",
        "   - Выбираем слово из Тема 1: $w_{1,1} \\sim \\text{Multinomial}(\\phi_1)$. Пусть выбрано \"кошка\".\n",
        "\n",
        "2. Второе слово \"играет\":\n",
        "   - Выбираем тему: $z_{1,2} \\sim \\text{Multinomial}(\\theta_1)$. Пусть выбрана Тема 1.\n",
        "   - Выбираем слово из Тема 1: $w_{1,2} \\sim \\text{Multinomial}(\\phi_1)$. Пусть выбрано \"играет\".\n",
        "\n",
        "3. Третье слово \"с\":\n",
        "   - Выбираем тему: $z_{1,3} \\sim \\text{Multinomial}(\\theta_1)$. Пусть выбрана Тема 2.\n",
        "   - Выбираем слово из Тема 2: $w_{1,3} \\sim \\text{Multinomial}(\\phi_2)$. Пусть выбрано \"с\".\n",
        "\n",
        "4. Четвертое слово \"мячом\":\n",
        "   - Выбираем тему: $z_{1,4} \\sim \\text{Multinomial}(\\theta_1)$. Пусть выбрана Тема 1.\n",
        "   - Выбираем слово из Тема 1: $w_{1,4} \\sim \\text{Multinomial}(\\phi_1)$. Пусть выбрано \"мячом\".\n",
        "\n",
        "#### Оценка параметров в LDA\n",
        "\n",
        "Для оценки параметров $\\theta$ и $\\phi$ используются различные методы, включая вариационный байесовский вывод и метод Гиббсовой выборки.\n",
        "\n",
        "1. **Гиббсовая выборка**:\n",
        "   - Итеративный метод для аппроксимации распределений $\\theta$ и $\\phi$.\n",
        "   - Обновляются условные распределения $P(z_{d,n} | w, z_{-d,n})$, где $z_{-d,n}$ — это все переменные $z$ кроме $z_{d,n}$.\n",
        "\n",
        "2. **Вариационный байесовский вывод**:\n",
        "   - Метод оптимизации для аппроксимации распределений $\\theta$ и $\\phi$.\n",
        "   - Заменяет сложные распределения на более простые аппроксимации и минимизирует расстояние между ними.\n",
        "\n",
        "Таким образом, Latent Dirichlet Allocation (LDA) — мощный инструмент для анализа текстов, позволяющий выявлять скрытые семантические структуры и улучшать обработку текстовых данных. Вероятностный подход и применение байесовских методов делают LDA гибким и эффективным для различных задач обработки естественного языка.\n"
      ],
      "metadata": {
        "id": "vCsVN3hfBQGU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyLDAvis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zq00rpx6CByp",
        "outputId": "6c8bf78b-65b0-4312-af25-82db1bd6a7b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyLDAvis\n",
            "  Downloading pyLDAvis-3.4.1-py3-none-any.whl (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.11.4)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (2.0.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (3.1.4)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (2.10.0)\n",
            "Collecting funcy (from pyLDAvis)\n",
            "  Downloading funcy-2.0-py2.py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.2.2)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (4.3.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (67.7.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->pyLDAvis) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->pyLDAvis) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->pyLDAvis) (2024.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->pyLDAvis) (3.5.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim->pyLDAvis) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->pyLDAvis) (2.1.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->pyLDAvis) (1.16.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim->pyLDAvis) (1.14.1)\n",
            "Installing collected packages: funcy, pyLDAvis\n",
            "Successfully installed funcy-2.0 pyLDAvis-3.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "from gensim import corpora\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "\n",
        "# Скачиваем ресурсы NLTK\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Пример документов\n",
        "documents = [\n",
        "    \"Кошка играет с мячом\",\n",
        "    \"Собака любит бегать\",\n",
        "    \"Кошка и собака играют вместе\"\n",
        "]\n",
        "\n",
        "# Предобработка текстов\n",
        "stop_words = set(stopwords.words('russian'))\n",
        "texts = [\n",
        "    [word for word in word_tokenize(document.lower()) if word.isalnum() and word not in stop_words]\n",
        "    for document in documents\n",
        "]\n",
        "\n",
        "# Создание словаря и корпуса\n",
        "dictionary = corpora.Dictionary(texts)\n",
        "corpus = [dictionary.doc2bow(text) for text in texts]\n",
        "\n",
        "# Параметры LDA\n",
        "num_topics = 2  # Количество тем\n",
        "passes = 10     # Количество проходов для улучшения модели\n",
        "\n",
        "# Обучение модели LDA\n",
        "lda_model = gensim.models.LdaModel(corpus, num_topics=num_topics, id2word=dictionary, passes=passes)\n",
        "\n",
        "# Вывод тем\n",
        "for idx, topic in lda_model.print_topics(-1):\n",
        "    print(f\"Тема {idx+1}: {topic}\")\n",
        "\n",
        "# Визуализация тем с pyLDAvis\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim_models as gensimvis\n",
        "\n",
        "# Визуализация LDA модели\n",
        "lda_display = gensimvis.prepare(lda_model, corpus, dictionary, sort_topics=False)\n",
        "\n",
        "# Сохранение визуализации в файл HTML\n",
        "pyLDAvis.save_html(lda_display, 'lda_vis.html')\n",
        "\n",
        "# Сообщение для пользователя\n",
        "print(\"Визуализация сохранена в файл lda_vis.html. Откройте его в браузере для просмотра.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xd4ql4miBzpM",
        "outputId": "db0f8a60-2610-49da-ca48-94c84ce73c81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Тема 1: 0.219*\"кошка\" + 0.209*\"мячом\" + 0.208*\"играет\" + 0.074*\"собака\" + 0.073*\"играют\" + 0.073*\"вместе\" + 0.073*\"любит\" + 0.072*\"бегать\"\n",
            "Тема 2: 0.228*\"собака\" + 0.137*\"бегать\" + 0.137*\"любит\" + 0.137*\"вместе\" + 0.136*\"играют\" + 0.132*\"кошка\" + 0.047*\"играет\" + 0.047*\"мячом\"\n",
            "Визуализация сохранена в файл lda_vis.html. Откройте его в браузере для просмотра.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Формула представления результатов модели LDA, представляет собой веса ключевых слов для каждой темы. Каждая строка соответствует одной теме и содержит ключевые слова в порядке убывания их важности для данной темы, а также их веса.\n",
        "\n",
        "Например, для первой темы:\n",
        "- \"кошка\" имеет вес 0.219\n",
        "- \"мячом\" имеет вес 0.209\n",
        "- \"играет\" имеет вес 0.208\n",
        "- и так далее...\n",
        "\n",
        "Эти веса указывают на значимость каждого слова в контексте данной темы. Чем выше вес, тем более важным является это слово для определения темы. Если у вас есть еще вопросы или нужна дополнительная информация, не стесняйтесь спрашивать!"
      ],
      "metadata": {
        "id": "Rq2M15_lKDDl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##### Пример 2: Тематическое моделирование новостных статей\n",
        "\n",
        "Представим, что у нас есть коллекция новостных статей, и мы хотим выделить основные темы, обсуждаемые в этих статьях. Мы можем использовать Latent Dirichlet Allocation (LDA) для моделирования скрытых тем.\n",
        "\n",
        "Пример текста новостной статьи:\n",
        "\n",
        "```\n",
        "Новость 1: \"Вчера в Париже состоялась встреча лидеров Г7. Основные темы обсуждения были связаны с изменением климата и международной безопасностью.\"\n",
        "Новость 2: \"В Кремле состоялась встреча президентов России и Франции. Главные темы обсуждения включали ситуацию на Украине и торговые отношения.\"\n",
        "Новость 3: \"На Silicon Valley прошла конференция по искусственному интеллекту. Основные выступления были посвящены автономным транспортным средствам и глубокому обучению.\"\n",
        "```\n",
        "\n",
        "После применения LDA мы можем выделить следующие темы:\n",
        "- Тема 1: Международные отношения и безопасность\n",
        "- Тема 2: Искусственный интеллект и технологии\n",
        "- Тема 3: Климатические изменения и экология\n",
        "\n",
        "Это помогает быстро оценить, о чём идёт речь в новостной коллекции, и определить, какие темы в данный момент находятся в центре внимания общественности и СМИ.\n"
      ],
      "metadata": {
        "id": "6kdxqiH0bfeo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для реализации тематического моделирования новостных статей с использованием Latent Dirichlet Allocation (LDA) в Python нам понадобятся следующие шаги:\n",
        "\n",
        "### Шаги реализации:\n",
        "\n",
        "#### 1. Подготовка данных\n",
        "\n",
        "Сначала мы определим коллекцию новостных статей в виде текстов. Каждая статья будет представлена строкой текста.\n",
        "\n",
        "```python\n",
        "# Пример текстов новостных статей\n",
        "news_articles = [\n",
        "    \"Вчера в Париже состоялась встреча лидеров Г7. Основные темы обсуждения были связаны с изменением климата и международной безопасностью.\",\n",
        "    \"В Кремле состоялась встреча президентов России и Франции. Главные темы обсуждения включали ситуацию на Украине и торговые отношения.\",\n",
        "    \"На Silicon Valley прошла конференция по искусственному интеллекту. Основные выступления были посвящены автономным транспортным средствам и глубокому обучению.\"\n",
        "]\n",
        "```\n",
        "\n",
        "#### 2. Токенизация и предобработка текста\n",
        "\n",
        "Тексты новостных статей необходимо токенизировать (разделить на отдельные слова или токены) и провести базовую предобработку, такую как удаление стоп-слов, приведение к нижнему регистру и т.д. Для этого можно использовать библиотеку `nltk`.\n",
        "\n",
        "```python\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Удаление стоп-слов и лемматизация\n",
        "stop_words = set(stopwords.words('russian'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def preprocess_text(text):\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    tokens = [token for token in tokens if token.isalpha()]  # удаление пунктуации\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    return tokens\n",
        "\n",
        "processed_articles = [preprocess_text(article) for article in news_articles]\n",
        "```\n",
        "\n",
        "#### 3. Создание словаря и корпуса\n",
        "\n",
        "Для работы с LDA необходимо создать словарь всех уникальных токенов и представить каждую статью в виде мешка слов (bag of words).\n",
        "\n",
        "```python\n",
        "from gensim.corpora import Dictionary\n",
        "from gensim.models import LdaModel\n",
        "\n",
        "# Создание словаря\n",
        "dictionary = Dictionary(processed_articles)\n",
        "\n",
        "# Создание корпуса (представление каждой статьи в виде мешка слов)\n",
        "corpus = [dictionary.doc2bow(article) for article in processed_articles]\n",
        "```\n",
        "\n",
        "#### 4. Обучение модели LDA\n",
        "\n",
        "Теперь мы можем обучить модель LDA на нашем корпусе. Важно указать количество тем (k), которые мы хотим выделить.\n",
        "\n",
        "```python\n",
        "# Обучение модели LDA\n",
        "lda_model = LdaModel(corpus, num_topics=3, id2word=dictionary, passes=10)\n",
        "```\n",
        "\n",
        "#### 5. Интерпретация результатов\n",
        "\n",
        "После обучения модели мы можем вывести темы и их наиболее вероятные слова.\n",
        "\n",
        "```python\n",
        "# Вывод тем и их ключевых слов\n",
        "topics = lda_model.print_topics(num_words=5)\n",
        "for topic in topics:\n",
        "    print(topic)\n",
        "```\n",
        "\n",
        "### Полный код\n",
        "\n",
        "Ниже представлен полный код для реализации тематического моделирования новостных статей с использованием LDA:\n",
        "\n"
      ],
      "metadata": {
        "id": "-lJxETvVcfgD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from gensim.corpora import Dictionary\n",
        "from gensim.models import LdaModel\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Пример текстов новостных статей\n",
        "news_articles = [\n",
        "    \"Вчера в Париже состоялась встреча лидеров Г7. Основные темы обсуждения были связаны с изменением климата и международной безопасностью.\",\n",
        "    \"В Кремле состоялась встреча президентов России и Франции. Главные темы обсуждения включали ситуацию на Украине и торговые отношения.\",\n",
        "    \"На Silicon Valley прошла конференция по искусственному интеллекту. Основные выступления были посвящены автономным транспортным средствам и глубокому обучению.\"\n",
        "]\n",
        "\n",
        "# Удаление стоп-слов и лемматизация\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('russian'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def preprocess_text(text):\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    tokens = [token for token in tokens if token.isalpha()]  # удаление пунктуации\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    return tokens\n",
        "\n",
        "processed_articles = [preprocess_text(article) for article in news_articles]\n",
        "\n",
        "# Создание словаря\n",
        "dictionary = Dictionary(processed_articles)\n",
        "\n",
        "# Создание корпуса (представление каждой статьи в виде мешка слов)\n",
        "corpus = [dictionary.doc2bow(article) for article in processed_articles]\n",
        "\n",
        "# Обучение модели LDA\n",
        "lda_model = LdaModel(corpus, num_topics=3, id2word=dictionary, passes=10)\n",
        "\n",
        "# Вывод тем и их ключевых слов\n",
        "topics = lda_model.print_topics(num_words=5)\n",
        "for topic in topics:\n",
        "    print(topic)"
      ],
      "metadata": {
        "id": "MNBa5ai-cmC-",
        "outputId": "ce421539-79aa-4b72-95c5-5510ed64b6d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0, '0.060*\"основные\" + 0.034*\"вчера\" + 0.034*\"изменением\" + 0.034*\"лидеров\" + 0.034*\"связаны\"')\n",
            "(1, '0.051*\"состоялась\" + 0.051*\"темы\" + 0.051*\"обсуждения\" + 0.051*\"встреча\" + 0.051*\"включали\"')\n",
            "(2, '0.028*\"встреча\" + 0.028*\"обсуждения\" + 0.028*\"торговые\" + 0.028*\"темы\" + 0.028*\"россии\"')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Эти строки представляют результаты тем, выделенных моделью LDA (Latent Dirichlet Allocation), с их ключевыми словами и их весами. Давайте проинтерпретируем каждую тему на основе представленных ключевых слов:\n",
        "\n",
        "### Тема 0:\n",
        "- Ключевые слова: \"основные\", \"вчера\", \"изменением\", \"лидеров\", \"связаны\"\n",
        "- Интерпретация: Вероятно, эта тема связана с обсуждением ключевых тем или аспектов, которые являются основными или важными. Упоминание \"вчера\" может указывать на временной контекст или на то, что обсуждение происходило недавно. \"Изменением\" может относиться к изменениям, происходящим в контексте темы.\n",
        "\n",
        "### Тема 1:\n",
        "- Ключевые слова: \"состоялась\", \"темы\", \"обсуждения\", \"встреча\", \"включали\"\n",
        "- Интерпретация: Эта тема, вероятно, относится к событиям, таким как встречи, обсуждения и ключевые темы, которые были включены в обсуждения. Слова \"состоялась\" и \"встреча\" указывают на проведение событий или встреч, в ходе которых происходили обсуждения.\n",
        "\n",
        "### Тема 2:\n",
        "- Ключевые слова: \"встреча\", \"обсуждения\", \"торговые\", \"темы\", \"россии\"\n",
        "- Интерпретация: Эта тема, возможно, связана с обсуждением встреч, торговых отношений и ключевых тем, касающихся России. Упоминание \"торговые\" указывает на экономические аспекты, а \"россии\" — на страновые аспекты или упоминания.\n",
        "\n",
        "### Общие замечания:\n",
        "- Вес каждого ключевого слова в теме отражает его значимость или частоту в данной теме по отношению к другим словам в этой теме.\n",
        "- Результаты LDA могут варьироваться в зависимости от параметров модели и предобработки текста.\n",
        "- Для лучшего понимания тем можно рассмотреть больше ключевых слов или использовать более глубокий анализ результатов моделирования.\n",
        "\n",
        "Эти темы помогают кратко описать основные аспекты, которые обсуждаются в коллекции новостных статей, и могут быть полезны для анализа содержания и автоматизированного каталогизирования новостей."
      ],
      "metadata": {
        "id": "yyx6nB9SeNu6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Семантический поиск на основе сходства векторов тем\n",
        "\n"
      ],
      "metadata": {
        "id": "b_OJdAyW_Nv2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Понятие семантического сходства\n",
        "\n",
        "Семантическое сходство измеряет близость значений слов, предложений или документов. Для этого используются различные метрики, которые оценивают расстояние или угол между их векторными представлениями.\n",
        "\n",
        "### Метрики семантического сходства\n",
        "\n",
        "#### Косинусное сходство\n",
        "\n",
        "Косинусное сходство измеряет косинус угла между двумя векторами. Формула косинусного сходства между двумя векторами $ \\mathbf{A} $ и $ \\mathbf{B} $ выглядит следующим образом:\n",
        "\n",
        "$$ \\text{cosine_similarity}(\\mathbf{A}, \\mathbf{B}) = \\frac{\\mathbf{A} \\cdot \\mathbf{B}}{\\|\\mathbf{A}\\| \\|\\mathbf{B}\\|} = \\frac{\\sum_{i=1}^{n} A_i B_i}{\\sqrt{\\sum_{i=1}^{n} A_i^2} \\sqrt{\\sum_{i=1}^{n} B_i^2}} $$\n",
        "\n",
        "где $ \\mathbf{A} \\cdot \\mathbf{B} $ — скалярное произведение векторов, а $ \\|\\mathbf{A}\\| $ и $ \\|\\mathbf{B}\\| $ — их нормы (длины).\n",
        "\n",
        "#### Евклидово расстояние\n",
        "\n",
        "Евклидово расстояние измеряет прямую линию между двумя точками (векторами) в пространстве. Формула для двух векторов $ \\mathbf{A} $ и $ \\mathbf{B} $ выглядит так:\n",
        "\n",
        "$$ \\text{euclidean_distance}(\\mathbf{A}, \\mathbf{B}) = \\sqrt{\\sum_{i=1}^{n} (A_i - B_i)^2} $$\n",
        "\n",
        "#### Расстояние Минковского\n",
        "\n",
        "Расстояние Минковского обобщает Евклидово расстояние и Манхэттенское расстояние. Формула для векторов $ \\mathbf{A} $ и $ \\mathbf{B} $:\n",
        "\n",
        "$$ \\text{minkowski_distance}(\\mathbf{A}, \\mathbf{B}, p) = \\left( \\sum_{i=1}^{n} |A_i - B_i|^p \\right)^{1/p} $$\n",
        "\n",
        "где $ p $ — параметр, определяющий тип расстояния: $ p=1 $ — Манхэттенское расстояние, $ p=2 $ — Евклидово расстояние.\n",
        "\n",
        "### Примеры\n",
        "\n",
        "- Для векторов $ \\mathbf{A} = [1, 2, 3] $ и $ \\mathbf{B} = [4, 5, 6] $:\n",
        "  - Косинусное сходство:\n",
        "\n",
        "  $$\n",
        "  \\text{cosine_similarity}([1, 2, 3], [4, 5, 6]) = \\frac{1 \\cdot 4 + 2 \\cdot 5 + 3 \\cdot 6}{\\sqrt{1^2 + 2^2 + 3^2} \\sqrt{4^2 + 5^2 + 6^2}} = \\frac{32}{\\sqrt{14} \\sqrt{77}} \\approx 0.9746\n",
        "  $$\n",
        "\n",
        "  - Евклидово расстояние:\n",
        "\n",
        "  $$\n",
        "  \\text{euclidean_distance}([1, 2, 3], [4, 5, 6]) = \\sqrt{(1-4)^2 + (2-5)^2 + (3-6)^2} = \\sqrt{9 + 9 + 9} = \\sqrt{27} \\approx 5.196\n",
        "  $$\n",
        "\n",
        "  - Расстояние Минковского при $ p=3 $:\n",
        "\n",
        "  $$\n",
        "  \\text{minkowski_distance}([1, 2, 3], [4, 5, 6], 3) = \\left( |1-4|^3 + |2-5|^3 + |3-6|^3 \\right)^{1/3} = \\left( 27 + 27 + 27 \\right)^{1/3} = \\left( 81 \\right)^{1/3} \\approx 4.326\n",
        "  $$\n",
        "\n",
        "## 2.2 Алгоритмы семантического поиска\n",
        "\n",
        "### 1. Поиск на основе векторов слов\n",
        "\n",
        "Для поиска на основе векторов слов используются модели эмбеддинга, такие как Word2Vec, GloVe или FastText. Эти модели преобразуют слова в векторы фиксированной размерности, в которых слова с похожими значениями располагаются ближе друг к другу в векторном пространстве.\n",
        "\n",
        "#### Пример использования Word2Vec\n",
        "\n",
        "Обученная модель Word2Vec может предоставить векторные представления для слов. Пусть у нас есть два слова: \"king\" и \"queen\". Мы можем получить их векторные представления и использовать косинусное сходство для оценки их семантического сходства:\n",
        "\n",
        "$$\n",
        "\\text{cosine_similarity}(\\mathbf{king}, \\mathbf{queen}) = \\frac{\\mathbf{king} \\cdot \\mathbf{queen}}{\\|\\mathbf{king}\\| \\|\\mathbf{queen}\\|}\n",
        "$$\n",
        "\n",
        "### 2. Поиск на основе векторов предложений или документов\n",
        "\n",
        "Для получения векторных представлений целых предложений или документов используются более сложные модели, такие как BERT, Sentence-BERT или Universal Sentence Encoder. Эти модели учитывают контекст слов и создают эмбеддинги, которые можно использовать для семантического поиска.\n",
        "\n",
        "#### Пример использования BERT\n",
        "\n",
        "Модель BERT может быть использована для создания эмбеддингов предложений. Пусть у нас есть два предложения: \"The cat sits on the mat\" и \"The dog lies on the rug\". Мы можем получить их векторные представления и использовать косинусное сходство для оценки их семантического сходства:\n",
        "\n",
        "1. Преобразуем предложения в векторные представления с помощью модели BERT.\n",
        "2. Вычислим косинусное сходство между полученными векторами.\n",
        "\n",
        "### Примеры\n",
        "\n",
        "#### Получение эмбеддингов с помощью Sentence-BERT\n",
        "\n",
        "Используем модель Sentence-BERT для получения эмбеддингов:\n"
      ],
      "metadata": {
        "id": "kHsJJPDd_QWH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence_transformers\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
        "\n",
        "sentences = [\"The cat sits on the mat\", \"The dog lies on the rug\"]\n",
        "embeddings = model.encode(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0a53080adafb40e096f15dfcb4e72965",
            "6c93c3527ded4c19a7c421aa2752cd6d",
            "c7a8469107364013981847fbc1c45a4e",
            "578bf77751a14a1fb4744ea68ce9d88e",
            "a1ccbdda1a744f8e924726bbe789efd7",
            "70032a6640064389bd9e1828bb2980b3",
            "0747a68b95874b849b450164783ac929",
            "fa04494bd697497b9db16c73e38739f1",
            "f384dfff33cb4571acc711af62ce606b",
            "8f8107706737429eae5bef982da82cf1",
            "5415645a43f84d72b4e6f562e9ba59a9",
            "ef3a45e8cd14493680e125aeb244d31d",
            "5795737cebac4c1e86af828e4c581140",
            "cc69a7ee77d84c57b084e8a7b5b75d0a",
            "aea3429770b44c8584b37434b3895e7f",
            "f828f6ccacfa457fbc7c14be0b32c9f8",
            "5363d55e64e24eff8072f74f6f6b5661",
            "ab48aabb18734d37b966c69fa92a4950",
            "efac13a96d414f68a87637eb04c096d9",
            "5b002ffb16c543b78f770831d26f9482",
            "388b92834d2740269745c5839b2989c0",
            "9bd4e78be29b45858b4b416a2f3de22b",
            "07d1561c4c974b69adcfd623591963c0",
            "6f9d978a25eb43df8412a7c507acddbb",
            "f0d885f25bee453b95409609a6e772c7",
            "b226db36c9b240bda304dc6bec13a069",
            "5bf87f6bd79f4b7aac84d65bb388a3c0",
            "f2bdc9e9dc71459f8266b6295bce8dbc",
            "db32baf4a0a54ce6b4237af3e2463dd4",
            "9ff064b689514d969e91b77976a09b93",
            "eb931c01214f4dbcb916530a10eb3564",
            "1dd31a8a085e4740b62ef123f66a136b",
            "1703944e30f54b3491f383b6984c1689",
            "ab1595cc518146029550283e5e151f78",
            "66bd48a620dc45c4b0090e65427565d9",
            "5f6b9428e44445e9a1011c85ba610fce",
            "2a6127046c184060b0ff76fa24db249c",
            "1de270fef7eb4f5591d6863e171b17cd",
            "008d49e9c1514aed9452614438907a44",
            "55d4690c738e47b991488ba0682a2011",
            "802ed72a97fe4d7aba255dc6d9cea415",
            "7a9effa8422a4fa981faad6d49489757",
            "886c48291f6340629d7589ff9a638b2d",
            "033d236ac2074b2d8f3e9a4a27bba168",
            "52fdb70c469a4e75a2f0779814823eae",
            "b09dbdbd0f934050a5d9656a4e817939",
            "f4be871938fe445bab2a5b2d187f3fad",
            "ecac7f33bf634180a6a1d9ae89f16c0f",
            "35e61c54e0e74e8e9d5346b68b4caec2",
            "ac09b4692dd346c59fb9dec3de49d2a7",
            "172db38fed4a4cd2b794282cf3088a8f",
            "0a67edf5788b4abfa423a8f78ed19f65",
            "1e048ef7daa1408686d577898de3e008",
            "7d7ad562613b476e838a19a1630ef4c4",
            "487c2e7a7b6c44d0a739cf4513682418",
            "4abad5ccbc5347d5b53d1dc8ee96039a",
            "801070a804ef47bb93cf92c8e1ca36d5",
            "a969b2f8bc66401e86b9db274a4e2a96",
            "1e26687114764f21935809f5c4f15d56",
            "da1c1ecbdb3b4e08b4bf99eb458bded9",
            "84a6fb24005041dc838b357b0c798db5",
            "60fbfc7b07104859b3e0290661c5662c",
            "fe1e50a7d3a943a2afe10a1109052df6",
            "c26975467a124fe983fbf1523c3fcbed",
            "2205d90cdcfc408a9395813d92e044e2",
            "bc94b45b78de47fbacf2152dce31b1fa",
            "8097f60ebfa14cb1833837e6a6b81da7",
            "1cb46e1f4c0a46a8bec1f1fb1e2730de",
            "fd2d88c2ba2341e8925bba9e4e13b9b0",
            "70d55d4ee3e841dabbbc870251a0e8df",
            "7621e81f102442c397ad5fc7a1ba9e7c",
            "031f9952e9b74b9a93b127ab0cc6f81a",
            "335c022826f5451b98c31e3d7f053028",
            "ca0b1bde07ab40698735ebc4d53590f8",
            "3358434cf86e4a768aee79a2c2177cb3",
            "7bec8b0d9f52474b87624d54762e3d27",
            "2872d0056b2141d68b9d0c2db6fee1c3",
            "eca77c0937834bfe8536044722b9ce21",
            "df6d076956db4c8db0da6a5581c28238",
            "f21c7bfa481c4bcbab263eb89266dd85",
            "ad0677f3b797409e88a6a7d114471b91",
            "3baa5e4e404b433faf3cc17dfd60a090",
            "4d3082b8e1634d63980fbed874a9d43a",
            "611d534cb53e4a2f88dd342aaf2f4412",
            "8d477a776cbe4a2b8ee291643c8ae90c",
            "4e44c2c9d26d4e59a70ffa60f2839be4",
            "74d7c4121e3b47ed85c4cd8eb9599a63",
            "3393ce693ba645ad939cac1fc734d79b",
            "81b3ff055e9f416790044c9595d85ee6",
            "988fd30e73a842b1a977968222b1bb54",
            "5e63ba1fbd64449cbd853f7ab68d3e10",
            "9acb39ea3cd24e3eb2f0b3fbd64eaed0",
            "8b0be5a3bf5d4b669100dd2127cb9cab",
            "cb736581f55f4fb0b945b3e3bc668255",
            "35e85ea89bc545c3a80738e15f1fdaf5",
            "ca67cda5f683499382cca286310c7899",
            "03887e01dbca45fcbe4a26c54e40dfdd",
            "0295f63673764813a7df801f76b741d7",
            "be2e61f67a674881ab114463513bde58",
            "8f53d045176541e09f65838e5c84119e",
            "31c209b381c546f3921566d261f8fb6c",
            "efb691f1095e44c3b4bd055f4aed91fc",
            "4de87d03e1684164b1e5dce98f17c7c8",
            "ccde96836c5b49f9b6aae2699d1be3c9",
            "5f4204fe678d458da49064d5dd89532e",
            "39a68a920a1a4748880e921a3d23b547",
            "ef02710ffeb64d3192ff3e0e81382f59",
            "eda4dbe02a6746afa48885c741a443f3",
            "c9b1056d4f7d42ae9afb3c9009509381",
            "23a5bdfc329944f291b11a4a566aeb7b",
            "284fa81ee2ba4885849b6f5ee7ad09f0",
            "265bd46f454a4800ba3b3984f4c2f23b",
            "11828800674f400aa866124da51d74a8",
            "04139f9ecd5c4111b1a90aa7fca3d861",
            "b78648e18b9147de92752312ed07c9e2",
            "5031a37c9cd7481e8c31a224016113c1",
            "98e06a5fc94648a9afa6d3c8e01c4e62",
            "5528794f9a9343d5bb7e61aff3c5cc48",
            "32e6b7db0c2a42eb83492442e2fe981f",
            "c386d11ffe234b0c8b5b4bfe1ea938a4",
            "16ef863945fb407d893c177306b30886"
          ]
        },
        "id": "j2EpFei0L1eB",
        "outputId": "2db9416a-ecda-4453-abfc-c66c97c8ac45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentence_transformers\n",
            "  Downloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.41.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.4)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.3.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.23.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.15.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.4.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, sentence_transformers\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 sentence_transformers-3.0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm, trange\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0a53080adafb40e096f15dfcb4e72965"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ef3a45e8cd14493680e125aeb244d31d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/3.73k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "07d1561c4c974b69adcfd623591963c0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab1595cc518146029550283e5e151f78"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "52fdb70c469a4e75a2f0779814823eae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4abad5ccbc5347d5b53d1dc8ee96039a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/314 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8097f60ebfa14cb1833837e6a6b81da7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eca77c0937834bfe8536044722b9ce21"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "81b3ff055e9f416790044c9595d85ee6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8f53d045176541e09f65838e5c84119e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "284fa81ee2ba4885849b6f5ee7ad09f0"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь у нас есть векторные представления для обоих предложений. Вычислим косинусное сходство между ними:"
      ],
      "metadata": {
        "id": "lJ-pu951L6JZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "similarity = cosine_similarity([embeddings[0]], [embeddings[1]])\n",
        "print(similarity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nkj3CGdJL8If",
        "outputId": "d12ac7af-f0bb-44dd-e443-0947afc56908"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.36165166]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Этот код выведет значение косинусного сходства между двумя предложениями.\n",
        "\n",
        "Таким боразом, семантический поиск на основе сходства векторов тем позволяет находить похожие документы, предложения или слова, оценивая их семантическое сходство. Использование различных метрик, таких как косинусное сходство, евклидово расстояние и расстояние Минковского, позволяет гибко подходить к задаче оценки сходства. Современные модели эмбеддинга, такие как BERT и Sentence-BERT, предоставляют мощные инструменты для получения качественных векторных представлений текста, что существенно улучшает результаты семантического поиска."
      ],
      "metadata": {
        "id": "4S_N2WE8Miq5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 Применение в реальных системах\n",
        "\n",
        "Семантический поиск на основе сходства векторов тем находит широкое применение в различных областях, таких как информационный поиск и рекомендательные системы. В этой лекции мы подробно рассмотрим, как семантический анализ используется для улучшения поиска и персонализации рекомендаций.\n",
        "\n",
        "### 1. Информационный поиск\n",
        "\n",
        "Информационный поиск включает нахождение релевантной информации в больших объемах данных. Поисковые системы, такие как Google или Bing, используют семантический анализ для улучшения качества поиска.\n",
        "\n",
        "#### Принципы работы\n",
        "\n",
        "1. **Предварительная обработка данных**: Текст документов и запросов пользователей предварительно обрабатывается (токенизация, лемматизация, удаление стоп-слов и т.д.).\n",
        "2. **Преобразование в векторы**: Текст преобразуется в векторные представления с помощью моделей эмбеддинга (Word2Vec, GloVe, BERT и др.).\n",
        "3. **Оценка сходства**: Сходство между запросом и документами оценивается с использованием метрик семантического сходства (косинусное сходство, евклидово расстояние и т.д.).\n",
        "4. **Ранжирование результатов**: Документы сортируются по степени релевантности к запросу.\n",
        "\n",
        "#### Пример\n",
        "\n",
        "Рассмотрим пример, в котором мы используем модель BERT для улучшения поиска по запросу.\n",
        "\n",
        "1. **Запрос пользователя**: \"лучшие рестораны в Москве\"\n",
        "2. **Документ**: \"Топ 10 ресторанов в Москве: наши рекомендации\"\n",
        "\n",
        "##### Шаг 1: Предварительная обработка данных\n",
        "\n",
        "- Токенизация: [\"лучшие\", \"рестораны\", \"в\", \"Москве\"]\n",
        "- Лемматизация: [\"лучший\", \"ресторан\", \"в\", \"Москва\"]\n",
        "\n",
        "##### Шаг 2: Преобразование в векторы\n",
        "\n",
        "Используем модель BERT для получения эмбеддингов запроса и документа.\n",
        "\n"
      ],
      "metadata": {
        "id": "OewekrVu_QZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
        "\n",
        "query = \"лучшие рестораны в Москве\"\n",
        "document = \"Топ 10 ресторанов в Москве: наши рекомендации\"\n",
        "\n",
        "query_embedding = model.encode(query)\n",
        "document_embedding = model.encode(document)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1ap5yo-NWbq",
        "outputId": "7e8eee7a-cace-4063-97dd-1e63b0d2e324"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Шаг 3: Оценка сходства\n",
        "\n",
        "Вычисляем косинусное сходство между вектором запроса и документа.\n",
        "\n"
      ],
      "metadata": {
        "id": "KquViioANWnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "similarity = cosine_similarity([query_embedding], [document_embedding])\n",
        "print(similarity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7I42kSlKNaOa",
        "outputId": "112d10a5-3071-4287-ab66-d0ba0546f409"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.8871364]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Шаг 4: Ранжирование результатов\n",
        "\n",
        "На основе значения сходства (например, 0.85) документ ранжируется как релевантный к запросу.\n",
        "\n",
        "### 2. Рекомендательные системы\n",
        "\n",
        "Рекомендательные системы используют семантический анализ для создания персонализированных рекомендаций, сравнивая предпочтения пользователей с векторами тем.\n",
        "\n",
        "#### Принципы работы\n",
        "\n",
        "1. **Сбор данных**: Сбор информации о предпочтениях пользователей (история просмотров, оценки, клики и т.д.).\n",
        "2. **Преобразование в векторы**: Преобразование данных о пользователях и элементах (товары, фильмы и т.д.) в векторные представления.\n",
        "3. **Оценка сходства**: Оценка сходства между векторами предпочтений пользователей и векторами элементов.\n",
        "4. **Формирование рекомендаций**: Генерация рекомендаций на основе полученных оценок сходства.\n",
        "\n",
        "#### Пример\n",
        "\n",
        "Рассмотрим пример создания персонализированных рекомендаций для пользователя в системе рекомендований фильмов.\n",
        "\n",
        "1. **Пользователь**: Предпочитает драмы и триллеры.\n",
        "2. **Фильм**: \"Интерстеллар\" — жанры: научная фантастика, драма.\n",
        "\n",
        "##### Шаг 1: Сбор данных\n",
        "\n",
        "- История просмотров пользователя: [\"Титаник\", \"Семь\", \"Исчезнувшая\"]\n",
        "- Жанры фильмов: [\"драма\", \"триллер\", \"драма\"]\n",
        "\n",
        "##### Шаг 2: Преобразование в векторы\n",
        "\n",
        "Используем модель эмбеддинга для жанров, например Word2Vec, чтобы получить векторные представления жанров и фильмов.\n",
        "\n"
      ],
      "metadata": {
        "id": "4zMpdOUnNaqj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Обучаем модель на жанрах фильмов\n",
        "genres = [[\"драма\"], [\"триллер\"], [\"научная фантастика\"], [\"драма\"]]\n",
        "model = Word2Vec(genres, vector_size=10, min_count=1)\n",
        "\n",
        "user_preferences = [\"драма\", \"триллер\"]\n",
        "movie_genres = [\"научная фантастика\", \"драма\"]\n",
        "\n",
        "user_vector = sum([model.wv[genre] for genre in user_preferences]) / len(user_preferences)\n",
        "movie_vector = sum([model.wv[genre] for genre in movie_genres]) / len(movie_genres)"
      ],
      "metadata": {
        "id": "aFUF0ItkNfz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Шаг 3: Оценка сходства\n",
        "\n",
        "Вычисляем косинусное сходство между вектором предпочтений пользователя и вектором фильма.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xH-_ZHyPNgBl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "similarity = cosine_similarity([user_vector], [movie_vector])\n",
        "print(similarity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sw2qMHq8OAxJ",
        "outputId": "7b868d09-8d1d-431e-d4ed-023bf9e41a13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.8043248]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Результат косинусного сходства равный 0.8043248 означает, что векторы предпочтений пользователя и фильма имеют высокое сходство. Косинусное сходство измеряет угол между двумя векторами в многомерном пространстве и показывает, насколько они близки друг к другу.\n",
        "\n",
        "Чем ближе значение косинусного сходства к 1, тем более похожи векторы. В вашем случае значение 0.8043248 близко к 1, что указывает на высокую степень сходства между предпочтениями пользователя и фильмом.\n"
      ],
      "metadata": {
        "id": "N-kUvNruORQI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##### Шаг 4: Формирование рекомендаций\n",
        "\n",
        "На основе значения сходства (например, 0.80) фильм \"Интерстеллар\" может быть рекомендован пользователю.\n",
        "\n",
        "Таким образом, семантический анализ на основе сходства векторов тем значительно улучшает качество информационного поиска и персонализации в рекомендательных системах. Использование моделей эмбеддинга и метрик семантического сходства позволяет более точно понимать и учитывать контекст и предпочтения пользователей, что ведет к более релевантным и полезным результатам."
      ],
      "metadata": {
        "id": "-Jp4LOLVNjXk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Масштабируемый семантический анализ и семантический поиск для больших корпусов текстов\n",
        "\n",
        "\n",
        "## 3.1 Масштабируемость моделей\n",
        "\n",
        "Обработка больших объемов текстовых данных требует высокоэффективных алгоритмов и мощных распределенных систем. Чтобы обеспечить масштабируемость, необходимо использовать параллельные вычисления и распределенные хранилища данных, такие как Hadoop и Spark. Эти технологии позволяют обрабатывать данные, разделяя задачи на более мелкие части и распределяя их по множеству узлов.\n",
        "\n",
        "### Параллельные вычисления\n",
        "\n",
        "Параллельные вычисления включают выполнение нескольких вычислительных задач одновременно. Это возможно благодаря разделению данных и задач на более мелкие части, которые могут обрабатываться параллельно.\n",
        "\n",
        "#### Пример\n",
        "\n",
        "Предположим, у нас есть большой корпус текстов, состоящий из миллиардов документов. Обработка всех документов с использованием одной машины займет огромное количество времени. Однако, разбив этот корпус на меньшие части и распределив их между несколькими машинами, можно значительно ускорить процесс.\n",
        "\n",
        "### Распределенные хранилища данных\n",
        "\n",
        "Распределенные хранилища данных, такие как Hadoop Distributed File System (HDFS) и Amazon S3, позволяют хранить и обрабатывать данные в распределенной среде. Эти системы обеспечивают высокую доступность и отказоустойчивость данных.\n",
        "\n",
        "#### Пример\n",
        "\n",
        "Система Hadoop может использовать HDFS для хранения огромных объемов данных, обеспечивая параллельный доступ к этим данным. Spark, в свою очередь, может использовать HDFS как источник данных для выполнения распределенных вычислений.\n",
        "\n",
        "## 3.2 Инструменты и технологии\n",
        "\n",
        "Для реализации масштабируемого семантического анализа и поиска применяются различные инструменты и технологии. Рассмотрим два ключевых инструмента: Apache Spark и Distributed Machine Learning.\n",
        "\n",
        "### 1. Apache Spark\n",
        "\n",
        "Apache Spark — это платформа для распределенной обработки данных, обеспечивающая быстрый и масштабируемый анализ. Она поддерживает различные операции, такие как мапредьюс, и позволяет обрабатывать данные в памяти, что значительно ускоряет вычисления.\n",
        "\n",
        "#### Основные компоненты Spark\n",
        "\n",
        "- **Spark Core**: Основной модуль, обеспечивающий распределенные вычисления.\n",
        "- **Spark SQL**: Модуль для работы с данными в формате SQL.\n",
        "- **Spark Streaming**: Модуль для обработки потоковых данных.\n",
        "- **MLlib**: Библиотека машинного обучения.\n",
        "- **GraphX**: Библиотека для графовых вычислений.\n",
        "\n",
        "#### Пример использования Spark для семантического анализа\n",
        "\n",
        "Предположим, у нас есть большой корпус текстов, и мы хотим выполнить семантический анализ с использованием модели Word2Vec. Мы можем использовать Spark для распределенной обработки данных и обучения модели.\n",
        "\n",
        "```python\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import Word2Vec\n",
        "\n",
        "# Создаем сессию Spark\n",
        "spark = SparkSession.builder.appName(\"Word2VecExample\").getOrCreate()\n",
        "\n",
        "# Загружаем данные\n",
        "data = spark.read.text(\"hdfs://path/to/corpus\")\n",
        "\n",
        "# Преобразуем данные в формат для Word2Vec\n",
        "documentDF = data.rdd.map(lambda row: row.value.split(\" \")).toDF([\"text\"])\n",
        "\n",
        "# Обучаем модель Word2Vec\n",
        "word2Vec = Word2Vec(vectorSize=100, minCount=0, inputCol=\"text\", outputCol=\"result\")\n",
        "model = word2Vec.fit(documentDF)\n",
        "\n",
        "# Преобразуем документы в векторы\n",
        "result = model.transform(documentDF)\n",
        "result.show()\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "fyPlk5JE_Tb3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Distributed Machine Learning\n",
        "\n",
        "Для обработки больших данных используются распределенные версии алгоритмов машинного обучения. Например, для обучения моделей Word2Vec и GloVe можно использовать их распределенные реализации.\n",
        "\n",
        "#### Распределенные версии Word2Vec и GloVe\n",
        "\n",
        "- **Distributed Word2Vec**: Обучение модели Word2Vec с использованием параллельных вычислений на нескольких узлах.\n",
        "- **Distributed GloVe**: Обучение модели GloVe на больших объемах данных с использованием распределенной среды.\n",
        "\n",
        "#### Пример использования распределенного Word2Vec\n",
        "\n",
        "В Apache Spark можно использовать распределенные вычисления для обучения модели Word2Vec на большом корпусе текстов.\n",
        "\n"
      ],
      "metadata": {
        "id": "ydDMFIbmPlR3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "from pyspark.ml.feature import Word2Vec\n",
        "\n",
        "# Настройки модели\n",
        "word2Vec = Word2Vec(vectorSize=100, minCount=0, inputCol=\"text\", outputCol=\"result\")\n",
        "\n",
        "# Обучение модели\n",
        "model = word2Vec.fit(documentDF)\n",
        "\n",
        "# Преобразование документов в векторы\n",
        "result = model.transform(documentDF)\n",
        "result.show()\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "fAgCCvTAP8E1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Пример использования распределенного GloVe\n",
        "\n",
        "GloVe может быть реализован в распределенной среде с использованием подходов, аналогичных тем, что используются в Word2Vec. Существуют специализированные библиотеки, такие как Spark GloVe, которые позволяют обучать GloVe на больших объемах данных.\n",
        "\n",
        "Таким образом, масштабируемый семантический анализ и поиск требуют использования эффективных алгоритмов и распределенных систем. Apache Spark и распределенные версии алгоритмов машинного обучения, таких как Word2Vec и GloVe, предоставляют мощные инструменты для обработки больших корпусов текстов. Использование параллельных вычислений и распределенных хранилищ данных позволяет значительно ускорить процесс и улучшить качество анализа.\n"
      ],
      "metadata": {
        "id": "JYOyR0YEPo8W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "su_U3Kh2_WD_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.3 Обработка больших данных**\n",
        "\n",
        "Для работы с большими корпусами текстов применяются следующие подходы:\n",
        "1. **MapReduce**: Парадигма для обработки больших данных, разделяющая задачи на подзадачи и выполняющая их параллельно.\n",
        "2. **Batch Processing и Stream Processing**: Batch Processing для анализа больших объемов данных за раз и Stream Processing для обработки данных в реальном времени.\n",
        "\n"
      ],
      "metadata": {
        "id": "ZixpQOK9_WHZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Семантические компоненты (темы) как признаки в конвейере NLP\n",
        "\n",
        "**4.1 Интеграция семантических компонентов**\n",
        "\n",
        "Векторные представления тем могут быть использованы в качестве признаков в различных NLP-задачах, таких как классификация текстов, кластеризация, распознавание сущностей и др.\n",
        "\n",
        "**4.2 Примеры применения**\n",
        "\n",
        "1. **Классификация текстов**: Использование векторов тем для обучения моделей классификации, например, для определения тематики документа.\n",
        "2. **Кластеризация документов**: Группировка документов по семантической схожести с использованием векторных представлений.\n",
        "\n"
      ],
      "metadata": {
        "id": "HpsBJNVv_Ytw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.3 Построение конвейеров NLP**\n",
        "\n",
        "1. **Feature Extraction**: Извлечение векторных признаков из текста.\n",
        "2. **Model Training**: Обучение моделей на основе этих признаков.\n",
        "3. **Model Evaluation**: Оценка качества моделей с использованием метрик, таких как точность, полнота и F-мера.\n",
        "\n"
      ],
      "metadata": {
        "id": "LLQvqMel_bGk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Ориентация в векторных пространствах высокой размерности\n",
        "\n",
        "**5.1 Высокая размерность и проблема курсовых**\n",
        "\n",
        "Проблема курсовых возникает при работе в пространствах высокой размерности, где расстояния между точками становятся менее информативными.\n",
        "\n",
        "**5.2 Методы уменьшения размерности**\n",
        "\n",
        "Для работы в высокоразмерных пространствах часто используются методы уменьшения размерности:\n",
        "1. **Principal Component Analysis (PCA)**: Преобразует данные в меньшее число измерений, сохраняя как можно больше вариации данных.\n",
        "2. **t-SNE**: Метод для визуализации высокоразмерных данных, сохраняющий локальную структуру данных.\n",
        "3. **UMAP**: Современный метод уменьшения размерности, который может быть более эффективным для некоторых задач, чем t-SNE.\n",
        "\n"
      ],
      "metadata": {
        "id": "imNbmyJf_dZ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "D0MTnh9P_fcL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5.3 Практическое применение**\n",
        "\n",
        "1. **Визуализация данных**: Использование методов уменьшения размерности для визуализации и анализа векторов слов и тем.\n",
        "2. **Повышение эффективности алгоритмов**: Уменьшение размерности для ускорения работы алгоритмов машинного обучения и снижения потребления памяти.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qwScX7cq_ffT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Таким, образом, семантический анализ и векторное представление слов и тем являются фундаментальными компонентами современных систем NLP. Они позволяют создавать мощные и масштабируемые решения для поиска и анализа текстов. Понимание этих методов и их правильное применение открывает широкие возможности для разработки инновационных приложений и сервисов в области обработки естественного языка."
      ],
      "metadata": {
        "id": "1CxB3IUf_kv6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Вопросы для закрепления темы"
      ],
      "metadata": {
        "id": "1WKCn0g1Slfz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Что такое семантический анализ и какова его основная цель?\n",
        "2. Объясните, что такое векторное представление слов (word embeddings) и его роль в семантическом анализе.\n",
        "3. Назовите и кратко опишите три основные модели для создания векторных представлений слов.\n",
        "4. Чем отличаются модели Word2Vec CBOW и Skip-Gram? Запишите их целевые функции.\n",
        "5. Выведите формулу для вычисления вероятности $P(w_{t+j} | w_t)$ в моделях CBOW и Skip-Gram.\n",
        "6. Как можно использовать векторные представления слов для поиска семантически близких слов? Опишите соответствующий алгоритм.\n",
        "7. Предложите способ визуализации высокомерных векторных пространств слов. Какую информацию можно из этого извлечь?\n",
        "8. Объясните, как можно применять векторные представления слов в задачах классификации текстов.\n",
        "9. Разработайте методику для оценки качества векторных представлений, полученных с помощью различных моделей.\n",
        "10. Опишите, как векторные представления слов могут использоваться для извлечения ключевых фраз из текстов.\n",
        "11. Как можно использовать векторные представления слов для улучшения качества машинного перевода?\n",
        "12. Объясните, как векторные представления слов могут применяться в системах вопросно-ответного диалога.\n",
        "13. Предложите алгоритм для автоматического определения тем в тексте на основе анализа векторных представлений слов.\n",
        "14. Как векторные представления слов могут использоваться для оценки сходства между текстами?\n",
        "15. Опишите, как можно построить семантические кластеры слов, используя их векторные представления.\n",
        "16. Объясните, как смещения (bias) в векторных представлениях слов могут быть выявлены и устранены.\n",
        "17. Как можно обогатить векторные представления слов с помощью внешних источников знаний, таких как словари и онтологии?\n",
        "18. Опишите, как векторные представления слов могут быть использованы для автоматического определения отношений между сущностями в тексте.\n",
        "19. Предложите способ использования векторных представлений слов для автоматического порождения вопросов.\n",
        "20. Объясните, как совместное обучение векторных представлений слов и их частей (морфем, префиксов, суффиксов) может улучшить качество семантического анализа.\n",
        "21. Как можно применить векторные представления слов для автоматической классификации текстов на основе их семантической близости?\n",
        "22. Опишите, как векторные представления слов могут использоваться для автоматического установления ссылок между текстами (text linking).\n",
        "23. Объясните роль семантического анализа в задачах обработки естественного языка. Приведите примеры.\n",
        "24. Сравните модели Word2Vec, GloVe и FastText. Какие преимущества и недостатки у каждой из них?\n",
        "25. Выведите формулу для вычисления скалярного произведения в моделях CBOW и Skip-Gram. Объясните, как она используется при обучении.\n",
        "26. Реализуйте простую версию модели CBOW на Python. Как можно обучить эту модель и проанализировать полученные векторные представления?\n",
        "27. Разработайте алгоритм для поиска семантически близких слов в векторном пространстве. Как можно применить его для расширения поисковых запросов?\n",
        "28. Предложите способ визуализации высокомерных векторных представлений слов. Какую информацию о семантике слов можно получить из такой визуализации?\n",
        "29. Опишите, как векторные представления слов могут использоваться в задачах классификации текстов. Приведите пример реализации.\n",
        "30. Объясните, как можно оценить качество векторных представлений, полученных с помощью различных моделей. Какие метрики можно использовать?"
      ],
      "metadata": {
        "id": "z_ZpJx4CUBLC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задачи для самостоятельной работы"
      ],
      "metadata": {
        "id": "W8JdniBpSJX7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Объясните основные принципы семантического анализа и векторного представления слов. Приведите примеры применения этих методов в реальных задачах обработки естественного языка.\n",
        "\n",
        "2. Опишите различия между моделями Word2Vec CBOW и Skip-Gram. Сформулируйте целевые функции для каждой из этих моделей и поясните их интуитивный смысл.\n",
        "\n",
        "3. Выведите формулы для вычисления вероятностей в моделях CBOW и Skip-Gram. Объясните, как эти вероятности используются для обучения векторных представлений слов.\n",
        "\n",
        "4. Реализуйте простую версию модели CBOW на Python, используя библиотеку NumPy. Обучите модель на небольшом корпусе текстов и проанализируйте полученные векторные представления.\n",
        "\n",
        "5. Сравните производительность моделей Word2Vec, GloVe и FastText на задаче аналогий слов. Объясните различия в подходах этих моделей к построению векторных представлений.\n",
        "\n",
        "6. Разработайте алгоритм для поиска семантически близких слов в векторном пространстве. Опишите, как можно использовать этот алгоритм для задачи расширения запросов в поисковых системах.\n",
        "\n",
        "7. Предложите способ визуализации векторных представлений слов высокой размерности. Объясните, какую информацию о семантике слов можно извлечь из такой визуализации.\n",
        "\n",
        "8. Опишите, как можно использовать векторные представления слов в задачах классификации текстов. Приведите пример реализации такого подхода.\n",
        "\n",
        "9. Разработайте методику для оценки качества векторных представлений, полученных различными моделями. Обсудите возможные метрики и способы их интерпретации.\n",
        "\n",
        "10. Объясните, как можно использовать векторные представления слов для решения задачи извлечения ключевых фраз из текстов. Предложите алгоритм, основанный на этом подходе.\n",
        "\n",
        "11. Рассмотрите применение векторных представлений слов в задаче машинного перевода. Объясните, как эта информация может быть использована для улучшения качества перевода.\n",
        "\n",
        "12. Опишите, как можно использовать векторные представления слов для построения систем вопросо-ответного диалога. Приведите пример реализации такой системы.\n",
        "\n",
        "13. Разработайте алгоритм для автоматического определения тем в тексте, основанный на анализе векторных представлений слов. Протестируйте его на наборе текстовых данных.\n",
        "\n",
        "14. Предложите способ использования векторных представлений слов для решения задачи автореферирования текстов. Объясните, как можно выделять наиболее важные предложения на основе семантической близости.\n",
        "\n",
        "15. Исследуйте, как можно применять векторные представления слов для задачи автоматической генерации текстов. Опишите, как эта информация может быть использована для улучшения качества генерируемых текстов.\n",
        "\n",
        "16. Проанализируйте, как можно использовать векторные представления слов для повышения точности задач распознавания именованных сущностей. Предложите алгоритм, основанный на этом подходе.\n",
        "\n",
        "17. Объясните, как можно применять векторные представления слов для решения задачи автоматического определения тональности текста (sentiment analysis). Приведите примеры реализации такого подхода.\n",
        "\n",
        "18. Разработайте модель для совместного обучения векторных представлений слов и предложений. Опишите, как можно использовать эти представления в задачах, таких как поиск релевантных документов.\n",
        "\n",
        "19. Исследуйте возможности использования векторных представлений слов для решения задачи автоматической классификации текстов по тематикам. Сравните различные подходы и оцените их эффективность.\n",
        "\n",
        "20. Предложите способ применения векторных представлений слов для решения задачи обнаружения ложной информации (fake news detection). Объясните, как семантическая информация может помочь в этой задаче.\n",
        "\n",
        "21. Опишите, как можно использовать векторные представления слов для решения задачи автоматического определения сходства между текстами. Приведите примеры практического применения такого подхода.\n",
        "\n",
        "22. Разработайте алгоритм для построения семантических кластеров слов, основываясь на их векторных представлениях. Объясните, как можно использовать эту информацию для задач обработки естественного языка.\n",
        "\n",
        "23. Исследуйте, как можно применять векторные представления слов для решения задачи машинного перевода с использованием нейронных сетей. Опишите, как семантическая информация может помочь в этом процессе.\n",
        "\n",
        "24. Предложите методику для анализа смещений (bias) в векторных представлениях слов. Объясните, как можно использовать эту информацию для выявления и устранения предвзятости в моделях обработки естественного языка.\n",
        "\n",
        "25. Разработайте алгоритм для обогащения векторных представлений слов с помощью внешних источников знаний, таких как словари и онтологии. Объясните, как это может повысить качество семантического анализа.\n",
        "\n",
        "26. Исследуйте применение векторных представлений слов в задаче автоматического определения отношений между сущностями в тексте. Опишите, как эта информация может быть использована для построения знаний.\n",
        "\n",
        "27. Предложите способ использования векторных представлений слов для решения задачи автоматического порождения вопросов. Объясните, как семантическая информация может помочь в этой задаче.\n",
        "\n",
        "28. Разработайте модель для совместного обучения векторных представлений слов и их частей (морфем, префиксов, суффиксов). Объясните, как это может улучшить качество семантического анализа, особенно для редко встречающихся слов.\n",
        "\n",
        "29. Исследуйте возможности использования векторных представлений слов для задачи автоматической классификации текстов на основе их семантической близости. Сравните этот подход с другими методами классификации.\n",
        "\n",
        "30. Предложите способ применения векторных представлений слов для решения задачи автоматического установления ссылок между текстами (text linking). Объясните, как семантическая информация может помочь в этой задаче."
      ],
      "metadata": {
        "id": "4MxmqQu8SPIp"
      }
    }
  ]
}