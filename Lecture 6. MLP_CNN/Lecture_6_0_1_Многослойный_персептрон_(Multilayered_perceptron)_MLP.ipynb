{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Lecture 6.0.1. Многослойный персептрон (Multilayered perceptron)-MLP"
      ],
      "metadata": {
        "id": "cI-VPMxZscqf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Персептрон (или многослойный персептрон) является одним из основных видов нейронных сетей, применяемых в задачах обработки естественного языка (NLP). В этой лекции мы подробно рассмотрим структуру персептрона, его применение в NLP, основные метрики оценки и примеры использования.\n",
        "\n",
        "### Часть 1: Основы персептрона\n",
        "\n",
        "#### 1.1. Определение персептрона\n",
        "\n",
        "Персептрон - это простейшая форма искусственной нейронной сети, состоящая из одного или нескольких слоев нейронов, в каждом из которых присутствуют активационные функции. Он используется для решения задач классификации и регрессии.\n",
        "\n",
        "#### 1.2. Структура персептрона\n",
        "\n",
        "Многослойный персептрон состоит из трех основных типов слоев:\n",
        "- **Входной слой**: принимает входные данные, представленные векторами признаков.\n",
        "- **Скрытые слои**: каждый слой содержит несколько нейронов, каждый из которых соединен с каждым нейроном предыдущего и следующего слоев.\n",
        "- **Выходной слой**: дает предсказания в виде вектора, который может интерпретироваться как вероятности классов или числовые значения.\n",
        "\n",
        "#### 1.3. Активационные функции\n",
        "\n",
        "Активационные функции определяют выход каждого нейрона в сети. Наиболее часто используемые функции в персептронах:\n",
        "- **Сигмоидальная функция**: $ \\sigma(z) = \\frac{1}{1 + e^{-z}} $\n",
        "- **Гиперболический тангенс**: $ \\tanh(z) = \\frac{e^z - e^{-z}}{e^z + e^{-z}} $\n",
        "- **ReLU (Rectified Linear Unit)**: $ \\text{ReLU}(z) = \\max(0, z) $\n",
        "\n",
        "#### 1.4. Обучение персептрона\n",
        "\n",
        "Обучение персептрона происходит методом стохастического градиентного спуска (SGD). Цель состоит в минимизации функции потерь, такой как кросс-энтропия для задач классификации или среднеквадратичная ошибка для задач регрессии.\n",
        "\n",
        "### Часть 2: Применение персептрона в NLP\n",
        "\n",
        "#### 2.1. Векторное представление текста\n",
        "\n",
        "Для использования персептрона в NLP текст преобразуется в векторное представление (например, методом мешка слов или эмбеддингами), который подается на входной слой.\n",
        "\n"
      ],
      "metadata": {
        "id": "qCMhW5TTsfXF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.2. Задачи в NLP\n",
        "\n",
        "- **Классификация текста**: Определение категории или класса текста (например, спам/не спам).\n",
        "- **Анализ тональности**: Определение эмоциональной окраски текста (позитивная/негативная).\n",
        "- **Машинный перевод**: Перевод текста с одного языка на другой.\n",
        "- **Генерация текста**: Создание новых текстовых данных на основе обучающего набора.\n",
        "\n",
        "### Часть 3: Метрики и оценки в NLP\n",
        "\n",
        "#### 3.1. Метрики качества\n",
        "\n",
        "- **Точность (Accuracy)**: $ \\frac{\\text{Количество правильных предсказаний}}{\\text{Общее количество предсказаний}} $\n",
        "- **Полнота (Recall)**: $ \\frac{\\text{TP}}{\\text{TP} + \\text{FN}} $\n",
        "- **Точность (Precision)**: $ \\frac{\\text{TP}}{\\text{TP} + \\text{FP}} $\n",
        "- **F-мера (F1-score)**: $ 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}} $\n",
        "\n",
        "#### 3.2. Оценки качества\n",
        "\n",
        "- **Кросс-валидация**: Метод оценки производительности модели, разделение данных на подмножества для обучения и тестирования.\n",
        "- **ROC-кривая и AUC-ROC**: Графическая кривая и площадь под ней для оценки классификаторов.\n",
        "- **Матрица ошибок (Confusion Matrix)**: Таблица, которая показывает количество верных и неверных предсказаний.\n",
        "\n",
        "\n",
        "\n",
        "### Тональность текста (Sentiment Analysis)\n",
        "\n",
        "**Определение:**\n",
        "Анализ тональности (или сентимент-анализ) — это процесс автоматического определения эмоциональной окраски текста. Цель состоит в том, чтобы выяснить, является ли текст позитивным, негативным или нейтральным.\n",
        "\n",
        "**Примеры задач:**\n",
        "- Определение настроения отзывов о продукции (положительный или отрицательный отзыв).\n",
        "- Анализ тональности комментариев в социальных сетях.\n",
        "- Изучение общественного мнения по поводу политических событий.\n",
        "\n",
        "**Примеры категорий:**\n",
        "- Позитивный\n",
        "- Негативный\n",
        "- Нейтральный\n",
        "- (Иногда добавляются более тонкие категории, такие как очень позитивный, немного негативный и т.д.)\n",
        "\n",
        "**Методы:**\n",
        "- Использование словарей тональности (наборы слов с заранее определенной эмоциональной окраской).\n",
        "- Модели машинного обучения и глубокого обучения, обученные на размеченных данных (например, MLP, RNN, LSTM, BERT).\n",
        "\n",
        "### Классификация текста (Text Classification)\n",
        "\n",
        "**Определение:**\n",
        "Классификация текста — это процесс назначения тексту одной или нескольких меток или категорий из заранее определенного набора. Это более общий термин, включающий в себя широкий спектр задач.\n",
        "\n",
        "**Примеры задач:**\n",
        "- Категоризация новостных статей по темам (спорт, политика, экономика).\n",
        "- Классификация писем электронной почты на спам и не-спам.\n",
        "- Определение жанра книг или фильмов по описанию.\n",
        "\n",
        "**Примеры категорий:**\n",
        "- Темы (например, спорт, политика, экономика)\n",
        "- Жанры (например, драма, комедия, триллер)\n",
        "- Классификация языка (например, английский, французский, китайский)\n",
        "\n",
        "**Методы:**\n",
        "- Классические алгоритмы машинного обучения (например, Naive Bayes, SVM, k-NN).\n",
        "- Модели глубокого обучения (например, CNN, RNN, трансформеры).\n",
        "- Эмбеддинги слов (например, Word2Vec, GloVe, BERT) для преобразования текста в числовые векторы.\n",
        "\n",
        "### Ключевые различия:\n",
        "\n",
        "1. **Цель:**\n",
        "   - **Тональность текста:** Определить эмоциональную окраску текста.\n",
        "   - **Классификация текста:** Присвоить тексту одну или несколько категорий из заранее определенного набора.\n",
        "\n",
        "2. **Типы категорий:**\n",
        "   - **Тональность текста:** Эмоциональные метки (позитивный, негативный, нейтральный).\n",
        "   - **Классификация текста:** Тематические или категориальные метки (спорт, политика, спам, не-спам).\n",
        "\n",
        "3. **Применение:**\n",
        "   - **Тональность текста:** Анализ отзывов, комментариев, мнений.\n",
        "   - **Классификация текста:** Организация и сортировка большого объема текстов по категориям, фильтрация спама, автоматическая рубрикация новостей.\n",
        "\n",
        "### Пример:\n",
        "\n",
        "Для наглядности приведем пример кода, показывающий разницу между сентимент-анализом и классификацией текста.\n",
        "\n",
        "#### Сентимент-анализ:"
      ],
      "metadata": {
        "id": "L2ISsrchtAOX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Пример сентимент-анализа с использованием библиотеки TextBlob\n",
        "from textblob import TextBlob\n",
        "\n",
        "text = \"Я очень доволен этим продуктом, он работает отлично!\"\n",
        "blob = TextBlob(text)\n",
        "sentiment = blob.sentiment.polarity\n",
        "\n",
        "if sentiment > 0:\n",
        "    print(\"Позитивный\")\n",
        "elif sentiment < 0:\n",
        "    print(\"Негативный\")\n",
        "else:\n",
        "    print(\"Нейтральный\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xY4yGYFiQpWl",
        "outputId": "2b80f010-20ae-4cdc-d86d-cc6142abecdc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Нейтральный\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Этот код демонстрирует простой пример использования библиотеки TextBlob для выполнения сентимент-анализа на русском тексте. TextBlob предоставляет предварительно обученные модели для анализа тональности текста на нескольких языках, включая русский.\n",
        "\n",
        "Данный пример может быть расширен для анализа более длинных текстов, а также интегрирован в более сложные приложения, требующие оценки эмоциональной окраски текстового контента."
      ],
      "metadata": {
        "id": "deMZDK-vRlrv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### Классификация текста:\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "v7kxv5oMQphg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Пример классификации текста с использованием библиотеки scikit-learn\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# Пример данных\n",
        "texts = [\"Футбольная команда победила в чемпионате\", \"Экономический кризис вызывает беспокойство\", \"Новый фильм оказался очень интересным\"]\n",
        "labels = [\"спорт\", \"экономика\", \"развлечение\"]\n",
        "\n",
        "# Создание и обучение модели\n",
        "model = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
        "model.fit(texts, labels)\n",
        "\n",
        "# Прогноз для нового текста\n",
        "new_text = \"Фондовый рынок падает второй день подряд\"\n",
        "predicted_label = model.predict([new_text])\n",
        "print(predicted_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0InnfWNvQwZd",
        "outputId": "cd159d20-e2b8-43cc-8c22-efdc1e5adb05"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['развлечение']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Этот код демонстрирует базовый пример использования scikit-learn для классификации текста с применением TF-IDF векторизации и наивного байесовского классификатора. Он может быть расширен и адаптирован для решения различных задач классификации текстовых данных."
      ],
      "metadata": {
        "id": "gakGkWexROfP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Эти примеры иллюстрируют, как можно применить методы сентимент-анализа и классификации текста для решения различных задач.\n"
      ],
      "metadata": {
        "id": "F-AGo0-pQwsN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Часть 4: Примеры использования персептрона в NLP\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Тональность текста и классификация текста — это два понятия в области обработки естественного языка (NLP), которые, хотя и имеют много общего, различаются по своим целям и методам применения.\n",
        "\n",
        "#### 4.1. Классификация текста\n",
        "\n",
        "Представим, что у нас есть задача классификации текста на позитивные и негативные отзывы. Мы можем использовать персептрон для обучения модели, которая будет предсказывать эмоциональную окраску текста на основе его содержания."
      ],
      "metadata": {
        "id": "QLkHGEYMQXaz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Пример.** Построить модель машинного обучения, способную классифицировать текстовые отзывы на фильмы как положительные или отрицательные, и оценить качество этой модели."
      ],
      "metadata": {
        "id": "sK9MVwNBHUlQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Более крупный и сбалансированный пример данных\n",
        "corpus = [\n",
        "    \"Этот фильм ужасен, я не смог досмотреть до конца\",\n",
        "    \"Отличный сюжет и интересные персонажи, рекомендую всем!\",\n",
        "    \"Ничего особенного, средний фильм без изюминки\",\n",
        "    \"Великолепный фильм, он меня вдохновил и покорил\",\n",
        "    \"Не понравилось, персонажи были плоскими и сюжет был предсказуем\",\n",
        "    \"Прекрасный фильм, замечательная игра актеров\",\n",
        "    \"Этот фильм был настоящим разочарованием, ожидал большего\",\n",
        "    \"Фильм захватывает с первых минут и держит в напряжении до конца\",\n",
        "    \"Ужасный сценарий и отвратительная игра актеров\",\n",
        "    \"Отличная режиссура и великолепные спецэффекты\",\n",
        "    \"Не стоит своих денег, слишком много клише и предсказуемых моментов\",\n",
        "    \"Смотрел с удовольствием, отличный семейный фильм\"\n",
        "]\n",
        "labels = [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]\n",
        "\n",
        "# Инициализация векторизатора TF-IDF\n",
        "vectorizer = TfidfVectorizer(max_features=1000, lowercase=True, analyzer='word', stop_words='english')\n",
        "\n",
        "# Преобразование текстов в TF-IDF признаки\n",
        "X = vectorizer.fit_transform(corpus).toarray()\n",
        "y = np.array(labels)\n",
        "\n",
        "# Разделение данных на обучающую и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Инициализация MLP классификатора\n",
        "mlp_classifier = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42, solver='adam', learning_rate_init=0.001)\n",
        "\n",
        "# Обучение модели\n",
        "mlp_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Предсказание на тестовой выборке\n",
        "y_pred = mlp_classifier.predict(X_test)\n",
        "\n",
        "# Оценка качества модели\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Вывод отчета по классификации (precision, recall, f1-score и support)\n",
        "print(classification_report(y_test, y_pred, target_names=['Отрицательный', 'Положительный']))\n",
        "\n",
        "# Предсказание на новых данных\n",
        "new_reviews = [\n",
        "    \"Отличный фильм! Очень трогательная история, рекомендую всем!\",\n",
        "    \"Самый ужасный фильм, который я когда-либо видел. Потраченное время и деньги.\"\n",
        "]\n",
        "\n",
        "# Преобразование новых отзывов в TF-IDF признаки с использованием ранее инициализированного векторизатора\n",
        "X_new = vectorizer.transform(new_reviews).toarray()\n",
        "\n",
        "# Предсказание сентимента с использованием обученной модели MLP\n",
        "predictions = mlp_classifier.predict(X_new)\n",
        "\n",
        "# Вывод результатов предсказания\n",
        "for review, prediction in zip(new_reviews, predictions):\n",
        "    sentiment = \"Положительный\" if prediction == 1 else \"Отрицательный\"\n",
        "    print(f\"Текст отзыва: {review}\")\n",
        "    print(f\"Прогноз сентимента: {sentiment}\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHgdD3YyHU-r",
        "outputId": "30d6b8e7-7184-49a3-df7a-ff6d442ed861"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.67\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "Отрицательный       1.00      0.50      0.67         2\n",
            "Положительный       0.50      1.00      0.67         1\n",
            "\n",
            "     accuracy                           0.67         3\n",
            "    macro avg       0.75      0.75      0.67         3\n",
            " weighted avg       0.83      0.67      0.67         3\n",
            "\n",
            "Текст отзыва: Отличный фильм! Очень трогательная история, рекомендую всем!\n",
            "Прогноз сентимента: Положительный\n",
            "\n",
            "Текст отзыва: Самый ужасный фильм, который я когда-либо видел. Потраченное время и деньги.\n",
            "Прогноз сентимента: Отрицательный\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Анализ и улучшение модели\n",
        "\n",
        "Модель показывает точность 67%, что не является высоким показателем. Несмотря на то, что новый отзыв классифицирован верно, есть возможности для дальнейшего улучшения модели.\n",
        "\n",
        "### Возможные улучшения\n",
        "\n",
        "1. **Увеличение объема данных:**\n",
        "   - Большее количество данных позволяет модели лучше понять закономерности в текстах.\n",
        "\n",
        "2. **Более сложные методы векторизации:**\n",
        "   - Использование методов вроде Word2Vec, GloVe или BERT может улучшить представление текста.\n",
        "\n",
        "3. **Тонкая настройка модели:**\n",
        "   - Настройка гиперпараметров модели, таких как количество слоев, количество нейронов, функция активации и алгоритм оптимизации.\n",
        "\n",
        "4. **Учет дополнительных факторов:**\n",
        "   - Включение в модель информации о частоте слов, биграммах, триграммах и т.д.\n"
      ],
      "metadata": {
        "id": "EwY7Ig8DJN8q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "#### 4.2. Анализ тональности\n",
        "\n",
        "Допустим, мы хотим разработать систему, которая автоматически анализирует тональность новостных статей. Мы можем использовать многослойный персептрон для создания классификатора, который будет определять, является ли текст статьи позитивным, негативным или нейтральным."
      ],
      "metadata": {
        "id": "Jc8WmegGtHWl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Программа для анализа тональности новостных статей\n",
        "\n",
        "Для создания системы анализа тональности новостных статей с использованием многослойного персептрона (MLP) можно использовать `scikit-learn` для обучения модели и предобученные эмбеддинги Word2Vec для представления текстов. В данном примере мы будем классифицировать статьи как позитивные, негативные или нейтральные.\n",
        "\n",
        "### Шаги:\n",
        "1. **Сбор и подготовка данных.**\n",
        "2. **Преобразование текстов в эмбеддинги Word2Vec.**\n",
        "3. **Обучение модели MLP.**\n",
        "4. **Оценка модели.**\n",
        "5. **Предсказание на новых данных.**\n",
        "\n",
        "### Пример реализации:\n",
        "\n",
        "#### 1. Подготовка данных:\n",
        "\n",
        "Для простоты предположим, что у нас есть небольшие наборы данных для каждой категории тональности.\n"
      ],
      "metadata": {
        "id": "a6Ba4w7bJtCN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Пример.** Построить модели машинного обучения, которая сможет эффективно классифицировать текстовые данные по трем категориям тональности - негативной, позитивной и нейтральной, и продемонстрировать хорошее качество классификации на тестовых данных. Кроме того, модель должна быть применима для предсказания тональности новых текстовых документов."
      ],
      "metadata": {
        "id": "4LsBVYdJMyMu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from gensim.models import Word2Vec\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "\n",
        "# Дополнительные данные для гарантии присутствия всех классов\n",
        "corpus = [\n",
        "    \"Экономика страны растет, инвестиции увеличиваются\",  # Позитивный\n",
        "    \"Произошла катастрофа, много пострадавших\",  # Негативный\n",
        "    \"Политическая ситуация стабильна\",  # Нейтральный\n",
        "    \"Компании сообщают о рекордной прибыли\",  # Позитивный\n",
        "    \"Новый закон вызвал волну протестов\",  # Негативный\n",
        "    \"Погода сегодня будет солнечной и теплой\",  # Нейтральный\n",
        "    \"Экономический кризис вызывает беспокойство у граждан\",  # Негативный\n",
        "    \"Ведущие эксперты прогнозируют улучшение рынка труда\",  # Позитивный\n",
        "    \"Произошел террористический акт в центре города\",  # Негативный\n",
        "    \"Выборы прошли спокойно, без серьезных нарушений\",  # Нейтральный\n",
        "    \"Новая волна пандемии вызывает опасения у населения\",  # Негативный\n",
        "    \"Рынок акций достиг исторического максимума\",  # Позитивный\n",
        "    \"Спортивные события будут проходить без зрителей\",  # Нейтральный\n",
        "    \"Научные достижения вызывают оптимизм\",  # Позитивный\n",
        "    \"Негативное влияние изменений климата\"  # Негативный\n",
        "]\n",
        "labels = [1, 0, 2, 1, 0, 2, 0, 1, 0, 2, 0, 1, 2, 1, 0]  # 0 - Негативный, 1 - Позитивный, 2 - Нейтральный\n",
        "\n",
        "# Токенизация текстов\n",
        "nltk.download('punkt')\n",
        "tokenized_corpus = [word_tokenize(review.lower()) for review in corpus]\n",
        "\n",
        "# Обучение Word2Vec на корпусе\n",
        "word2vec_model = Word2Vec(tokenized_corpus, vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "def get_average_word2vec(tokens_list, vector, k=100):\n",
        "    \"\"\"\n",
        "    Получение среднего вектора Word2Vec для списка токенов.\n",
        "    \"\"\"\n",
        "    if len(tokens_list) < 1:\n",
        "        return np.zeros(k)\n",
        "    vectorized = [vector[word] if word in vector else np.zeros(k) for word in tokens_list]\n",
        "    mean = np.mean(vectorized, axis=0)\n",
        "    return mean\n",
        "\n",
        "# Преобразование данных с использованием Word2Vec\n",
        "X = np.array([get_average_word2vec(tokens, word2vec_model.wv) for tokens in tokenized_corpus])\n",
        "y = np.array(labels)\n",
        "\n",
        "# Разделение данных на обучающую и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Проверка наличия всех классов в обучающей выборке\n",
        "print(\"Уникальные классы в обучающей выборке:\", np.unique(y_train))\n",
        "print(\"Уникальные классы в тестовой выборке:\", np.unique(y_test))\n",
        "\n",
        "# Инициализация MLP классификатора\n",
        "mlp_classifier = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42, solver='adam', learning_rate_init=0.001)\n",
        "\n",
        "# Обучение модели\n",
        "mlp_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Предсказание на тестовой выборке\n",
        "y_pred = mlp_classifier.predict(X_test)\n",
        "\n",
        "# Оценка качества модели\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Вывод отчета по классификации (precision, recall, f1-score и support)\n",
        "print(classification_report(y_test, y_pred, target_names=['Негативный', 'Позитивный', 'Нейтральный']))\n",
        "\n",
        "# Предсказание на новых данных\n",
        "new_articles = [\n",
        "    \"Новая волна пандемии вызывает опасения у населения\",\n",
        "    \"Рынок акций достиг исторического максимума\",\n",
        "    \"Спортивные события будут проходить без зрителей\"\n",
        "]\n",
        "\n",
        "# Токенизация новых статей\n",
        "tokenized_new_articles = [word_tokenize(article.lower()) for article in new_articles]\n",
        "X_new = np.array([get_average_word2vec(tokens, word2vec_model.wv) for tokens in tokenized_new_articles])\n",
        "\n",
        "# Предсказание тональности с использованием обученной модели MLP\n",
        "predictions = mlp_classifier.predict(X_new)\n",
        "\n",
        "# Вывод результатов предсказания\n",
        "for article, prediction in zip(new_articles, predictions):\n",
        "    sentiment = [\"Негативный\", \"Позитивный\", \"Нейтральный\"][prediction]\n",
        "    print(f\"Текст статьи: {article}\")\n",
        "    print(f\"Прогноз тональности: {sentiment}\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2WS0yuiJyHw",
        "outputId": "793df2bb-e4c1-482e-d2f6-9ec2703fe343"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Уникальные классы в обучающей выборке: [0 1 2]\n",
            "Уникальные классы в тестовой выборке: [0 1 2]\n",
            "Accuracy: 0.67\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Негативный       1.00      1.00      1.00         1\n",
            "  Позитивный       0.50      1.00      0.67         1\n",
            " Нейтральный       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.67         3\n",
            "   macro avg       0.50      0.67      0.56         3\n",
            "weighted avg       0.50      0.67      0.56         3\n",
            "\n",
            "Текст статьи: Новая волна пандемии вызывает опасения у населения\n",
            "Прогноз тональности: Негативный\n",
            "\n",
            "Текст статьи: Рынок акций достиг исторического максимума\n",
            "Прогноз тональности: Позитивный\n",
            "\n",
            "Текст статьи: Спортивные события будут проходить без зрителей\n",
            "Прогноз тональности: Нейтральный\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ]
}