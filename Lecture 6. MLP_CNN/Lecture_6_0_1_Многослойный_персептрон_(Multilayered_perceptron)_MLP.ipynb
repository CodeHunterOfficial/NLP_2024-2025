{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CodeHunterOfficial/NLP_2024-2025/blob/main/Lecture%206.%20MLP_CNN/Lecture_6_0_1_%D0%9C%D0%BD%D0%BE%D0%B3%D0%BE%D1%81%D0%BB%D0%BE%D0%B9%D0%BD%D1%8B%D0%B9_%D0%BF%D0%B5%D1%80%D1%81%D0%B5%D0%BF%D1%82%D1%80%D0%BE%D0%BD_(Multilayered_perceptron)_MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lecture 6.0.1. Многослойный персептрон (Multilayered perceptron)-MLP"
      ],
      "metadata": {
        "id": "cI-VPMxZscqf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Часть 1: Основы   MLP\n",
        "### 1. Введение\n",
        "\n",
        "Многослойная нейронная сеть (MLP) представляет собой модель машинного обучения, состоящую из нескольких слоев нейронов, включая входной слой, скрытые слои и выходной слой. Эти сети способны обучаться сложным нелинейным зависимостям в данных и широко применяются в задачах классификации, регрессии и других областях.\n",
        "\n",
        "### 2. Архитектура многослойной нейронной сети\n",
        "\n",
        "Архитектура MLP состоит из нескольких основных компонентов:\n",
        "\n",
        "- **Входной слой**: принимает входные данные, представленные вектором признаков.\n",
        "- **Скрытые слои**: один или несколько слоев, каждый из которых состоит из нескольких нейронов. Каждый нейрон в слое связан с каждым нейроном предыдущего и следующего слоев.\n",
        "- **Выходной слой**: генерирует предсказания или выводы модели.\n",
        "\n",
        "### 3. Функции активации\n",
        "\n",
        "Функции активации определяют выход нейрона в зависимости от его входа. Некоторые из популярных функций активации включают:\n",
        "\n",
        "- **Сигмоидальная функция**: $ \\sigma(z) = \\frac{1}{1 + e^{-z}} $\n",
        "- **Гиперболический тангенс**: $ \\tanh(z) = \\frac{e^z - e^{-z}}{e^z + e^{-z}} $\n",
        "- **ReLU (Rectified Linear Unit)**: $ \\text{ReLU}(z) = \\max(0, z) $\n",
        "- **Softmax**: для выходного слоя в задачах классификации, где требуется вероятностное распределение по классам.\n",
        "\n",
        "### 4. Функция потерь\n",
        "\n",
        "Функция потерь (loss function) оценивает, насколько хорошо модель предсказывает целевую переменную в обучающих данных. Некоторые типичные функции потерь включают:\n",
        "\n",
        "- **Среднеквадратичная ошибка (MSE)**: $ \\text{MSE} = \\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\hat{y}_i)^2 $\n",
        "- **Перекрёстная энтропия (Cross-Entropy)**: $ \\text{CrossEntropy} = -\\sum_{i=1}^{N} y_i \\log(\\hat{y}_i) $, где $ y_i $ - это истинная метка, а $ \\hat{y}_i $ - предсказание модели.\n",
        "\n",
        "### 5. Процесс обучения\n",
        "\n",
        "#### Прямой проход (Forward Pass)\n",
        "\n",
        "Процесс, при котором входные данные проходят через сеть для вычисления предсказаний:\n",
        "\n",
        "1. Входные данные подаются на входной слой.\n",
        "2. Для каждого скрытого слоя и выходного слоя вычисляются взвешенные суммы входов с последующим применением функции активации.\n",
        "\n",
        "Для скрытого слоя $ l $ и нейрона $ j $:\n",
        "\n",
        "$$ z_j^{(l)} = \\sum_{k=1}^{n^{(l-1)}} w_{jk}^{(l)} a_k^{(l-1)} + b_j^{(l)} $$\n",
        "\n",
        "$$ a_j^{(l)} = \\sigma(z_j^{(l)}) $$\n",
        "\n",
        "где $ w_{jk}^{(l)} $ - вес между нейронами $ k $-го слоя и $ j $-го слоя, $ b_j^{(l)} $ - смещение (bias) для нейрона $ j $-го слоя.\n",
        "\n",
        "#### Обратное распространение (Backpropagation)\n",
        "\n",
        "Процесс, при котором вычисляются градиенты функции потерь по всем параметрам сети с целью обновления их значений:\n",
        "\n",
        "1. Вычисление ошибки на выходе сети и градиентов по последнему слою.\n",
        "2. Распространение этих градиентов назад через сеть с использованием правила цепи (chain rule).\n",
        "\n",
        "Для выходного слоя:\n",
        "\n",
        "$$ \\delta_j^{(L)} = \\frac{\\partial \\mathcal{L}}{\\partial z_j^{(L)}} $$\n",
        "\n",
        "Для скрытых слоев:\n",
        "\n",
        "$$ \\delta_j^{(l)} = \\sigma'(z_j^{(l)}) \\sum_{k} w_{kj}^{(l+1)} \\delta_k^{(l+1)} $$\n",
        "\n",
        "где $ \\sigma' $ - производная функции активации, $ \\mathcal{L} $ - функция потерь.\n",
        "\n",
        "#### Обновление весов и смещений\n",
        "\n",
        "После вычисления градиентов веса и смещения обновляются с использованием градиентного спуска или его вариаций:\n",
        "\n",
        "$$ w_{jk}^{(l)} \\leftarrow w_{jk}^{(l)} - \\eta \\frac{\\partial \\mathcal{L}}{\\partial w_{jk}^{(l)}} $$\n",
        "\n",
        "$$ b_j^{(l)} \\leftarrow b_j^{(l)} - \\eta \\frac{\\partial \\mathcal{L}}{\\partial b_j^{(l)}} $$\n",
        "\n",
        "где $ \\eta $ - скорость обучения (learning rate).\n",
        "\n",
        "### 6. Метрики оценки и оценки качества модели\n",
        "\n",
        "После обучения модели её качество оценивается с использованием различных метрик, таких как:\n",
        "\n",
        "- **Точность (Accuracy)**: доля правильных предсказаний.\n",
        "- **Полнота (Recall)** и **Точность (Precision)**: для задач классификации.\n",
        "- **Среднеквадратичная ошибка (MSE)** и **Средняя абсолютная ошибка (MAE)**: для задач регрессии.\n",
        "\n",
        "##### Примеры\n",
        "\n",
        "1. Задачи XOR"
      ],
      "metadata": {
        "id": "qCMhW5TTsfXF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Определение нейронной сети\n",
        "class XORMLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(XORMLP, self).__init__()\n",
        "        self.hidden_layer = nn.Linear(2, 2)  # Входной размер 2 (для двух входов), выходной размер 2\n",
        "        self.activation = nn.ReLU()  # Функция активации ReLU\n",
        "        self.output_layer = nn.Linear(2, 1)  # Входной размер 2 (от скрытого слоя), выходной размер 1 (для одного выхода)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.activation(self.hidden_layer(x))\n",
        "        x = torch.sigmoid(self.output_layer(x))  # Используем сигмоиду для получения вероятности (бинарная классификация)\n",
        "        return x\n",
        "\n",
        "# Обучение модели\n",
        "def train(model, criterion, optimizer, inputs, labels, epochs):\n",
        "    for epoch in range(epochs):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if epoch % 1000 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Подготовка данных для XOR\n",
        "inputs = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\n",
        "labels = torch.tensor([[0], [1], [1], [0]], dtype=torch.float32)\n",
        "\n",
        "# Создание модели, выбор функции потерь и оптимизатора\n",
        "model = XORMLP()\n",
        "criterion = nn.BCELoss()  # Бинарная кросс-энтропия для бинарной классификации\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)  # Стохастический градиентный спуск\n",
        "\n",
        "# Обучение модели\n",
        "train(model, criterion, optimizer, inputs, labels, epochs=10000)\n",
        "\n",
        "# Проверка результатов на обучающих данных\n",
        "print(\"Проверка на обучающих данных:\")\n",
        "with torch.no_grad():\n",
        "    outputs = model(inputs)\n",
        "    predicted = (outputs > 0.5).float()  # Преобразуем вероятности в бинарные предсказания\n",
        "    print(f'Predicted: {predicted.squeeze()}')\n",
        "    print(f'Ground truth: {labels.squeeze()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LucsFpI05KE",
        "outputId": "f395a3cb-c5b2-49cd-befe-c7e3308ab223"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10000], Loss: 0.6943\n",
            "Epoch [1001/10000], Loss: 0.0541\n",
            "Epoch [2001/10000], Loss: 0.0163\n",
            "Epoch [3001/10000], Loss: 0.0091\n",
            "Epoch [4001/10000], Loss: 0.0062\n",
            "Epoch [5001/10000], Loss: 0.0046\n",
            "Epoch [6001/10000], Loss: 0.0037\n",
            "Epoch [7001/10000], Loss: 0.0030\n",
            "Epoch [8001/10000], Loss: 0.0026\n",
            "Epoch [9001/10000], Loss: 0.0023\n",
            "Проверка на обучающих данных:\n",
            "Predicted: tensor([0., 1., 1., 0.])\n",
            "Ground truth: tensor([0., 1., 1., 0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Подготовка новых тестовых данных\n",
        "new_data = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\n",
        "\n",
        "# Проверка результатов на новых данных\n",
        "print(\"\\nПроверка на новых данных:\")\n",
        "with torch.no_grad():\n",
        "    outputs = model(new_data)\n",
        "    predicted = (outputs > 0.5).float()  # Преобразуем вероятности в бинарные предсказания\n",
        "    print(f'Predicted: {predicted.squeeze()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKt4BXNM7xLA",
        "outputId": "59258df4-2aca-4f8e-be43-cbd63facbc2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Проверка на новых данных:\n",
            "Predicted: tensor([0., 1., 1., 0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.Таблица умножение"
      ],
      "metadata": {
        "id": "wjrRYKpe05ml"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для построения многослойной персептрона (MLP) для задачи таблицы умножения, нам нужно создать модель, которая может изучить зависимости между двумя входными числами (множителями) и предсказывать их произведение (результат умножения). В этом случае входом будут два числа, а выходом — одно число (результат умножения).\n",
        "\n",
        "Вот пример реализации MLP на Python с использованием библиотеки PyTorch:"
      ],
      "metadata": {
        "id": "bkEMUOD29DUD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "# Гиперпараметры\n",
        "input_size = 2  # размер входа (два числа)\n",
        "hidden_size = 10  # размер скрытого слоя\n",
        "output_size = 1  # размер выхода (одно число, результат умножения)\n",
        "\n",
        "learning_rate = 0.001\n",
        "num_epochs = 10000\n",
        "\n",
        "# Генерация данных для обучения\n",
        "def generate_data(num_samples):\n",
        "    X = []\n",
        "    y = []\n",
        "    for _ in range(num_samples):\n",
        "        a = np.random.randint(1, 10)  # первое число от 1 до 9\n",
        "        b = np.random.randint(1, 10)  # второе число от 1 до 9\n",
        "        X.append([a, b])\n",
        "        y.append([a * b])\n",
        "    return torch.tensor(X, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)\n",
        "\n",
        "# Модель MLP\n",
        "class Multiplier(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(Multiplier, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "\n",
        "# Инициализация модели, функции потерь и оптимизатора\n",
        "model = Multiplier(input_size, hidden_size, output_size)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Обучение модели\n",
        "for epoch in range(num_epochs):\n",
        "    inputs, labels = generate_data(100)  # генерируем 100 случайных примеров каждую эпоху\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch+1) % 1000 == 0:\n",
        "        print(f'Эпоха [{epoch+1}/{num_epochs}], Потери: {loss.item():.4f}')\n",
        "\n",
        "# Пример использования обученной модели\n",
        "model.eval()\n",
        "test_input = torch.tensor([[3, 5]], dtype=torch.float32)  # пример ввода для теста\n",
        "predicted_output = model(test_input)\n",
        "print(f'Предсказанный результат для 3 * 5: {predicted_output.item():.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOpLozpeBRji",
        "outputId": "fde47cb6-db6a-4645-ebae-c920187705bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпоха [1000/10000], Потери: 104.4529\n",
            "Эпоха [2000/10000], Потери: 56.3865\n",
            "Эпоха [3000/10000], Потери: 20.4014\n",
            "Эпоха [4000/10000], Потери: 13.3665\n",
            "Эпоха [5000/10000], Потери: 12.6987\n",
            "Эпоха [6000/10000], Потери: 8.7133\n",
            "Эпоха [7000/10000], Потери: 8.1359\n",
            "Эпоха [8000/10000], Потери: 5.7436\n",
            "Эпоха [9000/10000], Потери: 3.6076\n",
            "Эпоха [10000/10000], Потери: 1.3334\n",
            "Предсказанный результат для 3 * 5: 14.88\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Пример использования обученной модели\n",
        "model.eval()\n",
        "# Подготовка новых тестовых данных\n",
        "test_input = torch.tensor([[2, 5], [7, 3], [4, 8]], dtype=torch.float32)\n",
        "\n",
        "# Проверка результатов на новых данных\n",
        "print(\"\\nПроверка на новых данных:\")\n",
        "with torch.no_grad():\n",
        "    for input_data in test_input:\n",
        "        predicted_label = model(input_data.unsqueeze(0)).item()\n",
        "        print(f'Input: {input_data}, Predicted Label: {predicted_label:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eI2yNlLaCKFX",
        "outputId": "7b7521ad-b711-4351-a59d-63c25880b78d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Проверка на новых данных:\n",
            "Input: tensor([2., 5.]), Predicted Label: 9.40\n",
            "Input: tensor([7., 3.]), Predicted Label: 20.52\n",
            "Input: tensor([4., 8.]), Predicted Label: 31.82\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Часть 2: Применение персептрона в NLP\n",
        "\n",
        "#### 2.1. Векторное представление текста\n",
        "\n",
        "Для использования персептрона в NLP текст преобразуется в векторное представление (например, методом мешка слов или эмбеддингами), который подается на входной слой.\n",
        "\n",
        "\n",
        "\n",
        "#### 2.2. Задачи в NLP\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "####  Классификация текстов\n",
        "\n",
        "Одним из основных применений персептрона в NLP является классификация текстов. Здесь персептрон может использоваться для определения категории или класса текста на основе его содержания.\n",
        "\n",
        "**Пример**: Классификация отзывов на фильмы на положительные и отрицательные.\n",
        "\n",
        "####  Анализ тональности текстов\n",
        "\n",
        "Персептрон может быть использован для определения эмоциональной окраски текста (положительная, отрицательная или нейтральная).\n",
        "\n",
        "**Пример**: Определение тональности твитов (позитивная, негативная или нейтральная).\n",
        "\n",
        "####  Идентификация именованных сущностей (NER)\n",
        "\n",
        "Персептрон может быть применен для задачи распознавания именованных сущностей в текстах, таких как имена людей, мест, организаций и т.д.\n",
        "\n",
        "**Пример**: Извлечение имен людей и названий компаний из новостных статей.\n",
        "\n",
        "#### Разрешение синонимии и антонимии\n",
        "\n",
        "В задачах обработки естественного языка персептрон может быть использован для определения, являются ли два слова синонимами или антонимами.\n",
        "\n",
        "**Пример**: Определение, являются ли слова \"большой\" и \"огромный\" синонимами.\n",
        "\n",
        "\n",
        "\n",
        "### Часть 3: Метрики и оценки в NLP\n",
        "\n",
        "#### 3.1. Метрики качества\n",
        "\n",
        "- **Точность (Accuracy)**: $ \\frac{\\text{Количество правильных предсказаний}}{\\text{Общее количество предсказаний}} $\n",
        "- **Полнота (Recall)**: $ \\frac{\\text{TP}}{\\text{TP} + \\text{FN}} $\n",
        "- **Точность (Precision)**: $ \\frac{\\text{TP}}{\\text{TP} + \\text{FP}} $\n",
        "- **F-мера (F1-score)**: $ 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}} $\n",
        "\n",
        "#### 3.2. Оценки качества\n",
        "\n",
        "- **Кросс-валидация**: Метод оценки производительности модели, разделение данных на подмножества для обучения и тестирования.\n",
        "- **ROC-кривая и AUC-ROC**: Графическая кривая и площадь под ней для оценки классификаторов.\n",
        "- **Матрица ошибок (Confusion Matrix)**: Таблица, которая показывает количество верных и неверных предсказаний.\n",
        "\n",
        "\n",
        "\n",
        "### Тональность текста (Sentiment Analysis)\n",
        "\n",
        "**Определение:**\n",
        "Анализ тональности (или сентимент-анализ) — это процесс автоматического определения эмоциональной окраски текста. Цель состоит в том, чтобы выяснить, является ли текст позитивным, негативным или нейтральным.\n",
        "\n",
        "**Примеры задач:**\n",
        "- Определение настроения отзывов о продукции (положительный или отрицательный отзыв).\n",
        "- Анализ тональности комментариев в социальных сетях.\n",
        "- Изучение общественного мнения по поводу политических событий.\n",
        "\n",
        "**Примеры категорий:**\n",
        "- Позитивный\n",
        "- Негативный\n",
        "- Нейтральный\n",
        "- (Иногда добавляются более тонкие категории, такие как очень позитивный, немного негативный и т.д.)\n",
        "\n",
        "**Методы:**\n",
        "- Использование словарей тональности (наборы слов с заранее определенной эмоциональной окраской).\n",
        "- Модели машинного обучения и глубокого обучения, обученные на размеченных данных (например, MLP, RNN, LSTM, BERT).\n",
        "\n",
        "### Классификация текста (Text Classification)\n",
        "\n",
        "**Определение:**\n",
        "Классификация текста — это процесс назначения тексту одной или нескольких меток или категорий из заранее определенного набора. Это более общий термин, включающий в себя широкий спектр задач.\n",
        "\n",
        "**Примеры задач:**\n",
        "- Категоризация новостных статей по темам (спорт, политика, экономика).\n",
        "- Классификация писем электронной почты на спам и не-спам.\n",
        "- Определение жанра книг или фильмов по описанию.\n",
        "\n",
        "**Примеры категорий:**\n",
        "- Темы (например, спорт, политика, экономика)\n",
        "- Жанры (например, драма, комедия, триллер)\n",
        "- Классификация языка (например, английский, французский, китайский)\n",
        "\n",
        "**Методы:**\n",
        "- Классические алгоритмы машинного обучения (например, Naive Bayes, SVM, k-NN).\n",
        "- Модели глубокого обучения (например, CNN, RNN, трансформеры).\n",
        "- Эмбеддинги слов (например, Word2Vec, GloVe, BERT) для преобразования текста в числовые векторы.\n",
        "\n",
        "### Ключевые различия:\n",
        "\n",
        "1. **Цель:**\n",
        "   - **Тональность текста:** Определить эмоциональную окраску текста.\n",
        "   - **Классификация текста:** Присвоить тексту одну или несколько категорий из заранее определенного набора.\n",
        "\n",
        "2. **Типы категорий:**\n",
        "   - **Тональность текста:** Эмоциональные метки (позитивный, негативный, нейтральный).\n",
        "   - **Классификация текста:** Тематические или категориальные метки (спорт, политика, спам, не-спам).\n",
        "\n",
        "3. **Применение:**\n",
        "   - **Тональность текста:** Анализ отзывов, комментариев, мнений.\n",
        "   - **Классификация текста:** Организация и сортировка большого объема текстов по категориям, фильтрация спама, автоматическая рубрикация новостей.\n",
        "\n",
        "### Пример:\n",
        "\n",
        "Для наглядности приведем пример кода, показывающий разницу между сентимент-анализом и классификацией текста.\n",
        "\n",
        "#### Сентимент-анализ:"
      ],
      "metadata": {
        "id": "L2ISsrchtAOX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Пример сентимент-анализа с использованием библиотеки TextBlob\n",
        "from textblob import TextBlob\n",
        "\n",
        "text = \"Я очень доволен этим продуктом, он работает отлично!\"\n",
        "blob = TextBlob(text)\n",
        "sentiment = blob.sentiment.polarity\n",
        "\n",
        "if sentiment > 0:\n",
        "    print(\"Позитивный\")\n",
        "elif sentiment < 0:\n",
        "    print(\"Негативный\")\n",
        "else:\n",
        "    print(\"Нейтральный\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xY4yGYFiQpWl",
        "outputId": "2b80f010-20ae-4cdc-d86d-cc6142abecdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Нейтральный\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Этот код демонстрирует простой пример использования библиотеки TextBlob для выполнения сентимент-анализа на русском тексте. TextBlob предоставляет предварительно обученные модели для анализа тональности текста на нескольких языках, включая русский.\n",
        "\n",
        "Данный пример может быть расширен для анализа более длинных текстов, а также интегрирован в более сложные приложения, требующие оценки эмоциональной окраски текстового контента."
      ],
      "metadata": {
        "id": "deMZDK-vRlrv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### Классификация текста:\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "v7kxv5oMQphg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Пример классификации текста с использованием библиотеки scikit-learn\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# Пример данных\n",
        "texts = [\"Футбольная команда победила в чемпионате\", \"Экономический кризис вызывает беспокойство\", \"Новый фильм оказался очень интересным\"]\n",
        "labels = [\"спорт\", \"экономика\", \"развлечение\"]\n",
        "\n",
        "# Создание и обучение модели\n",
        "model = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
        "model.fit(texts, labels)\n",
        "\n",
        "# Прогноз для нового текста\n",
        "new_text = \"Фондовый рынок падает второй день подряд\"\n",
        "predicted_label = model.predict([new_text])\n",
        "print(predicted_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0InnfWNvQwZd",
        "outputId": "cd159d20-e2b8-43cc-8c22-efdc1e5adb05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['развлечение']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Этот код демонстрирует базовый пример использования scikit-learn для классификации текста с применением TF-IDF векторизации и наивного байесовского классификатора. Он может быть расширен и адаптирован для решения различных задач классификации текстовых данных."
      ],
      "metadata": {
        "id": "gakGkWexROfP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Эти примеры иллюстрируют, как можно применить методы сентимент-анализа и классификации текста для решения различных задач.\n"
      ],
      "metadata": {
        "id": "F-AGo0-pQwsN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Часть 4: Примеры использования персептрона в NLP\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Тональность текста и классификация текста — это два понятия в области обработки естественного языка (NLP), которые, хотя и имеют много общего, различаются по своим целям и методам применения.\n",
        "\n",
        "#### 4.1. Классификация текста\n",
        "\n",
        "Представим, что у нас есть задача классификации текста на позитивные и негативные отзывы. Мы можем использовать персептрон для обучения модели, которая будет предсказывать эмоциональную окраску текста на основе его содержания."
      ],
      "metadata": {
        "id": "QLkHGEYMQXaz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Пример.** Построить модель машинного обучения, способную классифицировать текстовые отзывы на фильмы как положительные или отрицательные, и оценить качество этой модели."
      ],
      "metadata": {
        "id": "sK9MVwNBHUlQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Более крупный и сбалансированный пример данных\n",
        "corpus = [\n",
        "    \"Этот фильм ужасен, я не смог досмотреть до конца\",\n",
        "    \"Отличный сюжет и интересные персонажи, рекомендую всем!\",\n",
        "    \"Ничего особенного, средний фильм без изюминки\",\n",
        "    \"Великолепный фильм, он меня вдохновил и покорил\",\n",
        "    \"Не понравилось, персонажи были плоскими и сюжет был предсказуем\",\n",
        "    \"Прекрасный фильм, замечательная игра актеров\",\n",
        "    \"Этот фильм был настоящим разочарованием, ожидал большего\",\n",
        "    \"Фильм захватывает с первых минут и держит в напряжении до конца\",\n",
        "    \"Ужасный сценарий и отвратительная игра актеров\",\n",
        "    \"Отличная режиссура и великолепные спецэффекты\",\n",
        "    \"Не стоит своих денег, слишком много клише и предсказуемых моментов\",\n",
        "    \"Смотрел с удовольствием, отличный семейный фильм\"\n",
        "]\n",
        "labels = [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]\n",
        "\n",
        "# Инициализация векторизатора TF-IDF\n",
        "vectorizer = TfidfVectorizer(max_features=1000, lowercase=True, analyzer='word', stop_words='english')\n",
        "\n",
        "# Преобразование текстов в TF-IDF признаки\n",
        "X = vectorizer.fit_transform(corpus).toarray()\n",
        "y = np.array(labels)\n",
        "\n",
        "# Разделение данных на обучающую и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Инициализация MLP классификатора\n",
        "mlp_classifier = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42, solver='adam', learning_rate_init=0.001)\n",
        "\n",
        "# Обучение модели\n",
        "mlp_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Предсказание на тестовой выборке\n",
        "y_pred = mlp_classifier.predict(X_test)\n",
        "\n",
        "# Оценка качества модели\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Вывод отчета по классификации (precision, recall, f1-score и support)\n",
        "print(classification_report(y_test, y_pred, target_names=['Отрицательный', 'Положительный']))\n",
        "\n",
        "# Предсказание на новых данных\n",
        "new_reviews = [\n",
        "    \"Отличный фильм! Очень трогательная история, рекомендую всем!\",\n",
        "    \"Самый ужасный фильм, который я когда-либо видел. Потраченное время и деньги.\"\n",
        "]\n",
        "\n",
        "# Преобразование новых отзывов в TF-IDF признаки с использованием ранее инициализированного векторизатора\n",
        "X_new = vectorizer.transform(new_reviews).toarray()\n",
        "\n",
        "# Предсказание сентимента с использованием обученной модели MLP\n",
        "predictions = mlp_classifier.predict(X_new)\n",
        "\n",
        "# Вывод результатов предсказания\n",
        "for review, prediction in zip(new_reviews, predictions):\n",
        "    sentiment = \"Положительный\" if prediction == 1 else \"Отрицательный\"\n",
        "    print(f\"Текст отзыва: {review}\")\n",
        "    print(f\"Прогноз сентимента: {sentiment}\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHgdD3YyHU-r",
        "outputId": "30d6b8e7-7184-49a3-df7a-ff6d442ed861"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.67\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "Отрицательный       1.00      0.50      0.67         2\n",
            "Положительный       0.50      1.00      0.67         1\n",
            "\n",
            "     accuracy                           0.67         3\n",
            "    macro avg       0.75      0.75      0.67         3\n",
            " weighted avg       0.83      0.67      0.67         3\n",
            "\n",
            "Текст отзыва: Отличный фильм! Очень трогательная история, рекомендую всем!\n",
            "Прогноз сентимента: Положительный\n",
            "\n",
            "Текст отзыва: Самый ужасный фильм, который я когда-либо видел. Потраченное время и деньги.\n",
            "Прогноз сентимента: Отрицательный\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Анализ и улучшение модели\n",
        "\n",
        "Модель показывает точность 67%, что не является высоким показателем. Несмотря на то, что новый отзыв классифицирован верно, есть возможности для дальнейшего улучшения модели.\n",
        "\n",
        "### Возможные улучшения\n",
        "\n",
        "1. **Увеличение объема данных:**\n",
        "   - Большее количество данных позволяет модели лучше понять закономерности в текстах.\n",
        "\n",
        "2. **Более сложные методы векторизации:**\n",
        "   - Использование методов вроде Word2Vec, GloVe или BERT может улучшить представление текста.\n",
        "\n",
        "3. **Тонкая настройка модели:**\n",
        "   - Настройка гиперпараметров модели, таких как количество слоев, количество нейронов, функция активации и алгоритм оптимизации.\n",
        "\n",
        "4. **Учет дополнительных факторов:**\n",
        "   - Включение в модель информации о частоте слов, биграммах, триграммах и т.д.\n"
      ],
      "metadata": {
        "id": "EwY7Ig8DJN8q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "#### 4.2. Анализ тональности\n",
        "\n",
        "Допустим, мы хотим разработать систему, которая автоматически анализирует тональность новостных статей. Мы можем использовать многослойный персептрон для создания классификатора, который будет определять, является ли текст статьи позитивным, негативным или нейтральным."
      ],
      "metadata": {
        "id": "Jc8WmegGtHWl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Программа для анализа тональности новостных статей\n",
        "\n",
        "Для создания системы анализа тональности новостных статей с использованием многослойного персептрона (MLP) можно использовать `scikit-learn` для обучения модели и предобученные эмбеддинги Word2Vec для представления текстов. В данном примере мы будем классифицировать статьи как позитивные, негативные или нейтральные.\n",
        "\n",
        "### Шаги:\n",
        "1. **Сбор и подготовка данных.**\n",
        "2. **Преобразование текстов в эмбеддинги Word2Vec.**\n",
        "3. **Обучение модели MLP.**\n",
        "4. **Оценка модели.**\n",
        "5. **Предсказание на новых данных.**\n",
        "\n",
        "### Пример реализации:\n",
        "\n",
        "#### 1. Подготовка данных:\n",
        "\n",
        "Для простоты предположим, что у нас есть небольшие наборы данных для каждой категории тональности.\n"
      ],
      "metadata": {
        "id": "a6Ba4w7bJtCN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Пример.** Построить модели машинного обучения, которая сможет эффективно классифицировать текстовые данные по трем категориям тональности - негативной, позитивной и нейтральной, и продемонстрировать хорошее качество классификации на тестовых данных. Кроме того, модель должна быть применима для предсказания тональности новых текстовых документов."
      ],
      "metadata": {
        "id": "4LsBVYdJMyMu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from gensim.models import Word2Vec\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Дополнительные данные для гарантии присутствия всех классов\n",
        "corpus = [\n",
        "    \"Экономика страны растет, инвестиции увеличиваются\",  # Позитивный\n",
        "    \"Произошла катастрофа, много пострадавших\",  # Негативный\n",
        "    \"Политическая ситуация стабильна\",  # Нейтральный\n",
        "    \"Компании сообщают о рекордной прибыли\",  # Позитивный\n",
        "    \"Новый закон вызвал волну протестов\",  # Негативный\n",
        "    \"Погода сегодня будет солнечной и теплой\",  # Нейтральный\n",
        "    \"Экономический кризис вызывает беспокойство у граждан\",  # Негативный\n",
        "    \"Ведущие эксперты прогнозируют улучшение рынка труда\",  # Позитивный\n",
        "    \"Произошел террористический акт в центре города\",  # Негативный\n",
        "    \"Выборы прошли спокойно, без серьезных нарушений\",  # Нейтральный\n",
        "    \"Новая волна пандемии вызывает опасения у населения\",  # Негативный\n",
        "    \"Рынок акций достиг исторического максимума\",  # Позитивный\n",
        "    \"Спортивные события будут проходить без зрителей\",  # Нейтральный\n",
        "    \"Научные достижения вызывают оптимизм\",  # Позитивный\n",
        "    \"Негативное влияние изменений климата\"  # Негативный\n",
        "]\n",
        "labels = [1, 0, 2, 1, 0, 2, 0, 1, 0, 2, 0, 1, 2, 1, 0]  # 0 - Негативный, 1 - Позитивный, 2 - Нейтральный\n",
        "\n",
        "# Токенизация текстов\n",
        "nltk.download('punkt')\n",
        "tokenized_corpus = [word_tokenize(review.lower()) for review in corpus]\n",
        "\n",
        "# Обучение Word2Vec на корпусе\n",
        "word2vec_model = Word2Vec(tokenized_corpus, vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "def get_average_word2vec(tokens_list, vector, k=100):\n",
        "    \"\"\"\n",
        "    Получение среднего вектора Word2Vec для списка токенов.\n",
        "    \"\"\"\n",
        "    if len(tokens_list) < 1:\n",
        "        return np.zeros(k)\n",
        "    vectorized = [vector[word] if word in vector else np.zeros(k) for word in tokens_list]\n",
        "    mean = np.mean(vectorized, axis=0)\n",
        "    return mean\n",
        "\n",
        "# Преобразование данных с использованием Word2Vec\n",
        "X = np.array([get_average_word2vec(tokens, word2vec_model.wv) for tokens in tokenized_corpus])\n",
        "y = np.array(labels)\n",
        "\n",
        "# Разделение данных на обучающую и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Проверка наличия всех классов в обучающей выборке\n",
        "print(\"Уникальные классы в обучающей выборке:\", np.unique(y_train))\n",
        "print(\"Уникальные классы в тестовой выборке:\", np.unique(y_test))\n",
        "\n",
        "# Инициализация MLP классификатора\n",
        "mlp_classifier = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42, solver='adam', learning_rate_init=0.001)\n",
        "\n",
        "# Обучение модели\n",
        "mlp_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Предсказание на тестовой выборке\n",
        "y_pred = mlp_classifier.predict(X_test)\n",
        "\n",
        "# Оценка качества модели\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Вывод отчета по классификации (precision, recall, f1-score и support)\n",
        "print(classification_report(y_test, y_pred, target_names=['Негативный', 'Позитивный', 'Нейтральный']))\n",
        "\n",
        "# Предсказание на новых данных\n",
        "new_articles = [\n",
        "    \"Новая волна пандемии вызывает опасения у населения\",\n",
        "    \"Рынок акций достиг исторического максимума\",\n",
        "    \"Спортивные события будут проходить без зрителей\"\n",
        "]\n",
        "\n",
        "# Токенизация новых статей\n",
        "tokenized_new_articles = [word_tokenize(article.lower()) for article in new_articles]\n",
        "X_new = np.array([get_average_word2vec(tokens, word2vec_model.wv) for tokens in tokenized_new_articles])\n",
        "\n",
        "# Предсказание тональности с использованием обученной модели MLP\n",
        "predictions = mlp_classifier.predict(X_new)\n",
        "\n",
        "# Вывод результатов предсказания\n",
        "for article, prediction in zip(new_articles, predictions):\n",
        "    sentiment = [\"Негативный\", \"Позитивный\", \"Нейтральный\"][prediction]\n",
        "    print(f\"Текст статьи: {article}\")\n",
        "    print(f\"Прогноз тональности: {sentiment}\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2WS0yuiJyHw",
        "outputId": "0b316d76-1d1f-4976-a38f-37b23b167e71"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Уникальные классы в обучающей выборке: [0 1 2]\n",
            "Уникальные классы в тестовой выборке: [0 1 2]\n",
            "Accuracy: 0.67\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Негативный       1.00      1.00      1.00         1\n",
            "  Позитивный       0.50      1.00      0.67         1\n",
            " Нейтральный       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.67         3\n",
            "   macro avg       0.50      0.67      0.56         3\n",
            "weighted avg       0.50      0.67      0.56         3\n",
            "\n",
            "Текст статьи: Новая волна пандемии вызывает опасения у населения\n",
            "Прогноз тональности: Негативный\n",
            "\n",
            "Текст статьи: Рынок акций достиг исторического максимума\n",
            "Прогноз тональности: Позитивный\n",
            "\n",
            "Текст статьи: Спортивные события будут проходить без зрителей\n",
            "Прогноз тональности: Нейтральный\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Идентификация именованных сущностей (NER)\n",
        "\n",
        "Идентификация именованных сущностей (Named Entity Recognition, NER) — это задача выделения из текста определенных сущностей, таких как имена людей, организаций, географических объектов и др. В этой задаче часто используют различные методы машинного обучения, включая персептроны.\n",
        "\n"
      ],
      "metadata": {
        "id": "OwHB2zbsSWV4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from gensim.models import Word2Vec\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Обновленные примеры предложений с разметкой NER\n",
        "sentences = [\n",
        "    (\"Иван Иванов работает в компании OpenAI\", [(\"Иван\", \"B-PER\"), (\"Иванов\", \"I-PER\"), (\"работает\", \"O\"), (\"в\", \"O\"), (\"компании\", \"O\"), (\"OpenAI\", \"B-ORG\")]),\n",
        "    (\"Мария живет в Москве\", [(\"Мария\", \"B-PER\"), (\"живет\", \"O\"), (\"в\", \"O\"), (\"Москве\", \"B-LOC\")]),\n",
        "    (\"Google является лидером в области технологий\", [(\"Google\", \"B-ORG\"), (\"является\", \"O\"), (\"лидером\", \"O\"), (\"в\", \"O\"), (\"области\", \"O\"), (\"технологий\", \"O\")]),\n",
        "    (\"VK и Amazon конкурируют на рынке\", [(\"VK\", \"B-ORG\"), (\"и\", \"O\"), (\"Amazon\", \"B-ORG\"), (\"конкурируют\", \"O\"), (\"на\", \"O\"), (\"рынке\", \"O\")]),\n",
        "    (\"Сергей Петров посетил конференцию в Санкт-Петербурге\", [(\"Сергей\", \"B-PER\"), (\"Петров\", \"I-PER\"), (\"посетил\", \"O\"), (\"конференцию\", \"O\"), (\"в\", \"O\"), (\"Санкт-Петербурге\", \"B-LOC\")]),\n",
        "    (\"Аркадий Волож и Илья Сегалович основали компанию Yandex\", [(\"Аркадий\", \"B-PER\"), (\"Волож\", \"I-PER\"), (\"и\", \"O\"), (\"Илья\", \"B-PER\"), (\"Сегалович\", \"I-PER\"), (\"основали\", \"O\"), (\"компанию\", \"O\"), (\"Yandex\", \"B-ORG\")]),\n",
        "    (\"Илон Маск является генеральным директором Tesla\", [(\"Илон\", \"B-PER\"), (\"Маск\", \"I-PER\"), (\"является\", \"O\"), (\"генеральным\", \"O\"), (\"директором\", \"O\"), (\"Tesla\", \"B-ORG\")]),\n",
        "    (\"Стив Джобс был сооснователем Apple\", [(\"Стив\", \"B-PER\"), (\"Джобс\", \"I-PER\"), (\"был\", \"O\"), (\"сооснователем\", \"O\"), (\"Apple\", \"B-ORG\")]),\n",
        "    (\"Джефф Безос владеет компанией Amazon\", [(\"Джефф\", \"B-PER\"), (\"Безос\", \"I-PER\"), (\"владеет\", \"O\"), (\"компанией\", \"O\"), (\"Amazon\", \"B-ORG\")]),\n",
        "    (\"Сундар Пичаи руководит Google\", [(\"Сундар\", \"B-PER\"), (\"Пичаи\", \"I-PER\"), (\"руководит\", \"O\"), (\"Google\", \"B-ORG\")]),\n",
        "]\n",
        "\n",
        "# Токенизация предложений и меток\n",
        "tokenized_sentences = [word_tokenize(sentence.lower()) for sentence, _ in sentences]\n",
        "labels = [[label for _, label in sent] for _, sent in sentences]\n",
        "\n",
        "# Обучение модели Word2Vec\n",
        "nltk.download('punkt')\n",
        "word2vec_model = Word2Vec(tokenized_sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "def get_word2vec(word, model, vector_size=100):\n",
        "    return model[word] if word in model else np.zeros(vector_size)\n",
        "\n",
        "# Подготовка данных для MLP\n",
        "X = []\n",
        "y = []\n",
        "for sent, labels in zip(tokenized_sentences, labels):\n",
        "    for word, label in zip(sent, labels):\n",
        "        X.append(get_word2vec(word, word2vec_model.wv))\n",
        "        y.append(label)\n",
        "\n",
        "# Преобразование меток в числовой формат\n",
        "unique_labels = list(set(y))\n",
        "label_to_index = {label: idx for idx, label in enumerate(unique_labels)}\n",
        "index_to_label = {idx: label for label, idx in label_to_index.items()}\n",
        "y = np.array([label_to_index[label] for label in y])\n",
        "\n",
        "# Разделение данных на обучающую и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Инициализация и обучение MLP классификатора\n",
        "mlp_classifier = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42)\n",
        "mlp_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Предсказание на тестовой выборке\n",
        "y_pred = mlp_classifier.predict(X_test)\n",
        "\n",
        "# Оценка качества модели\n",
        "print(classification_report(y_test, y_pred, target_names=[index_to_label[idx] for idx in sorted(index_to_label.keys())], labels=sorted(index_to_label.keys())))\n",
        "\n",
        "# Пример предсказания для нового предложения\n",
        "new_sentence = \"Александр работает в Google\"\n",
        "tokenized_new_sentence = word_tokenize(new_sentence.lower())\n",
        "X_new = np.array([get_word2vec(word, word2vec_model.wv) for word in tokenized_new_sentence])\n",
        "predictions = mlp_classifier.predict(X_new)\n",
        "\n",
        "# Вывод результатов предсказания\n",
        "for word, prediction in zip(tokenized_new_sentence, predictions):\n",
        "    print(f\"Слово: {word}, Предсказанная метка: {index_to_label[prediction]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ocs41yBASceh",
        "outputId": "a65c44e0-10c7-431e-906f-086eb99b9cb7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC       0.00      0.00      0.00         0\n",
            "       I-PER       0.00      0.00      0.00         2\n",
            "           O       0.55      1.00      0.71         6\n",
            "       B-PER       0.00      0.00      0.00         2\n",
            "       B-ORG       0.00      0.00      0.00         2\n",
            "\n",
            "   micro avg       0.50      0.50      0.50        12\n",
            "   macro avg       0.11      0.20      0.14        12\n",
            "weighted avg       0.27      0.50      0.35        12\n",
            "\n",
            "Слово: александр, Предсказанная метка: O\n",
            "Слово: работает, Предсказанная метка: O\n",
            "Слово: в, Предсказанная метка: O\n",
            "Слово: google, Предсказанная метка: B-ORG\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Разрешение синонимии и антонимии\n",
        "В задачах обработки естественного языка персептрон может быть использован для определения, являются ли два слова синонимами или антонимами.\n",
        "\n",
        "Пример: Определение, являются ли слова \"большой\" и \"огромный\" синонимами."
      ],
      "metadata": {
        "id": "xnDrF8dCScqL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from gensim.models import Word2Vec\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Example word pairs\n",
        "synonym_pairs = [\n",
        "    (\"большой\", \"огромный\"),\n",
        "    (\"маленький\", \"крошечный\"),\n",
        "    (\"умный\", \"сообразительный\"),\n",
        "    (\"красивый\", \"прекрасный\")\n",
        "]\n",
        "\n",
        "antonym_pairs = [\n",
        "    (\"большой\", \"маленький\"),\n",
        "    (\"быстрый\", \"медленный\"),\n",
        "    (\"темный\", \"светлый\"),\n",
        "    (\"день\", \"ночь\")\n",
        "]\n",
        "\n",
        "word_pairs = synonym_pairs + antonym_pairs\n",
        "labels = [1] * len(synonym_pairs) + [0] * len(antonym_pairs)  # 1 for synonym, 0 for antonym\n",
        "\n",
        "# Training a simple Word2Vec model\n",
        "sentences = [word_tokenize(pair[0]) + word_tokenize(pair[1]) for pair in word_pairs]\n",
        "word2vec_model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "def get_word2vec(word, model, vector_size=100):\n",
        "    return model[word] if word in model else np.zeros(vector_size)\n",
        "\n",
        "# Prepare feature vectors\n",
        "X = []\n",
        "for word1, word2 in word_pairs:\n",
        "    vec1 = get_word2vec(word1, word2vec_model.wv)\n",
        "    vec2 = get_word2vec(word2, word2vec_model.wv)\n",
        "    X.append(np.concatenate((vec1, vec2)))\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(labels)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the perceptron\n",
        "perceptron = Perceptron(max_iter=1000, random_state=42)\n",
        "perceptron.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = perceptron.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(classification_report(y_test, y_pred, target_names=[\"Antonym\", \"Synonym\"]))\n",
        "\n",
        "# Example prediction for a new pair of words\n",
        "new_pair = (\"огромный\", \"крошечный\")\n",
        "vec1 = get_word2vec(new_pair[0], word2vec_model.wv)\n",
        "vec2 = get_word2vec(new_pair[1], word2vec_model.wv)\n",
        "X_new = np.concatenate((vec1, vec2)).reshape(1, -1)\n",
        "\n",
        "prediction = perceptron.predict(X_new)\n",
        "\n",
        "print(f\"Слова: {new_pair[0]} и {new_pair[1]}, Предсказанная метка: {'Синонимы' if prediction[0] == 1 else 'Антонимы'}\")\n",
        "\n",
        "# Example prediction for a new pair of words\n",
        "new_pair = (\"день\", \"ночь\")\n",
        "vec1 = get_word2vec(new_pair[0], word2vec_model.wv)\n",
        "vec2 = get_word2vec(new_pair[1], word2vec_model.wv)\n",
        "X_new = np.concatenate((vec1, vec2)).reshape(1, -1)\n",
        "\n",
        "prediction = perceptron.predict(X_new)\n",
        "\n",
        "print(f\"Слова: {new_pair[0]} и {new_pair[1]}, Предсказанная метка: {'Синонимы' if prediction[0] == 1 else 'Антонимы'}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLtnvKYDesHg",
        "outputId": "5aa1ddec-e03d-4aa1-b11a-3da36e280ae6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Antonym       0.00      0.00      0.00         1\n",
            "     Synonym       0.50      1.00      0.67         1\n",
            "\n",
            "    accuracy                           0.50         2\n",
            "   macro avg       0.25      0.50      0.33         2\n",
            "weighted avg       0.25      0.50      0.33         2\n",
            "\n",
            "Слова: огромный и крошечный, Предсказанная метка: Антонимы\n",
            "Слова: день и ночь, Предсказанная метка: Антонимы\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ]
}