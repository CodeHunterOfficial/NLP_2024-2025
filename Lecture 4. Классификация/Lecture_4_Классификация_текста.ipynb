{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMM1AkqWa06jZQrx+9Ie3Zx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CodeHunterOfficial/NLP-2024-2025/blob/main/Lecture_4_%D0%9A%D0%BB%D0%B0%D1%81%D1%81%D0%B8%D1%84%D0%B8%D0%BA%D0%B0%D1%86%D0%B8%D1%8F_%D1%82%D0%B5%D0%BA%D1%81%D1%82%D0%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Лекция: Классификация текста\n",
        "\n",
        "### Введение\n",
        "\n",
        "Классификация текста является важной задачей в области обработки естественного языка (NLP). Она находит применение в спам-фильтрах, анализе тональности, категоризации новостей и многих других областях. В данной лекции мы рассмотрим основные методы машинного обучения, используемые для классификации текстов, включая методы предварительной обработки данных, алгоритмы классификации и оценку их эффективности.\n",
        "\n",
        "### 1. Предварительная обработка данных\n",
        "\n",
        "Перед тем как применять методы машинного обучения к тексту, необходимо выполнить несколько шагов предварительной обработки данных.\n",
        "\n",
        "#### 1.1. Токенизация\n",
        "\n",
        "Токенизация — это процесс разбиения текста на отдельные элементы (токены), такие как слова или фразы. Это можно сделать с помощью регулярных выражений или специализированных библиотек, таких как NLTK или SpaCy.\n"
      ],
      "metadata": {
        "id": "jrDZG7aye41q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "text = \"Machine learning is fascinating.\"\n",
        "tokens = word_tokenize(text)\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97cO3heNfAlv",
        "outputId": "29e94beb-0256-4e5e-bb51-994cbe7bc8d6"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Machine', 'learning', 'is', 'fascinating', '.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### 1.2. Приведение к нижнему регистру\n",
        "\n",
        "Приведение всех символов к нижнему регистру помогает уменьшить разнообразие слов и повысить точность модели.\n"
      ],
      "metadata": {
        "id": "BLBvCMAefFFM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = text.lower()\n",
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "huzqvWavfbb0",
        "outputId": "e077037b-477c-43fd-a920-45310bb446e6"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'machine learning is fascinating.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.3. Удаление стоп-слов\n",
        "\n",
        "Стоп-слова (например, \"и\", \"на\", \"в\") часто не несут значимой информации и могут быть удалены.\n"
      ],
      "metadata": {
        "id": "OfcVf9hffj8l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "tokens = [word for word in tokens if word not in stop_words]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDMofktAfkj2",
        "outputId": "c80324c3-976e-408a-c3e0-972802ca2f41"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.4. Лемматизация и стемминг\n",
        "\n",
        "Лемматизация и стемминг используются для приведения слов к их базовым формам.\n"
      ],
      "metadata": {
        "id": "R5rOEPnUf1Pz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grts6BETf4J3",
        "outputId": "dbdc0979-2f75-48c3-9765-f33f5d3f7b0d"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Machine', 'learning', 'fascinating', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Представление текста\n",
        "\n",
        "#### 2.1. Мешок слов (Bag of Words, BoW)\n",
        "\n",
        "Модель \"мешок слов\" представляет текст в виде вектора частот слов. Для этого используется векторизация, где каждая позиция вектора соответствует частоте появления определенного слова в документе.\n"
      ],
      "metadata": {
        "id": "8vfHk0sUgfXJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "corpus = [\"Machine learning is fascinating.\", \"Text classification with machine learning.\"]\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "print(X.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qqBzW77ggD7",
        "outputId": "0ccd14ea-7a00-4102-c885-3723aa8562b3"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 1 1 1 1 0 0]\n",
            " [1 0 0 1 1 1 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### 2.2. TF-IDF (Term Frequency-Inverse Document Frequency)\n",
        "\n",
        "TF-IDF улучшает модель BoW, взвешивая частоты слов на основе их важности.\n",
        "\n",
        "Формула TF-IDF для слова $ t $ в документе $ d $:\n",
        "\n",
        "$$\n",
        "\\text{TF-IDF}(t, d) = \\text{TF}(t, d) \\times \\text{IDF}(t)\n",
        "$$\n",
        "\n",
        "где\n",
        "\n",
        "$$\n",
        "\\text{TF}(t, d) = \\frac{\\text{Количество вхождений } t \\text{ в } d}{\\text{Общее количество слов в } d}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\text{IDF}(t) = \\log \\left( \\frac{\\text{Количество документов}}{\\text{Количество документов, содержащих } t} \\right)\n",
        "$$\n"
      ],
      "metadata": {
        "id": "n4ubNIIcgsKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "print(X.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilrbmCZGg_Ql",
        "outputId": "78c1839b-9110-4bbc-8650-2f49784b4753"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.         0.57615236 0.57615236 0.40993715 0.40993715 0.\n",
            "  0.        ]\n",
            " [0.49922133 0.         0.         0.35520009 0.35520009 0.49922133\n",
            "  0.49922133]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3. Алгоритмы классификации\n",
        "\n",
        "Классификация - это одна из основных задач машинного обучения, где цель состоит в том, чтобы определить, к какому классу или категории принадлежит объект на основе его признаков.\n",
        "\n",
        "Некоторые наиболее популярные алгоритмы классификации включают:\n",
        "\n",
        "1. **Наивный байесовский классификатор (Naive Bayes)**: Это вероятностный классификатор, основанный на теореме Байеса, который предполагает, что признаки независимы.\n",
        "\n",
        "2. **Логистическая регрессия (Logistic Regression)**: Это алгоритм, использующий регрессионную модель для прогнозирования категориального (бинарного или многоклассового) выходного значения.\n",
        "\n",
        "3. **Метод опорных векторов (Support Vector Machines, SVM)**: Это алгоритм, который строит гиперплоскость или набор гиперплоскостей в многомерном пространстве, которые могут использоваться для классификации.\n",
        "\n",
        "\n",
        "4. **K-ближайших соседей (K-Nearest Neighbors, KNN)**: Это алгоритм, который классифицирует объект на основе большинства голосов его K ближайших соседей в пространстве признаков.\n",
        "\n",
        "4. **Деревья решений (Decision Trees)**: Это алгоритм, который создает модель принятия решений в виде дерева с решениями и их возможными последствиями.\n",
        "\n",
        "5. **Случайный лес (Random Forest)**: Это ансамблевый алгоритм, который использует множество деревьев решений для более точного прогнозирования.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Каждый из этих алгоритмов имеет свои сильные и слабые стороны, и выбор наиболее подходящего алгоритма зависит от характера данных, требуемой точности и интерпретируемости модели."
      ],
      "metadata": {
        "id": "WMQPAsbohFvt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Наивный байесовский классификатор (Naive Bayes):"
      ],
      "metadata": {
        "id": "KbAafh_nhv8x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### Введение\n",
        "\n",
        "Наивный байесовский классификатор (Наивный Байес) — это один из самых простых и эффективных алгоритмов для задач классификации в машинном обучении. Он основывается на теореме Байеса с предположением о независимости признаков. В этой лекции мы подробно рассмотрим, как работает Наивный Байесовский классификатор в контексте обработки естественного языка (NLP), обсудим теоретическую основу, а также приведем примеры и формулы.\n",
        "\n",
        "#### Теоретическая основа\n",
        "\n",
        "##### Теорема Байеса\n",
        "\n",
        "Теорема Байеса описывает вероятность гипотезы $H$ при условии наблюдаемого события $E$:\n",
        "\n",
        "$$ P(H|E) = \\frac{P(E|H) \\cdot P(H)}{P(E)} $$\n",
        "\n",
        "где:\n",
        "- $P(H|E)$ — апостериорная вероятность гипотезы $H$ при условии наблюдения $E$.\n",
        "- $P(E|H)$ — вероятность наблюдения $E$ при условии, что гипотеза $H$ истинна.\n",
        "- $P(H)$ — априорная вероятность гипотезы $H$.\n",
        "- $P(E)$ — вероятность наблюдения $E$.\n",
        "\n",
        "##### Наивное предположение о независимости\n",
        "\n",
        "Наивный Байесовский классификатор предполагает, что все признаки (слова в тексте) независимы друг от друга. Хотя это предположение редко выполняется в реальной жизни, оно упрощает вычисления и часто даёт хорошие результаты.\n",
        "\n",
        "#### Применение в NLP\n",
        "\n",
        "##### Вероятность текста\n",
        "\n",
        "Если предположить, что слова в тексте независимы, вероятность текста $d = \\{w_1, w_2, \\ldots, w_n\\}$ при условии класса $C_i$ равна:\n",
        "\n",
        "$$ P(d|C_i) = P(w_1, w_2, \\ldots, w_n|C_i) = P(w_1|C_i) \\cdot P(w_2|C_i) \\cdot \\ldots \\cdot P(w_n|C_i) $$\n",
        "\n",
        "Таким образом, вероятность $P(C_i|d)$ можно записать как:\n",
        "\n",
        "$$ P(C_i|d) \\propto P(C_i) \\cdot \\prod_{j=1}^{n} P(w_j|C_i) $$\n",
        "\n",
        "##### Оценка вероятностей\n",
        "\n",
        "Априорная вероятность класса $P(C_i)$ оценивается как доля документов этого класса в обучающей выборке:\n",
        "\n",
        "$$ P(C_i) = \\frac{\\text{количество документов класса } C_i}{\\text{общее количество документов}} $$\n",
        "\n",
        "Условная вероятность слова $w_j$ при условии класса $C_i$ оценивается как:\n",
        "\n",
        "$$ P(w_j|C_i) = \\frac{\\text{количество вхождений } w_j \\text{ в документы класса } C_i + 1}{\\text{общее количество слов в документах класса } C_i + V} $$\n",
        "\n",
        "где $V$ — размер словаря (общее количество уникальных слов). Добавление единицы (Лапласов сглаживатель) предотвращает вероятность нуля для слов, которые отсутствуют в документах класса.\n",
        "\n",
        "#### Пример\n",
        "\n",
        "Рассмотрим простой пример классификации текста на спам и не спам.\n",
        "\n",
        "**Обучающая выборка:**\n",
        "\n",
        "- Документ 1 (спам): \"купить дешево\"\n",
        "- Документ 2 (не спам): \"хорошее качество\"\n",
        "- Документ 3 (спам): \"купить быстро дешево\"\n",
        "- Документ 4 (не спам): \"качество гарантировано\"\n",
        "\n",
        "Словарь: \"купить\", \"дешево\", \"хорошее\", \"качество\", \"быстро\", \"гарантировано\".\n",
        "\n",
        "**Оценка априорных вероятностей:**\n",
        "\n",
        "$$ P(\\text{спам}) = \\frac{2}{4} = 0.5 $$\n",
        "$$ P(\\text{не спам}) = \\frac{2}{4} = 0.5 $$\n",
        "\n",
        "**Оценка условных вероятностей:**\n",
        "\n",
        "Для класса \"спам\":\n",
        "\n",
        "$$ P(\\text{купить}|\\text{спам}) = \\frac{2 + 1}{5 + 6} = \\frac{3}{11} $$\n",
        "$$ P(\\text{дешево}|\\text{спам}) = \\frac{2 + 1}{5 + 6} = \\frac{3}{11} $$\n",
        "$$ P(\\text{быстро}|\\text{спам}) = \\frac{1 + 1}{5 + 6} = \\frac{2}{11} $$\n",
        "\n",
        "Для класса \"не спам\":\n",
        "\n",
        "$$ P(\\text{хорошее}|\\text{не спам}) = \\frac{1 + 1}{4 + 6} = \\frac{2}{10} = 0.2 $$\n",
        "$$ P(\\text{качество}|\\text{не спам}) = \\frac{2 + 1}{4 + 6} = \\frac{3}{10} = 0.3 $$\n",
        "$$ P(\\text{гарантировано}|\\text{не спам}) = \\frac{1 + 1}{4 + 6} = \\frac{2}{10} = 0.2 $$\n",
        "\n",
        "**Классификация нового документа:**\n",
        "\n",
        "Документ: \"купить качество\"\n",
        "\n",
        "Вычисляем вероятность для класса \"спам\":\n",
        "\n",
        "$$ P(\\text{спам}|\\text{купить качество}) \\propto P(\\text{спам}) \\cdot P(\\text{купить}|\\text{спам}) \\cdot P(\\text{качество}|\\text{спам}) $$\n",
        "$$ P(\\text{спам}|\\text{купить качество}) \\propto 0.5 \\cdot \\frac{3}{11} \\cdot \\frac{1}{11} = \\frac{3}{242} \\approx 0.0124 $$\n",
        "\n",
        "Вычисляем вероятность для класса \"не спам\":\n",
        "\n",
        "$$ P(\\text{не спам}|\\text{купить качество}) \\propto P(\\text{не спам}) \\cdot P(\\text{купить}|\\text{не спам}) \\cdot P(\\text{качество}|\\text{не спам}) $$\n",
        "$$ P(\\text{не спам}|\\text{купить качество}) \\propto 0.5 \\cdot \\frac{1}{10} \\cdot 0.3 = 0.015 $$\n",
        "\n",
        "Так как $0.015 > 0.0124$, документ \"купить качество\" классифицируется как \"не спам\".\n",
        "\n",
        "Таким образом, наивный Байесовский классификатор — мощный инструмент для задач классификации текста, несмотря на своё наивное предположение о независимости признаков. Его простота и эффектив"
      ],
      "metadata": {
        "id": "T1jCkqIiwnvi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ниже приведены примеры использования Наивного Байесовского классификатора для классификации текста с использованием библиотеки scikit-learn в Python."
      ],
      "metadata": {
        "id": "rWHUiP-Xzqq3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Пример данных\n",
        "data = {\n",
        "    'text': ['купить дешево', 'хорошее качество', 'купить быстро дешево', 'качество гарантировано',\n",
        "             'дешево и быстро', 'отличное качество', 'купить сразу', 'качество на высоте'],\n",
        "    'label': ['спам', 'не спам', 'спам', 'не спам', 'спам', 'не спам', 'спам', 'не спам']\n",
        "}\n",
        "\n",
        "# Создаем DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Разделение на обучающую и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.25, random_state=42)"
      ],
      "metadata": {
        "id": "glbrcq2czrd1"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Преобразование текстов в числовые признаки\n",
        "Для использования Наивного Байесовского классификатора, нужно преобразовать тексты в числовые признаки с помощью CountVectorizer."
      ],
      "metadata": {
        "id": "iSX1cRUTz0ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CountVectorizer это инструмент машинного обучения, который используется для преобразования текстовых данных в числовые векторные представления. Он подсчитывает частоту появления каждого слова (или n-граммы) в документе и создает разреженную матрицу, где каждая строка соответствует документу, а каждый столбец - уникальному слову (или n-грамме) в корпусе.\n",
        "\n",
        "Основные шаги работы CountVectorizer:\n",
        "\n",
        "1. Разбиение текста на токены (слова или n-граммы).\n",
        "2. Построение словаря уникальных токенов.\n",
        "3. Подсчет частоты появления каждого токена в каждом документе.\n",
        "4. Формирование разреженной матрицы, где каждая строка - документ, а каждый столбец - токен.\n",
        "\n",
        "Преимущества CountVectorizer:\n",
        "- Простота и эффективность.\n",
        "- Возможность учитывать n-граммы, а не только отдельные слова.\n",
        "- Возможность настройки параметров (min_df, max_df, ngram_range и др.).\n",
        "- Интеграция с другими инструментами машинного обучения в библиотеке scikit-learn.\n",
        "\n",
        "Пример использования в Python:\n"
      ],
      "metadata": {
        "id": "sXFolJLJ0Amn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Создание объекта CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Преобразование текстовых данных в матрицу частот\n",
        "X = vectorizer.fit_transform([\"Это первый документ.\", \"Это второй документ.\"])\n",
        "\n",
        "# Получение матрицы\n",
        "print(X.toarray())\n",
        "\n",
        "# Получение словаря\n",
        "print(vectorizer.vocabulary_)"
      ],
      "metadata": {
        "id": "6YE4m6o40D6t",
        "outputId": "52978e3c-965a-42ae-a786-f0537b401b1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 1 1 1]\n",
            " [1 1 0 1]]\n",
            "{'это': 3, 'первый': 2, 'документ': 1, 'второй': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Преобразование текста в вектор признаков\n",
        "vectorizer = CountVectorizer()\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "1hsvDdkX0KWW"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Обучение модели**\n",
        "\n",
        "Создадим и обучим модель Наивного Байесовского классификатора."
      ],
      "metadata": {
        "id": "Xp9jDCMS0Rk9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Создание и обучение модели\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train_vec, y_train)"
      ],
      "metadata": {
        "id": "TytnUHEM0V0C",
        "outputId": "950090bd-1162-4e18-b19e-7d076b4b9e2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        }
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Оценка модели\n",
        "\n",
        "Оценим качество работы модели на тестовой выборке."
      ],
      "metadata": {
        "id": "AHjWvtkw0daa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Предсказание на тестовой выборке\n",
        "y_pred = model.predict(X_test_vec)\n",
        "\n",
        "# Оценка точности\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy}')\n",
        "\n",
        "# Подробный отчет о классификации\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(report)"
      ],
      "metadata": {
        "id": "DeyV41xl0ej3",
        "outputId": "b2d069c2-6ba4-46bd-ba45-63c3eb94414b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     не спам       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           1.00         2\n",
            "   macro avg       1.00      1.00      1.00         2\n",
            "weighted avg       1.00      1.00      1.00         2\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Весь код."
      ],
      "metadata": {
        "id": "UivxigYr02Qx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Пример данных\n",
        "data = {\n",
        "    'text': ['купить дешево', 'хорошее качество', 'купить быстро дешево', 'качество гарантировано',\n",
        "             'дешево и быстро', 'отличное качество', 'купить сразу', 'качество на высоте'],\n",
        "    'label': ['спам', 'не спам', 'спам', 'не спам', 'спам', 'не спам', 'спам', 'не спам']\n",
        "}\n",
        "\n",
        "# Создаем DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Разделение на обучающую и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.25, random_state=42)\n",
        "\n",
        "# Преобразование текста в вектор признаков\n",
        "vectorizer = CountVectorizer()\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "# Создание и обучение модели\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train_vec, y_train)\n",
        "\n",
        "# Предсказание на тестовой выборке\n",
        "y_pred = model.predict(X_test_vec)\n",
        "\n",
        "# Оценка точности\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy}')\n",
        "\n",
        "# Подробный отчет о классификации\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(report)\n"
      ],
      "metadata": {
        "id": "RgLMHBxb03kJ",
        "outputId": "c4c77f04-87a1-47b9-d2ac-26f2c4e4acf0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     не спам       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           1.00         2\n",
            "   macro avg       1.00      1.00      1.00         2\n",
            "weighted avg       1.00      1.00      1.00         2\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Как видно модель Наивного Байеса показывает 100% точность на тестовых данных, что означает, что она безошибочно классифицирует сообщения как 'спам' или 'не спам'.\n",
        "\n",
        "Давайте рассмотрим, что это означает:\n",
        "\n",
        "1. **Точность (Accuracy)**: Значение 1.0 (или 100%) говорит о том, что все предсказания модели были правильными.\n",
        "\n",
        "2. **Отчет о классификации**:\n",
        "   - **Precision (Точность)**: Для класса 'не спам' модель имеет 100% точность, что означает, что все примеры, классифицированные как 'не спам', действительно являются 'не спам'.\n",
        "   - **Recall (Полнота)**: Модель также имеет 100% полноту для класса 'не спам', что означает, что она правильно распознала все 'не спам' примеры.\n",
        "   - **F1-score**: Гармоническое среднее между точностью и полнотой также составляет 100%, что говорит о высоком качестве классификации.\n",
        "\n",
        "Такие высокие показатели означают, что модель отлично справляется с распознаванием 'спам' и 'не спам' сообщений в данном наборе данных. Это может быть связано с тем, что данные хорошо разделены и модель Наивного Байеса эффективно выявляет отличия между ними.\n",
        "\n",
        "Теперь вы можете с уверенностью использовать эту модель для классификации новых текстовых данных. Если вы захотите улучшить ее производительность, вы можете попробовать другие методы предварительной обработки текста или алгоритмы машинного обучения. Но для этого набора данных модель Наивного Байеса показывает отличные результаты."
      ],
      "metadata": {
        "id": "kdHO1vzwoHgX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для использования результатов классификации можно выполнить следующие шаги:\n",
        "\n",
        "1. Получение предсказаний: После обучения модели, вы можете использовать метод predict() для получения предсказаний на новых данных. Например:\n",
        "\n"
      ],
      "metadata": {
        "id": "2MH7_i_nnuc2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_text = ['купить срочно дешево', 'качество супер']\n",
        "new_vec = vectorizer.transform(new_text)\n",
        "new_predictions = model.predict(new_vec)\n",
        "print(f'Предсказания: {new_predictions}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IeoscJDgn6dw",
        "outputId": "9bd5433d-7b7b-4e5d-b285-f7e75db894b7"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Предсказания: ['спам' 'не спам']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **Принятие решений**:\n",
        "\n",
        "Например, если мы получили предсказание 'спам', мы можем автоматически перемещать сообщение в папку со спамом:\n"
      ],
      "metadata": {
        "id": "46UeKU0joS5V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for pred in new_predictions:\n",
        "    if pred == 'спам':\n",
        "        print('Сообщение перемещено в папку со спамом')\n",
        "    else:\n",
        "        print('Сообщение добавлено в inbox')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HgfEkLdoU1_",
        "outputId": "164db42e-ef7e-4246-b05f-fc08ba619f66"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Сообщение перемещено в папку со спамом\n",
            "Сообщение добавлено в inbox\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Логистическая регрессия\n",
        "\n",
        "#### Введение в логистическую регрессию\n",
        "\n",
        "Логистическая регрессия (Logistic Regression) — это статистическая модель, используемая для бинарной классификации и оценки вероятности принадлежности объекта к определённому классу. В контексте обработки естественного языка (NLP), логистическая регрессия часто применяется для решения задач, таких как определение тональности текста, классификация документов, определение категорий и тематик текстов и других задач, где необходимо определить вероятность принадлежности текста к определённому классу.\n",
        "\n",
        "#### Основные принципы логистической регрессии\n",
        "\n",
        "1. **Логистическая функция (сигмоид)**\n",
        "\n",
        "   Логистическая регрессия использует логистическую функцию (сигмоид) для преобразования выхода линейной комбинации признаков в вероятность принадлежности к классу 1 (или любому другому классу в случае многоклассовой классификации).\n",
        "\n",
        "   Формула логистической функции:\n",
        "   $$\n",
        "   \\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
        "   $$\n",
        "   где $ z = \\theta^T x $, $ \\theta $ — вектор параметров модели, $ x $ — вектор признаков.\n",
        "\n",
        "   Интерпретация $ \\sigma(z) $: $ \\sigma(z) $ представляет собой вероятность того, что объект с признаками $ x $ принадлежит классу 1.\n",
        "\n",
        "2. **Функция потерь (логистическая функция потерь)**\n",
        "\n",
        "   Чтобы обучить параметры $ \\theta $ модели логистической регрессии, используется логистическая функция потерь (log loss):\n",
        "   $$\n",
        "   J(\\theta) = -\\frac{1}{m} \\sum_{i=1}^{m} \\left[ y^{(i)} \\log(\\sigma(\\theta^T x^{(i)})) + (1 - y^{(i)}) \\log(1 - \\sigma(\\theta^T x^{(i)})) \\right]\n",
        "   $$\n",
        "   где $ m $ — количество примеров в обучающей выборке, $ y^{(i)} $ — истинная метка класса для примера $ i $.\n",
        "\n",
        "   Цель минимизации функции потерь $ J(\\theta) $ — настройка параметров $ \\theta $ для максимизации вероятности правильной классификации.\n",
        "\n",
        "3. **Градиентный спуск**\n",
        "\n",
        "   Для оптимизации параметров $ \\theta $ используется градиентный спуск:\n",
        "   $$\n",
        "   \\theta := \\theta - \\alpha \\nabla_{\\theta} J(\\theta)\n",
        "   $$\n",
        "   где $ \\alpha $ — скорость обучения (learning rate), $ \\nabla_{\\theta} J(\\theta) $ — градиент функции потерь.\n",
        "\n",
        "#### Оценка качества модели логистической регрессии в NLP\n",
        "\n",
        "1. **Метрики**\n",
        "\n",
        "   В NLP часто используются следующие метрики для оценки качества модели:\n",
        "\n",
        "   - **Точность (Accuracy)**: доля правильно классифицированных примеров.\n",
        "   $$\n",
        "   \\text{Accuracy} = \\frac{\\text{Количество правильных предсказаний}}{\\text{Общее количество предсказаний}}\n",
        "   $$\n",
        "\n",
        "   - **Точность (Precision)** и **Полнота (Recall)**: используются для более детального анализа качества модели в случае дисбаланса классов или когда важны ошибки определённого типа.\n",
        "\n",
        "   - **F1-мера (F1-score)**: гармоническое среднее точности и полноты, которое учитывает обе метрики одновременно.\n",
        "\n",
        "2. **Кросс-валидация**\n",
        "\n",
        "   Для улучшения обобщающей способности модели в NLP часто применяют кросс-валидацию. Это позволяет оценить, насколько модель способна обобщаться на новые данные.\n",
        "\n",
        "#### Примеры применения логистической регрессии в NLP\n",
        "\n",
        "- **Определение тональности текста**: классификация текстов на позитивные и негативные отзывы.\n",
        "- **Классификация текстов по темам**: определение категории статьи или документа.\n",
        "- **Анализ тональности в социальных сетях**: автоматическое определение эмоциональной окраски текстовых сообщений.\n"
      ],
      "metadata": {
        "id": "qqSOHv41n6oM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Давайте рассмотрим задачу классификации с использованием логистической регрессии на примере. Допустим, у нас есть следующие данные:\n",
        "\n",
        "### Задача классификации\n",
        "\n",
        "Представим, что у нас есть обучающая выборка, состоящая из четырех документов, которые мы хотим классифицировать как спам или не спам.\n",
        "\n",
        "**Обучающая выборка:**\n",
        "\n",
        "- Документ 1 (спам): \"купить дешево\"\n",
        "- Документ 2 (не спам): \"хорошее качество\"\n",
        "- Документ 3 (спам): \"купить быстро дешево\"\n",
        "- Документ 4 (не спам): \"качество гарантировано\"\n",
        "\n",
        "**Словарь:** \"купить\", \"дешево\", \"хорошее\", \"качество\", \"быстро\", \"гарантировано\".\n",
        "\n",
        "### Шаг 1: Представление данных\n",
        "\n",
        "Преобразуем каждый документ в вектор признаков, используя векторное представление мешка слов на основе нашего словаря.\n",
        "\n",
        "- Документ 1 (спам): $ x^{(1)} = [1, 1, 0, 0, 0, 0] $\n",
        "- Документ 2 (не спам): $ x^{(2)} = [0, 0, 1, 1, 0, 0] $\n",
        "- Документ 3 (спам): $ x^{(3)} = [1, 1, 0, 0, 1, 0] $\n",
        "- Документ 4 (не спам): $ x^{(4)} = [0, 0, 0, 1, 0, 1] $\n",
        "\n",
        "### Шаг 2: Формулирование модели логистической регрессии\n",
        "\n",
        "Логистическая регрессия моделирует вероятность принадлежности документа к классу \"спам\" с помощью сигмоидной функции:\n",
        "\n",
        "$$ P(y = 1 | x) = \\sigma(\\theta^T x) = \\frac{1}{1 + e^{-\\theta^T x}} $$\n",
        "\n",
        "где $ \\theta $ — параметры модели, $ x $ — вектор признаков документа, $ \\sigma(z) $ — сигмоидная функция $ \\sigma(z) = \\frac{1}{1 + e^{-z}} $.\n",
        "\n",
        "### Шаг 3: Функция потерь и обучение модели\n",
        "\n",
        "Функция потерь для логистической регрессии (логистическая функция потерь) выглядит следующим образом:\n",
        "\n",
        "$$ J(\\theta) = -\\frac{1}{m} \\sum_{i=1}^{m} \\left[ y^{(i)} \\log(\\sigma(\\theta^T x^{(i)})) + (1 - y^{(i)}) \\log(1 - \\sigma(\\theta^T x^{(i)})) \\right] $$\n",
        "\n",
        "где $ m $ — количество документов в обучающей выборке, $ y^{(i)} $ — метка класса для документа $ i $.\n",
        "\n",
        "### Шаг 4: Градиентный спуск\n",
        "\n",
        "Для обновления параметров $ \\theta $ используется градиентный спуск:\n",
        "\n",
        "$$ \\theta_j := \\theta_j - \\alpha \\frac{\\partial J(\\theta)}{\\partial \\theta_j} $$\n",
        "\n",
        "где $ \\alpha $ — скорость обучения (learning rate), $ \\frac{\\partial J(\\theta)}{\\partial \\theta_j} $ — градиент функции потерь по параметру $ \\theta_j $.\n",
        "\n",
        "### Шаг 5: Предсказание\n",
        "\n",
        "После обучения модели, для нового документа $ x_{\\text{новый}} $, вероятность принадлежности к классу \"спам\" вычисляется как:\n",
        "\n",
        "$$ P(y = 1 | x_{\\text{новый}}) = \\sigma(\\theta^T x_{\\text{новый}}) $$\n",
        "\n",
        "Если $ P(y = 1 | x_{\\text{новый}}) > 0.5 $, предсказываем, что документ является спамом; если $ P(y = 1 | x_{\\text{новый}}) \\leq 0.5 $, предсказываем, что документ не является спамом.\n",
        "\n",
        "### Пример расчета\n",
        "\n",
        "Предположим, у нас есть новый документ: \"купить качество\". Мы вычисляем его вектор признаков $ x_{\\text{новый}} = [1, 0, 1, 1, 0, 0] $.\n",
        "\n",
        "Чтобы классифицировать его:\n",
        "\n",
        "$$ \\theta = [-1, 0.5, 1, 1, -0.5, 0] $$ (примерный вектор параметров, не реальные числа)\n",
        "\n",
        "$$ \\theta^T x_{\\text{новый}} = -1 \\cdot 1 + 0.5 \\cdot 0 + 1 \\cdot 1 + 1 \\cdot 1 + (-0.5) \\cdot 0 + 0 \\cdot 0 = 1.5 $$\n",
        "\n",
        "Теперь вычисляем вероятность принадлежности к классу \"спам\":\n",
        "\n",
        "$$ P(y = 1 | x_{\\text{новый}}) = \\sigma(1.5) = \\frac{1}{1 + e^{-1.5}} \\approx 0.817 $$\n",
        "\n",
        "Так как $ P(y = 1 | x_{\\text{новый}}) > 0.5 $, предсказываем, что документ \"купить качество\" является спамом.\n",
        "\n",
        "Это основы решения задачи классификации текста с использованием логистической регрессии.\n",
        "\n"
      ],
      "metadata": {
        "id": "oDMunibpqgiW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Реализация на питон"
      ],
      "metadata": {
        "id": "vJ99HbWCxoQr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Пример данных\n",
        "data = {\n",
        "    'text': ['купить дешево', 'хорошее качество', 'купить быстро дешево', 'качество гарантировано',\n",
        "             'дешево и быстро', 'отличное качество', 'купить сразу', 'качество на высоте'],\n",
        "    'label': ['спам', 'не спам', 'спам', 'не спам', 'спам', 'не спам', 'спам', 'не спам']\n",
        "}\n",
        "\n",
        "# Создаем DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Разделение на обучающую и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.25, random_state=42)\n",
        "\n",
        "# Преобразование текста в вектор признаков\n",
        "vectorizer = CountVectorizer()\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "# Создание и обучение модели логистической регрессии\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train_vec, y_train)\n",
        "\n",
        "# Предсказание на тестовой выборке\n",
        "y_pred = model.predict(X_test_vec)\n",
        "\n",
        "# Оценка точности\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy}')\n",
        "\n",
        "# Подробный отчет о классификации\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPE3JeM4wGhE",
        "outputId": "3ca4358a-e91d-483e-9ef0-9a3a0ba5072d"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     не спам       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           1.00         2\n",
            "   macro avg       1.00      1.00      1.00         2\n",
            "weighted avg       1.00      1.00      1.00         2\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Это действительно отличный результат! Модель логистической регрессии показывает идеальную точность на данной небольшой тестовой выборке.\n",
        "\n",
        "Давайте разберем полученные метрики:\n",
        "\n",
        "- **Accuracy**: 1.0 - это означает, что все предсказания модели были абсолютно верными, то есть все объекты были классифицированы правильно.\n",
        "- **Precision, Recall, F1-score**: Поскольку у нас бинарная классификация (\"спам\" и \"не спам\"), все эти метрики равны 1.0 для класса \"не спам\". Это означает, что модель не допустила ни одной ошибки при классификации объектов данного класса.\n",
        "- **Support**: Показывает, что в тестовой выборке было 2 объекта класса \"не спам\".\n",
        "\n",
        "Такой отличный результат может быть связан с тем, что:\n",
        "\n",
        "1. Данные очень хорошо разделяются по классам, и логистическая регрессия может точно выделить границу между классами.\n",
        "2. Размер обучающей и тестовой выборок достаточно мал, поэтому модель \"запоминает\" шаблоны и идеально классифицирует объекты.\n",
        "\n",
        "В реальных задачах чаще всего получить такой высокий уровень точности не удается, и нужно уделять больше внимания оценке модели на независимых данных, анализу ошибок, подбору гиперпараметров и т.д. Но этот пример показывает, что логистическая регрессия является мощным инструментом для бинарной классификации."
      ],
      "metadata": {
        "id": "p5XXCkWzw2lX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для использования результатов классификации можно выполнить следующие шаги:\n",
        "\n",
        "1. Получение предсказаний: После обучения модели, вы можете использовать метод predict() для получения предсказаний на новых данных. Например:\n",
        "\n"
      ],
      "metadata": {
        "id": "uiEJ4Oy_wouJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_text = ['купить срочно дешево', 'качество супер']\n",
        "new_vec = vectorizer.transform(new_text)\n",
        "new_predictions = model.predict(new_vec)\n",
        "print(f'Предсказания: {new_predictions}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "324c707c-1f18-41bb-bd83-23d14f727fd7",
        "id": "jaY_6h-8wouL"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Предсказания: ['спам' 'не спам']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **Принятие решений**:\n",
        "\n",
        "Например, если мы получили предсказание 'спам', мы можем автоматически перемещать сообщение в папку со спамом:\n"
      ],
      "metadata": {
        "id": "yRUwi4qlwouO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for pred in new_predictions:\n",
        "    if pred == 'спам':\n",
        "        print('Сообщение перемещено в папку со спамом')\n",
        "    else:\n",
        "        print('Сообщение добавлено в inbox')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b549e4f-4c4d-4602-83ed-bbdfc031a3cb",
        "id": "XWXNGHtfwouP"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Сообщение перемещено в папку со спамом\n",
            "Сообщение добавлено в inbox\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SVM"
      ],
      "metadata": {
        "id": "qw17BDTPw7Lq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### Введение в SVM (Support Vector Machines)\n",
        "\n",
        "**Support Vector Machines (SVM)** - это мощный алгоритм машинного обучения, который может использоваться для задач классификации, регрессии и других задач машинного обучения. В контексте обработки естественного языка (NLP), SVM часто применяется для задач классификации текстовых данных, таких как определение тональности текста, категоризация документов и других.\n",
        "\n",
        "#### Основные концепции SVM\n",
        "\n",
        "1. **Разделяющая гиперплоскость**: SVM ищет оптимальную гиперплоскость, которая лучше всего разделяет два класса объектов в многомерном пространстве признаков.\n",
        "\n",
        "2. **Опорные вектора**: Это объекты обучающего набора данных, которые находятся на границе между классами и влияют на положение разделяющей гиперплоскости.\n",
        "\n",
        "3. **Ядерные функции**: SVM может использовать различные ядерные функции для преобразования признакового пространства, что позволяет лучше разделять классы в сложных пространствах признаков.\n",
        "\n",
        "#### SVM для NLP\n",
        "\n",
        "В контексте NLP, SVM часто используется для задач классификации текста, таких как:\n",
        "\n",
        "- **Определение тональности текста** (позитивный, негативный, нейтральный).\n",
        "- **Классификация документов** (например, новостные статьи по теме).\n",
        "- **Определение категории текста** (спорт, политика, технологии и т.д.).\n",
        "\n",
        "#### Пример работы SVM для задачи классификации тональности текста\n",
        "\n",
        "Давайте рассмотрим пример применения SVM для задачи определения тональности текста. Предположим, у нас есть набор данных с отзывами о продуктах, и мы хотим определить, положительный ли отзыв или отрицательный на основе текста.\n",
        "\n",
        "##### Шаги:\n",
        "\n",
        "1. **Предобработка данных**: Преобразование текста в векторы признаков (например, с помощью метода TF-IDF или Word2Vec).\n",
        "\n",
        "2. **Построение SVM модели**:\n",
        "\n",
        "   - Пусть у нас есть обучающий набор данных $ D = \\{(x_i, y_i)\\}_{i=1}^{n} $, где $ x_i $ - вектор признаков для i-го текста, $ y_i \\in \\{-1, +1\\} $ - метка класса (негативный или положительный отзыв).\n",
        "   \n",
        "   - SVM ищет гиперплоскость в форме $ \\mathbf{w} \\cdot \\mathbf{x} + b = 0 $, которая разделяет два класса, где $ \\mathbf{w} $ - веса признаков, $ b $ - смещение (bias).\n",
        "\n",
        "   - Целевая функция SVM для разделяющей гиперплоскости:\n",
        "     $$ \\min_{\\mathbf{w}, b} \\frac{1}{2} \\| \\mathbf{w} \\|^2 + C \\sum_{i=1}^{n} \\max(0, 1 - y_i (\\mathbf{w} \\cdot \\mathbf{x}_i + b)) $$\n",
        "     где $ C $ - параметр регуляризации.\n",
        "\n",
        "   - SVM использует ядерные функции для перехода в более высокие пространства признаков, например, полиномиальное ядро $ K(\\mathbf{x}_i, \\mathbf{x}_j) = (\\mathbf{x}_i \\cdot \\mathbf{x}_j + c)^d $ или радиальное базисное функциональное ядро (RBF).\n",
        "\n",
        "3. **Оценка модели**: После обучения модели SVM используется тестовый набор данных для оценки её качества. Можно использовать различные метрики, такие как точность, полнота, F1-мера и ROC-кривая.\n",
        "\n",
        "#### Метрики оценки модели SVM для NLP\n",
        "\n",
        "- **Точность (Accuracy)**: $ \\frac{TP + TN}{TP + TN + FP + FN} $, где $ TP $, $ TN $, $ FP $, $ FN $ - true positive, true negative, false positive, false negative соответственно.\n",
        "\n",
        "- **Полнота (Recall)**: $ \\frac{TP}{TP + FN} $, где $ TP $ - true positive, $ FN $ - false negative.\n",
        "\n",
        "- **Точность (Precision)**: $ \\frac{TP}{TP + FP} $, где $ FP $ - false positive.\n",
        "\n",
        "- **F1-мера (F1-score)**: $ 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}} $, гармоническое среднее точности и полноты.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3x96A-pTx_KW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Пример.**\n",
        "Рассмотрим задачу классификации текстов на примере модели SVM. У нас есть обучающая выборка из четырех документов, которые мы хотим классифицировать как спам или не спам.\n",
        "\n",
        "**Обучающая выборка:**\n",
        "\n",
        "- Документ 1 (спам): \"купить дешево\"\n",
        "- Документ 2 (не спам): \"хорошее качество\"\n",
        "- Документ 3 (спам): \"купить быстро дешево\"\n",
        "- Документ 4 (не спам): \"качество гарантировано\"\n",
        "\n",
        "**Шаг 1: Представление данных**\n",
        "\n",
        "Каждый документ представляется в виде вектора признаков с использованием мешка слов на основе словаря:\n",
        "\n",
        "- Документ 1 (спам): \\( x^{(1)} = [1, 1, 0, 0, 0, 0] \\)\n",
        "- Документ 2 (не спам): \\( x^{(2)} = [0, 0, 1, 1, 0, 0] \\)\n",
        "- Документ 3 (спам): \\( x^{(3)} = [1, 1, 0, 0, 1, 0] \\)\n",
        "- Документ 4 (не спам): \\( x^{(4)} = [0, 0, 0, 1, 0, 1] \\)\n",
        "\n",
        "**Шаг 2: Формулирование модели SVM**\n",
        "\n",
        "Модель SVM строит разделяющую гиперплоскость в многомерном пространстве признаков для классификации.\n",
        "\n",
        "### Шаг 3: Функция решающего правила\n",
        "\n",
        "Цель SVM - найти оптимальную разделяющую гиперплоскость, максимизирующую зазор между классами. Для классификации нового документа \\( x_{\\text{новый}} \\), используем:\n",
        "\n",
        "$$ f(x_{\\text{новый}}) = \\text{sign}(\\theta^T x_{\\text{новый}} + b) $$\n",
        "\n",
        "где \\( \\theta \\) — вектор весов, \\( b \\) — смещение (bias), \\( \\text{sign} \\) — функция знака.\n",
        "\n",
        "### Пример расчета\n",
        "\n",
        "Предположим, у нас есть новый документ \"купить качество\". Его вектор признаков: \\( x_{\\text{новый}} = [1, 0, 1, 1, 0, 0] \\).\n",
        "\n",
        "Чтобы классифицировать его, мы используем полученную модель SVM:\n",
        "\n",
        "$$ \\theta = [1, 0, -1, 1, -0.5, 0] $$ (примерный вектор параметров, не реальные числа)\n",
        "\n",
        "$$ b = 0 $$ (примерное смещение)\n",
        "\n",
        "Вычисляем решающее правило:\n",
        "\n",
        "$$ f(x_{\\text{новый}}) = \\text{sign}(1 \\cdot 1 + 0 \\cdot 0 + (-1) \\cdot 1 + 1 \\cdot 1 + (-0.5) \\cdot 0 + 0 \\cdot 0 + 0) $$\n",
        "\n",
        "$$ f(x_{\\text{новый}}) = \\text{sign}(1) = 1 $$\n",
        "\n",
        "Так как результат \\( f(x_{\\text{новый}}) > 0 \\), мы предсказываем, что документ \"купить качество\" относится к классу спама.\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "L-S_Q9nh4jKr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Таким образом, Support Vector Machines (SVM) представляют собой мощный инструмент для классификации текстовых данных в NLP благодаря своей способности строить эффективные разделяющие гиперплоскости в многомерных пространствах признаков. Важно учитывать выбор ядра и настройку параметров модели для достижения оптимальных результатов."
      ],
      "metadata": {
        "id": "SixIbZYT4jW2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Реализация на Питон."
      ],
      "metadata": {
        "id": "qFRJEvhnSWg9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Пример данных\n",
        "data = {\n",
        "    'text': ['купить дешево', 'хорошее качество', 'купить быстро дешево', 'качество гарантировано',\n",
        "             'дешево и быстро', 'отличное качество', 'купить сразу', 'качество на высоте'],\n",
        "    'label': ['спам', 'не спам', 'спам', 'не спам', 'спам', 'не спам', 'спам', 'не спам']\n",
        "}\n",
        "\n",
        "# Создаем DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Разделение на обучающую и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.25, random_state=42)\n",
        "\n",
        "# Преобразование текста в вектор признаков\n",
        "vectorizer = CountVectorizer()\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "# Создание и обучение модели SVC\n",
        "model = SVC()\n",
        "model.fit(X_train_vec, y_train)\n",
        "\n",
        "# Предсказание на тестовой выборке\n",
        "y_pred = model.predict(X_test_vec)\n",
        "\n",
        "# Оценка точности\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy}')\n",
        "\n",
        "# Подробный отчет о классификации\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "429566f6-6048-479f-9fc4-f410775e64eb",
        "id": "jhXe_dld56jk"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     не спам       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           1.00         2\n",
            "   macro avg       1.00      1.00      1.00         2\n",
            "weighted avg       1.00      1.00      1.00         2\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Это отличный результат! Модель демонстрирует 100% точность на тестовой выборке. Это значит, что она безошибочно классифицирует сообщения как \"спам\" или \"не спам\".\n",
        "\n",
        "Такой высокий уровень производительности на небольшом наборе данных может свидетельствовать о том, что модель хорошо обучилась на этих примерах, однако важно проверить, как она будет работать на более разнообразных и реалистичных данных. Тем не менее, на данном этапе можно сделать следующие выводы:\n",
        "\n",
        "1. Модель SVM успешно справилась с задачей классификации сообщений на \"спам\" и \"не спам\".\n",
        "2. Показатели точности, полноты и F1-меры равны 1.0, что говорит о высоком качестве классификации.\n",
        "3. Модель может быть использована для автоматической фильтрации спама в реальном приложении.\n",
        "\n",
        "Дальнейшие шаги могут включать в себя:\n",
        "\n",
        "- Тестирование модели на более крупных и разнообразных наборах данных, чтобы оценить ее обобщающую способность.\n",
        "- Настройку гиперпараметров модели SVM для улучшения ее производительности.\n",
        "- Сравнение производительности SVM с другими алгоритмами машинного обучения, такими как логистическая регрессия, наивный байесовский классификатор и т.д.\n",
        "- Интеграцию модели в реальное приложение для фильтрации спама.\n",
        "\n",
        "В целом, это очень хороший результат, который демонстрирует эффективность применения SVM для задачи классификации текстовых данных."
      ],
      "metadata": {
        "id": "LrMNsM8RBAqA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для использования результатов классификации можно выполнить следующие шаги:\n",
        "\n",
        "1. Получение предсказаний: После обучения модели, вы можете использовать метод predict() для получения предсказаний на новых данных. Например:\n",
        "\n"
      ],
      "metadata": {
        "id": "kL-b0zze56jn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_text = ['купить срочно дешево', 'качество супер']\n",
        "new_vec = vectorizer.transform(new_text)\n",
        "new_predictions = model.predict(new_vec)\n",
        "print(f'Предсказания: {new_predictions}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ba4de18-9368-43d8-b157-ad95dbb41f2e",
        "id": "Z1VPeeE056jo"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Предсказания: ['спам' 'не спам']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **Принятие решений**:\n",
        "\n",
        "Например, если мы получили предсказание 'спам', мы можем автоматически перемещать сообщение в папку со спамом:\n"
      ],
      "metadata": {
        "id": "uT41Bg-356jp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for pred in new_predictions:\n",
        "    if pred == 'спам':\n",
        "        print('Сообщение перемещено в папку со спамом')\n",
        "    else:\n",
        "        print('Сообщение добавлено в inbox')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "307fe84b-b568-4d92-9b24-ed883c3fd409",
        "id": "XGwtcYB_56jq"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Сообщение перемещено в папку со спамом\n",
            "Сообщение добавлено в inbox\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **K-ближайших соседей (K-Nearest Neighbors, KNN)**"
      ],
      "metadata": {
        "id": "QYEGYg2-BDf7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### Введение в метод KNN\n",
        "\n",
        "Метод KNN является одним из простейших и понятных алгоритмов машинного обучения. Он используется как для задач классификации, так и для задач регрессии. Основная идея метода заключается в том, чтобы классифицировать (или предсказать) новые точки данных на основе их близости к уже известным точкам данных.\n",
        "\n",
        "#### Основные принципы KNN\n",
        "\n",
        "1. **Классификация**: Для классификации новой точки данных определяется её класс на основе классов её ближайших соседей.\n",
        "2. **Регрессия**: Для регрессии новая точка данных получает предсказанное значение на основе значений её ближайших соседей.\n",
        "\n",
        "#### Алгоритм KNN\n",
        "\n",
        "1. **Шаг 1**: Загрузка обучающих данных.\n",
        "2. **Шаг 2**: Выбор числа ближайших соседей $ k $.\n",
        "3. **Шаг 3**: Определение метрики расстояния (например, евклидово расстояние).\n",
        "4. **Шаг 4**: Для новой точки данных вычисление расстояний до всех точек обучающего набора.\n",
        "5. **Шаг 5**: Отбор $ k $ ближайших точек.\n",
        "6. **Шаг 6**: Определение класса (или значения) новой точки данных на основе классов (или значений) её ближайших соседей.\n",
        "\n",
        "#### Метрики расстояния\n",
        "\n",
        "1. **Евклидово расстояние**: Для двух точек $ \\mathbf{p} = (p_1, p_2, \\ldots, p_n) $ и $ \\mathbf{q} = (q_1, q_2, \\ldots, q_n) $:\n",
        "   $$\n",
        "   \\text{EuclideanDistance}(\\mathbf{p}, \\mathbf{q}) = \\sqrt{\\sum_{i=1}^{n} (p_i - q_i)^2}\n",
        "   $$\n",
        "\n",
        "2. **Манхэттенское расстояние**: Для двух точек $ \\mathbf{p} = (p_1, p_2, \\ldots, p_n) $ и $ \\mathbf{q} = (q_1, q_2, \\ldots, q_n) $:\n",
        "   $$\n",
        "   \\text{ManhattanDistance}(\\mathbf{p}, \\mathbf{q}) = \\sum_{i=1}^{n} |p_i - q_i|\n",
        "   $$\n",
        "\n",
        "#### Оценка качества модели\n",
        "\n",
        "Для оценки качества модели KNN важно использовать метрики, такие как:\n",
        "\n",
        "1. **Accuracy (точность)**: Доля правильно классифицированных объектов.\n",
        "   $$\n",
        "   \\text{Accuracy} = \\frac{\\text{Количество правильных предсказаний}}{\\text{Общее количество предсказаний}}\n",
        "   $$\n",
        "\n",
        "2. **Precision (точность)**: Доля верно предсказанных положительных классов среди всех предсказанных положительных классов.\n",
        "   $$\n",
        "   \\text{Precision} = \\frac{\\text{TP}}{\\text{TP} + \\text{FP}}\n",
        "   $$\n",
        "\n",
        "3. **Recall (полнота)**: Доля верно предсказанных положительных классов среди всех реальных положительных классов.\n",
        "   $$\n",
        "   \\text{Recall} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}}\n",
        "   $$\n",
        "\n"
      ],
      "metadata": {
        "id": "Xiks9IRSCdLP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Пример\n",
        "\n",
        "Рассмотрим простой пример классификации текста на спам и не спам.\n",
        "\n",
        "**Обучающая выборка:**\n",
        "\n",
        "- Документ 1 (спам): \"купить дешево\"\n",
        "- Документ 2 (не спам): \"хорошее качество\"\n",
        "- Документ 3 (спам): \"купить быстро дешево\"\n",
        "- Документ 4 (не спам): \"качество гарантировано\"\n",
        "\n",
        "Словарь: \"купить\", \"дешево\", \"хорошее\", \"качество\", \"быстро\", \"гарантировано\".\n",
        "тность делают его популярным в NLP.\n",
        "\n",
        "### Пример классификации текста с использованием KNN\n",
        "\n",
        "#### Обучающая выборка:\n",
        "\n",
        "Представим, что каждый текст представлен вектором TF-IDF (Term Frequency-Inverse Document Frequency) на основе словаря из шести слов: \"купить\", \"дешево\", \"хорошее\", \"качество\", \"быстро\", \"гарантировано\". Давайте представим обучающую выборку в виде векторов TF-IDF.\n",
        "\n",
        "- Документ 1 (спам): \"купить дешево\"  \n",
        "  TF-IDF вектор: $ [1, 1, 0, 0, 0, 0] $\n",
        "\n",
        "- Документ 2 (не спам): \"хорошее качество\"  \n",
        "  TF-IDF вектор: $ [0, 0, 1, 1, 0, 0] $\n",
        "\n",
        "- Документ 3 (спам): \"купить быстро дешево\"  \n",
        "  TF-IDF вектор: $ [1, 1, 0, 0, 1, 0] $\n",
        "\n",
        "- Документ 4 (не спам): \"качество гарантировано\"  \n",
        "  TF-IDF вектор: $ [0, 0, 0, 1, 0, 1] $\n",
        "\n",
        "#### Классификация нового документа \"купить качество\":\n",
        "\n",
        "1. **Вычисление расстояний до всех обучающих примеров** (используем евклидово расстояние в пространстве TF-IDF):\n",
        "\n",
        "   - Документ \"купить качество\" TF-IDF вектор: $ [1, 0, 0, 1, 0, 0] $\n",
        "\n",
        "   Расстояния:\n",
        "   - До Документа 1 (спам): $ \\sqrt{(1-1)^2 + (1-0)^2 + (0-0)^2 + (0-1)^2 + (0-0)^2 + (0-0)^2} = \\sqrt{1} = 1 $\n",
        "   - До Документа 2 (не спам): $ \\sqrt{(0-1)^2 + (0-0)^2 + (1-0)^2 + (1-1)^2 + (0-0)^2 + (0-0)^2} = \\sqrt{2} \\approx 1.414 $\n",
        "   - До Документа 3 (спам): $ \\sqrt{(1-1)^2 + (1-0)^2 + (0-0)^2 + (0-1)^2 + (1-0)^2 + (0-0)^2} = \\sqrt{1} = 1 $\n",
        "   - До Документа 4 (не спам): $ \\sqrt{(0-1)^2 + (0-0)^2 + (0-0)^2 + (1-1)^2 + (0-0)^2 + (0-0)^2} = \\sqrt{1} = 1 $\n",
        "\n",
        "2. **Выбор $ k $ ближайших соседей**:\n",
        "\n",
        "   Пусть $ k = 3 $. Ближайшие документы по расстоянию: Документ 1 (спам), Документ 3 (спам), Документ 4 (не спам).\n",
        "\n",
        "3. **Определение класса нового документа**:\n",
        "\n",
        "   - Документ 1 (спам)\n",
        "   - Документ 3 (спам)\n",
        "   - Документ 4 (не спам)\n",
        "\n",
        "   Исходя из большинства среди $ k $ ближайших соседей, новый документ \"купить качество\" будет классифицирован как \"спам\", так как 2 из 3 ближайших соседей относятся к классу \"спам\".\n",
        "\n",
        "#### Заключение\n",
        "\n",
        "Метод KNN представляет собой простой и эффективный алгоритм для классификации текстов на основе их схожести с обучающими примерами. Он особенно полезен в NLP благодаря простоте векторизации текстовых данных и непосредственной работы с метриками сходства.\n"
      ],
      "metadata": {
        "id": "FjR_c5epGai4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Реализация на питон"
      ],
      "metadata": {
        "id": "sJwmX04BHN1c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Пример данных\n",
        "data = {\n",
        "    'text': ['купить дешево', 'хорошее качество', 'купить быстро дешево', 'качество гарантировано',\n",
        "             'дешево и быстро', 'отличное качество', 'купить сразу', 'качество на высоте'],\n",
        "    'label': ['спам', 'не спам', 'спам', 'не спам', 'спам', 'не спам', 'спам', 'не спам']\n",
        "}\n",
        "\n",
        "# Создаем DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Разделение на обучающую и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.25, random_state=42)\n",
        "\n",
        "# Преобразование текста в вектор признаков\n",
        "vectorizer = CountVectorizer()\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "# Создание и обучение модели KNN\n",
        "model = KNeighborsClassifier()\n",
        "model.fit(X_train_vec, y_train)\n",
        "\n",
        "# Предсказание на тестовой выборке\n",
        "y_pred = model.predict(X_test_vec)\n",
        "\n",
        "# Оценка точности\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy}')\n",
        "\n",
        "# Подробный отчет о классификации\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11e77881-ac50-40d4-cc3a-ce1e8a13c743",
        "id": "2cLeu9FaHeWs"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     не спам       0.00      0.00      0.00       2.0\n",
            "        спам       0.00      0.00      0.00       0.0\n",
            "\n",
            "    accuracy                           0.00       2.0\n",
            "   macro avg       0.00      0.00      0.00       2.0\n",
            "weighted avg       0.00      0.00      0.00       2.0\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ошибка с нулевой точностью и пустым отчетом о классификации указывает на проблему в данных или модели.\n",
        "\n",
        "Давайте оптимизируем и упростим код, обеспечив корректное разделение данных и добавив проверку для сбалансированности классов в обучающей и тестовой выборках.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Оптимизированный код"
      ],
      "metadata": {
        "id": "U9SrITPzJw_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.utils import resample\n",
        "\n",
        "# Пример данных\n",
        "data = {\n",
        "    'text': ['купить дешево', 'хорошее качество', 'купить быстро дешево', 'качество гарантировано',\n",
        "             'дешево и быстро', 'отличное качество', 'купить сразу', 'качество на высоте'],\n",
        "    'label': ['спам', 'не спам', 'спам', 'не спам', 'спам', 'не спам', 'спам', 'не спам']\n",
        "}\n",
        "\n",
        "# Создаем DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Балансировка данных с помощью ресемплинга\n",
        "df_majority = df[df.label == 'не спам']\n",
        "df_minority = df[df.label == 'спам']\n",
        "\n",
        "# Увеличение меньшинства с ресемплингом\n",
        "df_minority_upsampled = resample(df_minority,\n",
        "                                 replace=True,     # Увеличиваем с повторением\n",
        "                                 n_samples=len(df_majority),    # Увеличиваем до числа в классе \"не спам\"\n",
        "                                 random_state=42)\n",
        "\n",
        "# Комбинируем обратно сбалансированные данные\n",
        "df_balanced = pd.concat([df_majority, df_minority_upsampled])\n",
        "\n",
        "# Разделение на обучающую и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_balanced['text'], df_balanced['label'], test_size=0.25, random_state=42)\n",
        "\n",
        "# Преобразование текста в вектор признаков\n",
        "vectorizer = CountVectorizer()\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "# Создание и обучение модели KNN\n",
        "model = KNeighborsClassifier(n_neighbors=3)  # Выбираем k=3 для этого примера\n",
        "model.fit(X_train_vec, y_train)\n",
        "\n",
        "# Предсказание на тестовой выборке\n",
        "y_pred = model.predict(X_test_vec)\n",
        "\n",
        "# Оценка точности\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy}')\n",
        "\n",
        "# Подробный отчет о классификации\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSwvcKDwJ_Z_",
        "outputId": "0135b6e8-3be8-4f8f-988c-09727315e5f7"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     не спам       1.00      1.00      1.00         1\n",
            "        спам       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           1.00         2\n",
            "   macro avg       1.00      1.00      1.00         2\n",
            "weighted avg       1.00      1.00      1.00         2\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### Объяснение изменений\n",
        "\n",
        "1. **Балансировка данных**: Добавлен шаг балансировки данных с помощью ресемплинга, чтобы гарантировать, что обучающая выборка содержит одинаковое количество примеров каждого класса. Это помогает избежать проблем с несбалансированными классами, что может привести к нулевой точности.\n",
        "   \n",
        "2. **Оптимизация импорта и использования sklearn**: Используются наиболее подходящие методы для балансировки данных и разделения их на обучающую и тестовую выборки.\n",
        "\n",
        "3. **Настройка модели KNN**: Задали параметр `n_neighbors=3` для модели KNN, чтобы продемонстрировать выбор числа ближайших соседей.\n",
        "\n",
        "### Примечание\n",
        "\n",
        "Если данные в реальных сценариях остаются несбалансированными, можно использовать дополнительные методы, такие как взвешивание классов или специальные метрики оценки, которые лучше справляются с несбалансированными наборами данных."
      ],
      "metadata": {
        "id": "WJzv8LvYK5Qa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Основываясь на предоставленных результатах, где точность модели составляет 1.0 (100%), а отчет о классификации показывает идеальные результаты (precision, recall и f1-score равны 1.0 для обоих классов), можно сделать вывод, что модель KNN отлично справилась с классификацией текстовых данных на \"спам\" и \"не спам\" в этом конкретном примере.\n",
        "\n",
        "Ключевые моменты:\n",
        "\n",
        "1. **Точность (Accuracy)**: Модель правильно классифицировала все примеры в тестовой выборке, что говорит о ее высокой производительности.\n",
        "\n",
        "2. **Отчет о классификации (Classification Report)**:\n",
        "   - Precision (точность): 1.0 для обоих классов, что означает, что модель не допускает ложноположительных срабатываний.\n",
        "   - Recall (полнота): 1.0 для обоих классов, что указывает на то, что модель не пропускает ни одного примера.\n",
        "   - F1-score (гармоническое среднее precision и recall): 1.0 для обоих классов, что является идеальным результатом.\n",
        "\n",
        "Такие высокие показатели на небольшом тестовом наборе данных свидетельствуют о том, что модель KNN отлично справляется с данной задачей классификации текста на \"спам\" и \"не спам\". Однако для более объективной оценки модели необходимо протестировать ее на более обширных и разнообразных данных."
      ],
      "metadata": {
        "id": "zeLbWMU_Kx-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для использования результатов классификации можно выполнить следующие шаги:\n",
        "\n",
        "1. Получение предсказаний: После обучения модели, вы можете использовать метод predict() для получения предсказаний на новых данных. Например:\n",
        "\n"
      ],
      "metadata": {
        "id": "pZwwxkYLHeWt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_text = ['купить срочно дешево', 'качество супер']\n",
        "new_vec = vectorizer.transform(new_text)\n",
        "new_predictions = model.predict(new_vec)\n",
        "print(f'Предсказания: {new_predictions}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "943c98dc-caef-4a23-f43d-53ad53360b0b",
        "id": "-rQDGyLUHeWu"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Предсказания: ['спам' 'не спам']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **Принятие решений**:\n",
        "\n",
        "Например, если мы получили предсказание 'спам', мы можем автоматически перемещать сообщение в папку со спамом:\n"
      ],
      "metadata": {
        "id": "DdYH0943HeWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for pred in new_predictions:\n",
        "    if pred == 'спам':\n",
        "        print('Сообщение перемещено в папку со спамом')\n",
        "    else:\n",
        "        print('Сообщение добавлено в inbox')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ec881d5-3861-457e-f53c-79d4c722a22f",
        "id": "SVv6zeTuHeWw"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Сообщение перемещено в папку со спамом\n",
            "Сообщение добавлено в inbox\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Деревья решений (Decision Trees)**"
      ],
      "metadata": {
        "id": "My8TRNm2CdPp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Введение в деревья решений\n",
        "\n",
        "Деревья решений (Decision Trees) — это алгоритмы машинного обучения, используемые для классификации и регрессии. Они основаны на построении модели, представляющей собой дерево, где каждый узел соответствует проверке на атрибут, каждое ветвление — исходу проверки, а каждый лист — метке класса или значению регрессии. Деревья решений обладают следующими преимуществами:\n",
        "- Простота понимания и интерпретации.\n",
        "- Способность работать с данными, содержащими как числовые, так и категориальные признаки.\n",
        "- Возможность выявлять важные признаки.\n",
        "\n",
        "### Основные элементы деревьев решений\n",
        "\n",
        "1. **Корневой узел (Root Node)**: Начальный узел дерева, который представляет весь датасет.\n",
        "2. **Внутренние узлы (Internal Nodes)**: Узлы, представляющие проверку на атрибут.\n",
        "3. **Листья (Leaf Nodes)**: Узлы, представляющие метки классов или значения регрессии.\n",
        "4. **Ветви (Branches)**: Результаты проверок, соединяющие узлы.\n",
        "\n",
        "### Алгоритм построения дерева решений\n",
        "\n",
        "Основной алгоритм построения дерева решений — это рекурсивный процесс, включающий:\n",
        "1. Выбор наилучшего признака для разделения данных.\n",
        "2. Разделение данных на основе выбранного признака.\n",
        "3. Рекурсивное построение поддеревьев для каждой части данных.\n",
        "4. Остановка, когда все данные в узле имеют одну метку или когда дальнейшее разделение не приносит значительных улучшений.\n",
        "\n",
        "### Критерии выбора признаков\n",
        "\n",
        "Для выбора наилучшего признака используются различные метрики. Наиболее распространенные:\n",
        "\n",
        "#### Информационная выгода (Information Gain)\n",
        "\n",
        "$$\n",
        "IG(D, A) = H(D) - \\sum_{v \\in \\text{Values}(A)} \\frac{|D_v|}{|D|} H(D_v)\n",
        "$$\n",
        "\n",
        "где:\n",
        "- $IG(D, A)$ — информационная выгода признака $A$ для датасета $D$.\n",
        "- $H(D)$ — энтропия датасета $D$.\n",
        "- $D_v$ — подмножество $D$, где признак $A$ принимает значение $v$.\n",
        "\n",
        "Энтропия:\n",
        "\n",
        "$$\n",
        "H(D) = - \\sum_{i=1}^n p_i \\log_2(p_i)\n",
        "$$\n",
        "\n",
        "где:\n",
        "- $p_i$ — вероятность класса $i$ в датасете $D$.\n",
        "\n",
        "#### Индекс Джини (Gini Index)\n",
        "\n",
        "$$\n",
        "Gini(D) = 1 - \\sum_{i=1}^n p_i^2\n",
        "$$\n",
        "\n",
        "где:\n",
        "- $p_i$ — вероятность класса $i$ в датасете $D$.\n",
        "\n",
        "### Построение дерева решений для NLP\n",
        "\n",
        "В Natural Language Processing (NLP), деревья решений могут быть использованы для различных задач, таких как классификация текста, определение тональности, категоризация документов и др.\n",
        "\n",
        "#### Пример задачи: Классификация текста\n",
        "\n",
        "Допустим, у нас есть набор данных, состоящий из текстов, помеченных как \"позитивные\" или \"негативные\". Мы будем строить дерево решений для классификации новых текстов.\n",
        "\n",
        "1. **Предобработка текста**: Преобразование текста в числовые признаки.\n",
        "    - Токенизация.\n",
        "    - Удаление стоп-слов.\n",
        "    - Стемминг/лемматизация.\n",
        "    - Векторизация (например, использование TF-IDF или мешка слов).\n",
        "\n",
        "2. **Формирование признаков**: Признаки могут включать частоту слов, наличие/отсутствие определенных слов, биграммы и т.д.\n",
        "\n",
        "#### Пример с формулами\n",
        "\n",
        "1. **Исходные данные**:\n",
        "\n",
        "| Текст              | Метка    |\n",
        "|--------------------|----------|\n",
        "| \"Мне понравился фильм\" | Позитивный |\n",
        "| \"Фильм был ужасен\"      | Негативный |\n",
        "| \"Очень хороший фильм\"   | Позитивный |\n",
        "| \"Очень плохой фильм\"    | Негативный |\n",
        "\n",
        "2. **Векторизация** (TF-IDF или мешок слов):\n",
        "\n",
        "| Текст              | понравился | фильм | ужасен | хороший | плохой | Метка    |\n",
        "|--------------------|------------|-------|--------|---------|--------|----------|\n",
        "| \"Мне понравился фильм\" | 1          | 1     | 0      | 0       | 0      | Позитивный |\n",
        "| \"Фильм был ужасен\"      | 0          | 1     | 1      | 0       | 0      | Негативный |\n",
        "| \"Очень хороший фильм\"   | 0          | 1     | 0      | 1       | 0      | Позитивный |\n",
        "| \"Очень плохой фильм\"    | 0          | 1     | 0      | 0       | 1      | Негативный |\n",
        "\n",
        "3. **Построение дерева решений**:\n",
        "\n",
        "a. **Корневой узел**: Выбор признака с максимальной информационной выгодой.\n",
        "\n",
        "$$\n",
        "IG(D, \\text{фильм}) = H(D) - \\left( \\frac{3}{4} H(D_{\\text{фильм}=1}) + \\frac{1}{4} H(D_{\\text{фильм}=0}) \\right)\n",
        "$$\n",
        "\n",
        "$$\n",
        "H(D) = - \\left( \\frac{2}{4} \\log_2 \\left( \\frac{2}{4} \\right) + \\frac{2}{4} \\log_2 \\left( \\frac{2}{4} \\right) \\right) = 1\n",
        "$$\n",
        "\n",
        "$$\n",
        "H(D_{\\text{фильм}=1}) = - \\left( \\frac{2}{3} \\log_2 \\left( \\frac{2}{3} \\right) + \\frac{1}{3} \\log_2 \\left( \\frac{1}{3} \\right) \\right) \\approx 0.918\n",
        "$$\n",
        "\n",
        "$$\n",
        "H(D_{\\text{фильм}=0}) = 0 \\quad \\text{(все элементы одного класса)}\n",
        "$$\n",
        "\n",
        "$$\n",
        "IG(D, \\text{фильм}) = 1 - \\left( \\frac{3}{4} \\cdot 0.918 + \\frac{1}{4} \\cdot 0 \\right) \\approx 0.311\n",
        "$$\n",
        "\n",
        "b. **Разделение данных**:\n",
        "\n",
        "```\n",
        "Если \"фильм\" = 1:\n",
        "    Далее выбираем следующий признак.\n",
        "Иначе:\n",
        "    Метка = \"Позитивный\"\n",
        "```\n",
        "\n",
        "### Оценка качества модели\n",
        "\n",
        "1. **Точность (Accuracy)**:\n",
        "\n",
        "$$\n",
        "\\text{Accuracy} = \\frac{\\text{Количество верных предсказаний}}{\\text{Общее количество примеров}}\n",
        "$$\n",
        "\n",
        "2. **Матрица ошибок (Confusion Matrix)**: Таблица, показывающая верные и неверные предсказания для каждого класса.\n",
        "\n",
        "3. **Метрики на основе матрицы ошибок**:\n",
        "    - **Precision**: Точность предсказания положительного класса.\n",
        "    - **Recall**: Полнота предсказания положительного класса.\n",
        "    - **F1-Score**: Гармоническое среднее между Precision и Recall.\n",
        "\n",
        "$$\n",
        "\\text{Precision} = \\frac{TP}{TP + FP}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\text{Recall} = \\frac{TP}{TP + FN}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\text{F1-Score} = \\frac{2 \\cdot \\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
        "$$\n",
        "\n",
        "где:\n",
        "- $TP$ — истинные положительные.\n",
        "- $FP$ — ложные положительные.\n",
        "- $FN$ — ложные отрицательные.\n",
        "\n"
      ],
      "metadata": {
        "id": "cRXV0W2tCdmf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Пример классификации текста с использованием Decision Trees\n",
        "\n",
        "#### Обучающая выборка\n",
        "\n",
        "Рассмотрим пример классификации текстов на спам и не спам. Пусть у нас есть следующие документы:\n",
        "\n",
        "- Документ 1 (спам): \"купить дешево\"\n",
        "- Документ 2 (не спам): \"хорошее качество\"\n",
        "- Документ 3 (спам): \"купить быстро дешево\"\n",
        "- Документ 4 (не спам): \"качество гарантировано\"\n",
        "\n",
        "Словарь: \"купить\", \"дешево\", \"хорошее\", \"качество\", \"быстро\", \"гарантировано\".\n",
        "\n",
        "Каждый документ представлен вектором TF-IDF на основе этого словаря:\n",
        "\n",
        "- Документ 1 (спам): \"купить дешево\"  \n",
        "  TF-IDF вектор: $ [1, 1, 0, 0, 0, 0] $\n",
        "\n",
        "- Документ 2 (не спам): \"хорошее качество\"  \n",
        "  TF-IDF вектор: $ [0, 0, 1, 1, 0, 0] $\n",
        "\n",
        "- Документ 3 (спам): \"купить быстро дешево\"  \n",
        "  TF-IDF вектор: $ [1, 1, 0, 0, 1, 0] $\n",
        "\n",
        "- Документ 4 (не спам): \"качество гарантировано\"  \n",
        "  TF-IDF вектор: $ [0, 0, 0, 1, 0, 1] $\n",
        "\n",
        "#### Построение дерева решений для классификации текста\n",
        "\n",
        "1. **Выбор начального признака для разделения** (например, используем информационную выгоду).\n",
        "\n",
        "2. **Разделение данных на основе выбранного признака**.\n",
        "\n",
        "3. **Повторение шагов 1 и 2 для каждого подмножества данных до тех пор, пока все данные в узле не будут принадлежать одному классу или не будут исчерпаны все признаки**.\n",
        "\n",
        "Рассмотрим более подробно построение дерева на примере нашей обучающей выборки.\n",
        "\n",
        "1. **Исходные данные**:\n",
        "\n",
        "| Документ            | купить | дешево | хорошее | качество | быстро | гарантировано | Метка    |\n",
        "|---------------------|--------|--------|---------|----------|--------|---------------|----------|\n",
        "| \"купить дешево\"     | 1      | 1      | 0       | 0        | 0      | 0             | Спам     |\n",
        "| \"хорошее качество\"  | 0      | 0      | 1       | 1        | 0      | 0             | Не спам  |\n",
        "| \"купить быстро дешево\" | 1    | 1      | 0       | 0        | 1      | 0             | Спам     |\n",
        "| \"качество гарантировано\" | 0   | 0      | 0       | 1        | 0      | 1             | Не спам  |\n",
        "\n",
        "2. **Выбор признака для первого разделения**:\n",
        "\n",
        "   Рассчитаем информационную выгоду для каждого признака:\n",
        "\n",
        "   - Энтропия начального датасета:\n",
        "     $$\n",
        "     H(D) = - \\left( \\frac{2}{4} \\log_2 \\left( \\frac{2}{4} \\right) + \\frac{2}{4} \\log_2 \\left( \\frac{2}{4} \\right) \\right) = 1\n",
        "     $$\n",
        "\n",
        "   - Информационная выгода для признака \"купить\":\n",
        "     $$\n",
        "     IG(D, \\text{купить}) = 1 - \\left( \\frac{2}{4} H(D_{\\text{купить}=1}) + \\frac{2}{4} H(D_{\\text{купить}=0}) \\right)\n",
        "     $$\n",
        "     Подмножество $D_{\\text{купить}=1}$:\n",
        "     $$\n",
        "     H(D_{\\text{купить}=1}) = - \\left( \\frac{2}{2} \\log_2 \\left( \\frac{2}{2} \\right) \\right) = 0\n",
        "     $$\n",
        "     Подмножество $D_{\\text{купить}=0}$:\n",
        "     $$\n",
        "     H(D_{\\text{купить}=0}) = - \\left( \\frac{2}{2} \\log_2 \\left( \\frac{2}{2} \\right) \\right) = 0\n",
        "     $$\n",
        "     Таким образом,\n",
        "     $$\n",
        "     IG(D, \\text{купить}) = 1 - 0 = 1\n",
        "     $$\n",
        "\n",
        "3. **Разделение данных по признаку \"купить\"**:\n",
        "\n",
        "   $$\n",
        "   \\begin{cases}\n",
        "   \\text{Если \"купить\" = 1, то Спам} \\\\\n",
        "   \\text{Если \"купить\" = 0, то Не спам}\n",
        "   \\end{cases}\n",
        "   $$\n",
        "\n",
        "   После первого разделения:\n",
        "\n",
        "   | купить | дешево | хорошее | качество | быстро | гарантировано | Метка    |\n",
        "   |--------|--------|---------|----------|--------|---------------|----------|\n",
        "   | 1      | 1      | 0       | 0        | 0      | 0             | Спам     |\n",
        "   | 1      | 1      | 0       | 0        | 1      | 0             | Спам     |\n",
        "   | 0      | 0      | 1       | 1        | 0      | 0             | Не спам  |\n",
        "   | 0      | 0      | 0       | 1        | 0      | 1             | Не спам  |\n",
        "\n",
        "   Так как энтропия обоих подмножеств равна 0, дальнейшего разделения не требуется.\n",
        "\n",
        "### Заключение\n",
        "\n",
        "Метод деревьев решений позволяет эффективно классифицировать текстовые данные, выявляя ключевые признаки, определяющие классы. В примере, рассматриваемом выше, решение было найдено с помощью одного шага, так как один из признаков полностью разделял данные на классы. Этот подход легко интерпретируем и может быть полезен для анализа важности признаков и построения простых, но мощных моделей классификации в задачах NLP.\n"
      ],
      "metadata": {
        "id": "EYNJ9WvHRh9V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Реализация на Питон"
      ],
      "metadata": {
        "id": "eX8kg2iKRvQS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Пример данных\n",
        "data = {\n",
        "    'text': ['купить дешево', 'хорошее качество', 'купить быстро дешево', 'качество гарантировано',\n",
        "             'дешево и быстро', 'отличное качество', 'купить сразу', 'качество на высоте'],\n",
        "    'label': ['спам', 'не спам', 'спам', 'не спам', 'спам', 'не спам', 'спам', 'не спам']\n",
        "}\n",
        "\n",
        "# Создаем DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Разделение на обучающую и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.25, random_state=42)\n",
        "\n",
        "# Преобразование текста в вектор признаков\n",
        "vectorizer = CountVectorizer()\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "# Создание и обучение модели Decision Tree\n",
        "model = DecisionTreeClassifier()\n",
        "model.fit(X_train_vec, y_train)\n",
        "\n",
        "# Предсказание на тестовой выборке\n",
        "y_pred = model.predict(X_test_vec)\n",
        "\n",
        "# Оценка точности\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy}')\n",
        "\n",
        "# Подробный отчет о классификации\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91baecac-65ed-4daf-cf0a-9385c3ab842f",
        "id": "hwQEIaAvSbZ2"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     не спам       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           1.00         2\n",
            "   macro avg       1.00      1.00      1.00         2\n",
            "weighted avg       1.00      1.00      1.00         2\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Отлично, наша модель показывает очень впечатляющие результаты! Достигнутая точность в 100% говорит о том, что модель на основе Decision Tree превосходно справляется с классификацией данных в вашем примере.\n",
        "\n",
        "Подробный отчет о классификации также подтверждает высокую эффективность модели:\n",
        "\n",
        "- Для класса \"не спам\" (единственный неспамный класс в данном примере) показатели precision, recall и f1-score равны 1.0, что говорит об идеальной классификации.\n",
        "- Общая точность (accuracy) составляет 1.0, или 100%, что означает, что все примеры были классифицированы верно.\n",
        "- Значения macro avg и weighted avg также равны 1.0, что дополнительно свидетельствует о высоком качестве модели.\n",
        "\n",
        "Такие результаты на таком небольшом наборе данных довольно ожидаемы, поскольку простая модель Decision Tree может легко \"выучить\" такие простые правила классификации. Тем не менее, это хороший пример того, как можно быстро создать работающую модель для решения задачи классификации текстовых данных.\n",
        "\n",
        "В реальных задачах, где данные будут более сложными и неоднозначными, потребуется более тщательный подход к выбору и настройке модели, а также к оценке ее производительности на независимых тестовых данных. Но этот пример демонстрирует, как можно быстро приступить к решению подобных задач с помощью библиотеки scikit-learn."
      ],
      "metadata": {
        "id": "zLTozcFBTgk-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для использования результатов классификации можно выполнить следующие шаги:\n",
        "\n",
        "1. Получение предсказаний: После обучения модели, вы можете использовать метод predict() для получения предсказаний на новых данных. Например:\n",
        "\n"
      ],
      "metadata": {
        "id": "eBRq92C0SbaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_text = ['купить срочно дешево', 'качество супер']\n",
        "new_vec = vectorizer.transform(new_text)\n",
        "new_predictions = model.predict(new_vec)\n",
        "print(f'Предсказания: {new_predictions}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16389318-50cd-43ea-83f3-1112c49f50f0",
        "id": "mhP6LrNlSbaF"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Предсказания: ['спам' 'не спам']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **Принятие решений**:\n",
        "\n",
        "Например, если мы получили предсказание 'спам', мы можем автоматически перемещать сообщение в папку со спамом:\n"
      ],
      "metadata": {
        "id": "KjiwCzRGSbaF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for pred in new_predictions:\n",
        "    if pred == 'спам':\n",
        "        print('Сообщение перемещено в папку со спамом')\n",
        "    else:\n",
        "        print('Сообщение добавлено в inbox')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2101d9b-b553-49ec-9bcf-6c151449836c",
        "id": "giBQNT7oSbaG"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Сообщение перемещено в папку со спамом\n",
            "Сообщение добавлено в inbox\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Случайный лес (Random Forest)**\n"
      ],
      "metadata": {
        "id": "ybsWE6kRCdpt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Случайный лес (Random Forest)\n",
        "\n",
        "### Введение\n",
        "\n",
        "Случайный лес (Random Forest) - это ансамблевый метод машинного обучения, который используется для классификации и регрессии. Он строит множество деревьев решений на подмножествах данных и агрегирует их результаты для получения финального предсказания. Этот метод обладает высокой точностью и устойчивостью к переобучению.\n",
        "\n",
        "### Основные концепции\n",
        "\n",
        "#### 1. Дерево решений\n",
        "Дерево решений - это алгоритм, который принимает решения на основе ряда вопросов. В контексте NLP дерево решений может использоваться для классификации текста по различным категориям.\n",
        "\n",
        "#### 2. Ансамбль методов\n",
        "Ансамбль методов предполагает использование нескольких моделей для улучшения общей производительности. В случае случайного леса создается множество деревьев решений, и их предсказания объединяются.\n",
        "\n",
        "### Формирование случайного леса\n",
        "\n",
        "#### 1. Бутаггинг (Bootstrap Aggregating)\n",
        "Бутаггинг заключается в создании множества выборок с возвращением из исходного набора данных. Для каждой выборки строится дерево решений.\n",
        "\n",
        "#### 2. Строительство деревьев решений\n",
        "Для каждого дерева:\n",
        "- Выбирается случайная подвыборка признаков.\n",
        "- Строится дерево решений до определенной глубины или пока не будут выполнены другие условия остановки.\n",
        "\n",
        "### Формулы\n",
        "\n",
        "#### 1. Энтропия и информационная выгода\n",
        "\n",
        "Энтропия $ H $ для бинарной классификации:\n",
        "\n",
        "$$ H(D) = -p_1 \\log_2(p_1) - p_2 \\log_2(p_2) $$\n",
        "\n",
        "где $ p_1 $ и $ p_2 $ - доли классов в наборе данных $ D $.\n",
        "\n",
        "Информационная выгода $ IG $ от разбиения набора данных $ D $ на подмножества $ D_1 $ и $ D_2 $:\n",
        "\n",
        "$$ IG(D, A) = H(D) - \\sum_{i=1}^{k} \\frac{|D_i|}{|D|} H(D_i) $$\n",
        "\n",
        "#### 2. Gini индекс\n",
        "\n",
        "Индекс Gini для набора данных $ D $:\n",
        "\n",
        "$$ Gini(D) = 1 - \\sum_{i=1}^{n} p_i^2 $$\n",
        "\n",
        "где $ p_i $ - доля объектов класса $ i $ в наборе данных $ D $.\n",
        "\n",
        "### Метрики\n",
        "\n",
        "#### 1. Точность (Accuracy)\n",
        "\n",
        "$$ \\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN} $$\n",
        "\n",
        "где $ TP $ - истинно положительные, $ TN $ - истинно отрицательные, $ FP $ - ложно положительные, $ FN $ - ложно отрицательные.\n",
        "\n",
        "#### 2. Precision, Recall и F1-score\n",
        "\n",
        "$$ \\text{Precision} = \\frac{TP}{TP + FP} $$\n",
        "$$ \\text{Recall} = \\frac{TP}{TP + FN} $$\n",
        "$$ \\text{F1-score} = \\frac{2 \\cdot \\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}} $$\n"
      ],
      "metadata": {
        "id": "6ObfXOm1CrKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Пример классификации текста с использованием Decision Trees\n",
        "\n",
        "#### Обучающая выборка\n",
        "\n",
        "Рассмотрим пример классификации текстов на спам и не спам. Пусть у нас есть следующие документы:\n",
        "\n",
        "- Документ 1 (спам): \"купить дешево\"\n",
        "- Документ 2 (не спам): \"хорошее качество\"\n",
        "- Документ 3 (спам): \"купить быстро дешево\"\n",
        "- Документ 4 (не спам): \"качество гарантировано\"\n",
        "\n",
        "Словарь: \"купить\", \"дешево\", \"хорошее\", \"качество\", \"быстро\", \"гарантировано\".\n",
        "\n",
        "\n",
        "\n",
        "Для построения дерева решений будем использовать информационную энтропию. Энтропия множества $$S$$ вычисляется по формуле:\n",
        "\n",
        "$$H(S) = -\\sum_{i=1}^{c}p_i\\log_2(p_i)$$\n",
        "\n",
        "где $c$ - количество классов, а $p_i$ - вероятность принадлежности к $i$-му классу.\n",
        "\n",
        "Шаги построения дерева:\n",
        "\n",
        "1. Вычислим энтропию всей обучающей выборки:\n",
        "   * Всего 4 документа, из них 2 спама и 2 не спама\n",
        "   * $$H(S) = -\\frac{2}{4}\\log_2(\\frac{2}{4}) - \\frac{2}{4}\\log_2(\\frac{2}{4}) = 1$$\n",
        "\n",
        "2. Выберем признак для разбиения, который уменьшает энтропию наиболее сильно. Рассмотрим признак \"купить\":\n",
        "   * Для документов, где \"купить\" = 1, все 2 относятся к спаму, энтропия 0\n",
        "   * Для документов, где \"купить\" = 0, 2 не спама и 0 спамов, энтропия 0\n",
        "   * Взвешенная энтропия: $$H(S|\"купить\") = \\frac{2}{4}\\cdot 0 + \\frac{2}{4}\\cdot 0 = 0$$\n",
        "   * Информационный выигрыш: $$Gain(\"купить\") = H(S) - H(S|\"купить\") = 1 - 0 = 1$$\n",
        "\n",
        "3. Поскольку признак \"купить\" полностью разделяет данные, построение дерева на этом заканчивается.\n",
        "\n",
        "Результирующее дерево решений:\n",
        "\n",
        "$$\n",
        "\\begin{array}{c}\n",
        "    \\text{купить} \\\\\n",
        "    / \\quad \\\\\n",
        "    1 \\quad 0 \\\\\n",
        "    \\text{спам} \\quad \\text{не спам}\n",
        "\\end{array}\n",
        "$$\n",
        "\n",
        "Таким образом, мы построили дерево решений для классификации текстов на спам и не спам, используя формулу информационной энтропии.\n",
        "\n"
      ],
      "metadata": {
        "id": "kEqBr1QbXpVL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Пример данных\n",
        "data = {\n",
        "    'text': ['купить дешево', 'хорошее качество', 'купить быстро дешево', 'качество гарантировано',\n",
        "             'дешево и быстро', 'отличное качество', 'купить сразу', 'качество на высоте'],\n",
        "    'label': ['спам', 'не спам', 'спам', 'не спам', 'спам', 'не спам', 'спам', 'не спам']\n",
        "}\n",
        "\n",
        "# Создаем DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Разделение на обучающую и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.25, random_state=42)\n",
        "\n",
        "# Преобразование текста в вектор признаков\n",
        "vectorizer = CountVectorizer()\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "# Создание и обучение модели Random Forest\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train_vec, y_train)\n",
        "\n",
        "# Предсказание на тестовой выборке\n",
        "y_pred = model.predict(X_test_vec)\n",
        "\n",
        "# Оценка точности\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy}')\n",
        "\n",
        "# Подробный отчет о классификации\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "448207a7-4ae8-4bb1-f47c-12670f2e28a9",
        "id": "v5bL5z1nXpyY"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     не спам       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           1.00         2\n",
            "   macro avg       1.00      1.00      1.00         2\n",
            "weighted avg       1.00      1.00      1.00         2\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Из представленных результатов видно что - модель Random Forest показывает 100% точность на тестовой выборке. Это отличный результат!\n",
        "\n",
        "Важно отметить, что при таком небольшом наборе данных, модель может показывать очень высокую точность, но при применении на более реалистичных, больших и сложных данных, ее производительность может отличаться. Тем не менее, это хороший старт, и вы можете попробовать улучшить модель, экспериментируя с гиперпараметрами, добавляя больше данных для обучения или применяя другие алгоритмы машинного обучения."
      ],
      "metadata": {
        "id": "TTAWyjZhYDjF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для использования результатов классификации можно выполнить следующие шаги:\n",
        "\n",
        "1. Получение предсказаний: После обучения модели, вы можете использовать метод predict() для получения предсказаний на новых данных. Например:\n",
        "\n"
      ],
      "metadata": {
        "id": "pnpf10hFXpyb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_text = ['купить срочно дешево', 'качество супер']\n",
        "new_vec = vectorizer.transform(new_text)\n",
        "new_predictions = model.predict(new_vec)\n",
        "print(f'Предсказания: {new_predictions}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ddfed7b-9164-4c0c-c779-06cbe803bfd2",
        "id": "qxHmWt2JXpyc"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Предсказания: ['спам' 'не спам']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **Принятие решений**:\n",
        "\n",
        "Например, если мы получили предсказание 'спам', мы можем автоматически перемещать сообщение в папку со спамом:\n"
      ],
      "metadata": {
        "id": "a18cYnlrXpyd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for pred in new_predictions:\n",
        "    if pred == 'спам':\n",
        "        print('Сообщение перемещено в папку со спамом')\n",
        "    else:\n",
        "        print('Сообщение добавлено в inbox')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1adbce51-3d9f-44c7-fca6-a0249293528c",
        "id": "_p8XtoLLXpye"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Сообщение перемещено в папку со спамом\n",
            "Сообщение добавлено в inbox\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Визуализация важности признаков:**"
      ],
      "metadata": {
        "id": "VHYfV7Egdzm4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Получение важности признаков из модели\n",
        "importances = model.feature_importances_\n",
        "\n",
        "# Получение списка слов (признаков)\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "# Создание DataFrame для удобства сортировки\n",
        "feature_importances_df = pd.DataFrame({'feature': feature_names, 'importance': importances})\n",
        "feature_importances_df = feature_importances_df.sort_values(by='importance', ascending=False).reset_index(drop=True)\n",
        "\n",
        "# Визуализация важности признаков\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(feature_importances_df['feature'][:10], feature_importances_df['importance'][:10], align='center')\n",
        "plt.xlabel('Важность признака')\n",
        "plt.title('Топ-10 важных признаков для классификации текста')\n",
        "plt.gca().invert_yaxis()  # чтобы наиболее важные признаки были сверху\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "jK-CIu7Fdu1T",
        "outputId": "c7dbdb67-7528-4e91-f2ee-94f69d779ae0"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydotplus graphviz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hhHAEYJeZCZ",
        "outputId": "7373f904-5667-4211-a075-b7b9887464c0"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydotplus in /usr/local/lib/python3.10/dist-packages (2.0.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (0.20.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from pydotplus) (3.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import export_graphviz\n",
        "from six import StringIO\n",
        "from IPython.display import Image\n",
        "import pydotplus\n",
        "\n",
        "estimator = model.estimators_[0]\n",
        "\n",
        "dot_data = StringIO()\n",
        "export_graphviz(estimator, out_file=dot_data,\n",
        "                filled=True, rounded=True,\n",
        "                special_characters=True, feature_names=vectorizer.get_feature_names_out())\n",
        "\n",
        "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
        "Image(graph.create_png())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "id": "kLi3bP5uebU3",
        "outputId": "4aa4852b-a96f-4e29-eead-ee0e81cc38c4"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Вопросы для закрепления темы"
      ],
      "metadata": {
        "id": "Y9-APzNEhd2V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Что такое токенизация текста и для чего она необходима?\n",
        "2. Объясните, почему приведение текста к нижнему регистру может улучшить точность классификации.\n",
        "3. Как удаление стоп-слов влияет на качество классификации текстов?\n",
        "4. В чем заключается различие между лемматизацией и стеммингом при обработке текста?\n",
        "5. Поясните, как работает модель \"мешок слов\" (Bag of Words) для представления текстовых данных.\n",
        "6. Опишите идею TF-IDF и объясните, чем она отличается от Bag of Words.\n",
        "7. Как устроен Наивный Байесовский классификатор и какие его преимущества для классификации текстов?\n",
        "8. Расскажите о логистической регрессии и ее применении для многоклассовой классификации текстов.\n",
        "9. Объясните, как работает метод опорных векторов (SVM) для классификации текстовых данных.\n",
        "10. Как алгоритм k-ближайших соседей (KNN) может быть использован для классификации текстов?\n",
        "11. Перечислите преимущества и недостатки моделей на основе решающих деревьев для задач классификации текстов.\n",
        "12. Расскажите об ансамблевом методе случайного леса и его применении для классификации текстов.\n",
        "13. Как можно создать конвейер предварительной обработки и классификации текстов с помощью различных комбинаций методов?\n",
        "14. Объясните, почему размер обучающей выборки влияет на точность классификации текстов.\n",
        "15. Почему кросс-валидация важна для оценки качества моделей классификации текстов?\n",
        "16. Как можно классифицировать новостные статьи по категориям с использованием методов машинного обучения?\n",
        "17. Объясните, как определить тональность (положительную или отрицательную) отзывов с помощью классификации текстов.\n",
        "18. Как можно автоматически категоризировать электронные письма (личные, рабочие, спам и т.д.)?\n",
        "19. Какие особенности необходимо учитывать при классификации твитов по темам (политика, спорт, развлечения и т.д.)?\n",
        "20. Как можно реализовать алгоритм классификации текстов, способный работать с многоязычными данными?\n",
        "21. Как проанализировать ошибки классификации текстов и предложить способы их улучшения?\n",
        "22. Опишите, как можно автоматически назначать теги к техническим документам на основе их содержания.\n",
        "23. Расскажите о подходах к определению авторства текстов с использованием методов классификации.\n",
        "24. Как реализовать модель глубокого обучения, например, сверточную нейронную сеть (CNN), для классификации текстов?\n",
        "25. Как можно классифицировать медицинские записи по различным типам заболеваний?\n",
        "26. Какие методы можно использовать для определения жанра художественных произведений на основе их текстов?\n",
        "27. Как можно классифицировать тексты по авторскому стилю?\n",
        "28. Объясните, как можно определить возрастную категорию автора текста на основе его языковых особенностей.\n",
        "29. Как можно классифицировать юридические документы (законы, контракты, судебные решения и т.д.) по различным категориям?\n",
        "30. Как можно определять уровень сложности текста (детский, подростковый, взрослый) на основе его лексики и синтаксиса?\n"
      ],
      "metadata": {
        "id": "w_vkEIzfhvYC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задачи для самостоятелльной работы"
      ],
      "metadata": {
        "id": "gdn2ODAJhInW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. Проведите предварительную обработку текста (токенизация, приведение к нижнему регистру, удаление стоп-слов, лемматизация) на произвольном наборе текстовых данных.\n",
        "\n",
        "2. Реализуйте модель \"мешок слов\" (Bag of Words) для представления текстовых данных. Объясните, как работает данный подход.\n",
        "\n",
        "3. Реализуйте TF-IDF для представления текстовых данных. Сравните результаты с моделью \"мешок слов\".\n",
        "\n",
        "4. Разработайте Наивный Байесовский классификатор для бинарной классификации текстов (например, \"спам\" или \"не спам\"). Оцените качество модели на тестовых данных.\n",
        "\n",
        "5. Реализуйте логистическую регрессию для многоклассовой классификации текстов. Протестируйте модель на реальном наборе данных.\n",
        "\n",
        "6. Постройте модель на основе метода опорных векторов (SVM) для классификации текстов. Сравните результаты с другими алгоритмами.\n",
        "\n",
        "7. Разработайте алгоритм k-ближайших соседей (KNN) для классификации текстов. Исследуйте влияние параметра k на качество модели.\n",
        "\n",
        "8. Создайте модель на основе решающих деревьев для классификации текстовых данных. Объясните преимущества и недостатки этого подхода.\n",
        "\n",
        "9. Реализуйте ансамблевый метод случайного леса для классификации текстов. Сравните его производительность с другими алгоритмами.\n",
        "\n",
        "10. Разработайте конвейер предварительной обработки и классификации текстов, использующий различные комбинации методов (например, TF-IDF + SVM).\n",
        "\n",
        "11. Проведите исследование, как размер обучающей выборки влияет на точность классификации текстов различными алгоритмами.\n",
        "\n",
        "12. Реализуйте кросс-валидацию для оценки качества классификации текстов. Объясните важность этого подхода.\n",
        "\n",
        "13. Разработайте систему для классификации новостных статей по заданным категориям. Протестируйте различные алгоритмы.\n",
        "\n",
        "14. Создайте модель для определения тональности отзывов (положительный/отрицательный) с использованием методов классификации текстов.\n",
        "\n",
        "15. Постройте систему для автоматической категоризации электронных писем (личные, рабочие, спам и т.д.).\n",
        "\n",
        "16. Разработайте инструмент для классификации твитов на основе их текста (политика, спорт, развлечения и т.д.).\n",
        "\n",
        "17. Реализуйте алгоритм классификации текстов, способный работать с многоязычными данными. Исследуйте влияние языка на качество модели.\n",
        "\n",
        "18. Проведите анализ ошибок классификации текстов, выявите наиболее сложные случаи и предложите способы их улучшения.\n",
        "\n",
        "19. Разработайте систему для автоматического назначения тегов к техническим документам на основе их содержания.\n",
        "\n",
        "20. Реализуйте модель для определения авторства текстов с использованием методов классификации. Оцените применимость модели к различным стилям письма.\n",
        "\n",
        "21. Реализуйте модель глубокого обучения, например, сверточную нейронную сеть (CNN), для классификации текстов. Сравните ее производительность с традиционными методами машинного обучения.\n",
        "\n",
        "22. Разработайте систему для автоматической классификации медицинских записей по различным типам заболеваний.\n",
        "\n",
        "23. Постройте модель для определения жанра художественных произведений на основе их текстов (роман, рассказ, поэзия и т.д.).\n",
        "\n",
        "24. Реализуйте алгоритм, который может классифицировать текст по авторскому стилю. Протестируйте его на произведениях различных писателей.\n",
        "\n",
        "25. Разработайте модель для определения возрастной категории автора текста (молодой, средний возраст, пожилой) на основе его языковых особенностей.\n",
        "\n",
        "26. Постройте систему для классификации юридических документов (законы, контракты, судебные решения и т.д.) по различным категориям.\n",
        "\n",
        "27. Реализуйте модель, которая может определять уровень сложности текста (детский, подростковый, взрослый) на основе его лексики и синтаксиса.\n",
        "\n",
        "28. Разработайте алгоритм, который может классифицировать текстовые диалоги по типу отношений между собеседниками (дружеские, деловые, конфликтные и т.д.).\n",
        "\n",
        "29. Постройте систему для автоматической категоризации художественных произведений по жанрам (фантастика, детектив, драма и т.д.) на основе их текстового содержания.\n",
        "\n",
        "30. Реализуйте модель, которая может определять эмоциональную окраску текста (радость, грусть, гнев, страх и т.д.) и использовать ее для классификации.\n",
        "\n"
      ],
      "metadata": {
        "id": "pdVvU8U-hM_q"
      }
    }
  ]
}