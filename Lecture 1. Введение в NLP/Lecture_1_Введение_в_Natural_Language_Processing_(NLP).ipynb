{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMa48hmvRbDYCaITb2U/D19",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CodeHunterOfficial/NLP-2024-2025/blob/main/Lecture_1_%D0%92%D0%B2%D0%B5%D0%B4%D0%B5%D0%BD%D0%B8%D0%B5_%D0%B2_Natural_Language_Processing_(NLP).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Lecture 1.  Введение в Natural Language Processing (NLP)\n",
        "\n",
        "#### Определение NLP и его применения\n",
        "\n",
        "Natural Language Processing (NLP), или обработка естественного языка, представляет собой область компьютерных наук, искусственного интеллекта и лингвистики, занимающуюся взаимодействием между компьютерами и человеческим языком. Основная цель NLP заключается в создании систем, которые способны понимать, интерпретировать и генерировать естественный язык, делая его доступным для автоматической обработки компьютерами.\n",
        "\n",
        "Применения NLP охватывают широкий спектр задач и областей, таких как:\n",
        "- **Автоматическая обработка текстов**: извлечение информации, анализ тональности, категоризация текстов и т.д.\n",
        "- **Машинный перевод**: автоматическое переведение текстов с одного языка на другой.\n",
        "- **Распознавание и синтез речи**: распознавание речи человека компьютером и синтез речи компьютером.\n",
        "- **Вопросно-ответные системы**: системы, отвечающие на вопросы пользователя на естественном языке.\n",
        "- **Диалоговые системы**: создание чат-ботов и виртуальных помощников, способных вести диалог с пользователями.\n",
        "- **Извлечение информации и Named Entity Recognition (NER)**: извлечение и классификация именованных сущностей (имен, организаций, дат и т.д.) из текста.\n",
        "- **Анализ тональности**: определение эмоциональной окраски текста (положительная, отрицательная или нейтральная).\n",
        "\n",
        "#### Исторический обзор развития NLP\n",
        "\n",
        "История NLP насчитывает более полувека и связана с постоянным развитием компьютерных технологий и методов обработки естественного языка. Вот ключевые моменты её развития:\n",
        "\n",
        "1. **1950-е годы**: Зарождение идеи создания программ, способных обрабатывать естественный язык. Проекты, такие как **Georgetown-IBM эксперимент** в 1954 году, ставят начало исследованиям в этой области.\n",
        "\n",
        "2. **1960-е годы**: Появление первых систем, таких как **ELIZA** (1966), которая представляла собой чат-бота, способного имитировать непродолжительные разговоры на естественном языке.\n",
        "\n",
        "3. **1970-е - 1980-е годы**: Развитие более сложных систем обработки текста и синтаксического анализа. В 1971 году **SHRDLU** (программа для обработки естественного языка) демонстрирует возможности семантического анализа.\n",
        "\n",
        "4. **1990-е годы**: Появление статистических методов и машинного обучения в NLP. Возрождение интереса к проблемам машинного перевода и распознавания речи.\n",
        "\n",
        "5. **2000-е годы и позднее**: Эпоха глубокого обучения (deep learning). Революционизация NLP благодаря использованию нейронных сетей, что привело к значительному улучшению результатов в задачах перевода, генерации текста и диалоговых системах.\n",
        "\n",
        "#### Основные компоненты систем NLP\n",
        "\n",
        "Системы обработки естественного языка обычно включают следующие ключевые компоненты:\n",
        "\n",
        "1. **Токенизация (Tokenization)**: Процесс разделения текста на отдельные слова или токены.\n",
        "\n",
        "2. **Частеречная разметка (Part-of-Speech Tagging)**: Определение части речи для каждого слова в тексте (существительное, глагол, прилагательное и т.д.).\n",
        "\n",
        "3. **Синтаксический анализ (Parsing)**: Анализ структуры предложений, построение дерева зависимостей или синтаксического дерева.\n",
        "\n",
        "4. **Семантический анализ (Semantic Parsing)**: Понимание смысла предложений и текста в целом.\n",
        "\n",
        "5. **Извлечение информации (Information Extraction)**: Извлечение структурированной информации из неструктурированных текстов.\n",
        "\n",
        "6. **Машинное обучение и глубокое обучение (Machine Learning and Deep Learning)**: Применение методов машинного обучения для решения задач NLP, включая классификацию, кластеризацию, генерацию текста и др.\n",
        "\n",
        "7. **Основные приложения NLP (NLP Applications)**: Включают в себя машинный перевод, распознавание и синтез речи, вопросно-ответные системы, чат-боты, анализ тональности и другие.\n",
        "\n",
        "Компоненты NLP работают совместно для создания комплексных систем, способных выполнять различные задачи обработки и анализа естественного языка, делая NLP одной из наиболее динамично развивающихся областей в современных информационных технологиях.\n"
      ],
      "metadata": {
        "id": "bVI3LzGK0NQT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обработка естественного языка (NLP) представляет собой сложную задачу по нескольким причинам, включая:\n",
        "\n",
        "1. **Неоднозначность и многообразие языка**: Естественный язык часто неоднозначен и многообразен. Один и тот же словоформа может иметь разные значения в зависимости от контекста. Например, слово \"банка\" может означать контейнер для хранения или банковское учреждение. Понимание контекста и семантики требует глубокого анализа.\n",
        "\n",
        "2. **Разнообразие грамматических конструкций**: Естественные языки имеют разнообразные грамматические правила и конструкции, которые не всегда легко формализовать для компьютерной обработки. Например, существует множество способов выражения одного и того же смысла с использованием различных грамматических форм и структур.\n",
        "\n",
        "3. **Проблемы синтаксического и семантического анализа**: Понимание структуры предложений и их семантического содержания является сложной задачей. Даже для человека иногда непросто точно определить, что именно имеет в виду автор текста.\n",
        "\n",
        "4. **Сложности в распознавании и синтезе речи**: Обработка речи в реальном времени или распознавание речи с высокой точностью требует учета различных акцентов, интонаций, а также фоновых шумов.\n",
        "\n",
        "5. **Ограниченность данных и ресурсов**: Для обучения систем NLP требуется большое количество размеченных данных, что может быть сложно в силу ограниченного доступа к таким данным или их дороговизны.\n",
        "\n",
        "6. **Непредсказуемость человеческого языка**: Человеческий язык может быть неоднозначным и непредсказуемым в своем использовании. Это создает вызовы для систем NLP, которые должны быть гибкими и адаптивными к разнообразию языковых выражений.\n",
        "\n",
        "7. **Требования к вычислительным ресурсам**: Некоторые современные методы NLP, такие как модели глубокого обучения, требуют значительных вычислительных ресурсов для обучения и инференса.\n",
        "\n",
        "Все эти аспекты делают NLP сложной областью исследования и разработки, требующей комбинации лингвистических знаний, компьютерных наук и статистического анализа для достижения высокого качества обработки и понимания естественного языка компьютерами."
      ],
      "metadata": {
        "id": "suaupJYC0jBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Современное развитие обработки естественного языка (NLP)\n",
        "Современное развитие обработки естественного языка (NLP) представляет собой захватывающую и динамично развивающуюся область в сфере искусственного интеллекта и компьютерных наук. В последние годы NLP переживает настоящую революцию благодаря применению глубокого обучения, развитию больших данных и новым подходам к обработке текстов.\n",
        "\n",
        "### Ключевые направления современного развития NLP:\n",
        "\n",
        "1. **Модели глубокого обучения**:\n",
        "   - **Трансформеры**: Внедрение моделей, таких как BERT (Bidirectional Encoder Representations from Transformers), GPT (Generative Pre-trained Transformer), и их различные вариации (например, GPT-2, GPT-3), которые демонстрируют выдающиеся результаты в задачах машинного перевода, генерации текста, вопросно-ответных системах и других приложениях NLP.\n",
        "   - **BERT** особенно значим для представления контекста и семантического понимания текста, благодаря использованию маскированного языкового моделирования.\n",
        "\n",
        "2. **Продвинутые методы обработки текстов**:\n",
        "   - **Автоматическое извлечение информации**: Улучшение точности и эффективности извлечения структурированной информации из текстовых данных.\n",
        "   - **Извлечение именованных сущностей (NER)**: Развитие методов для точного распознавания и классификации именованных сущностей, таких как имена людей, организаций и мест.\n",
        "\n",
        "3. **Машинный перевод и мультиязычность**:\n",
        "   - **Системы машинного перевода**: Появление моделей, способных работать с несколькими языками и адаптироваться к специфическим лингвистическим особенностям.\n",
        "   - **Кросс-языковые исследования**: Исследования в области переноса обучения и мультиязычности, которые позволяют сократить объем данных для обучения и улучшить качество перевода.\n",
        "\n",
        "4. **Генерация текста и диалоговые системы**:\n",
        "   - **Модели генерации текста**: Продвинутые генеративные модели, такие как GPT, способные автоматически создавать тексты высокого качества, основываясь на обучающих данных.\n",
        "   - **Диалоговые системы**: Развитие чат-ботов и виртуальных помощников, обладающих способностью поддерживать естественный и информативный диалог с пользователями.\n",
        "\n",
        "5. **Этические и социальные вопросы**:\n",
        "   - **Проблемы прозрачности и объяснимости моделей**: Важность разработки методов, позволяющих понять, почему модели принимают определенные решения и как они приходят к своим выводам.\n",
        "   - **Проблемы безопасности и конфиденциальности данных**: Защита данных пользователя и предотвращение их злоупотребления в контексте NLP-систем.\n",
        "\n",
        "Стоить, отметить, что современное развитие NLP открывает перед нами множество возможностей и вызовов. Применение глубокого обучения и передовых методов анализа текста позволяет создавать все более умные и адаптивные системы, способные обрабатывать и понимать естественный язык с высокой точностью. Вместе с тем, важно учитывать этические и социальные аспекты, чтобы обеспечить безопасность, прозрачность и справедливость в использовании NLP-технологий в нашем обществе."
      ],
      "metadata": {
        "id": "hFUAOdFM0j0e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Библиотеки Python для анализа естественного языка\n",
        "\n",
        "Работа в области обработки естественного языка (NLP) в значительной степени зависит от использования специализированных библиотек и фреймворков, которые предоставляют готовые инструменты и алгоритмы для анализа текстовых данных. Вот несколько ключевых библиотек и фреймворков, которые широко используются в современных исследованиях и разработках в области NLP:\n",
        "\n",
        "### 1. NLTK (Natural Language Toolkit)\n",
        "\n",
        "**NLTK** является одним из наиболее популярных и универсальных инструментов для обработки естественного языка на языке Python. Он предоставляет широкий спектр функций для работы с текстом, включая токенизацию, частеречную разметку, синтаксический анализ, семантический анализ, а также возможности для машинного обучения и классификации текстовых данных. NLTK также включает в себя коллекцию корпусов текстов и лексических ресурсов, что делает его мощным инструментом как для учебных, так и для научных целей.\n",
        "\n",
        "### 2. SpaCy\n",
        "\n",
        "**SpaCy** — это ещё одна популярная библиотека для обработки естественного языка на Python. SpaCy предлагает оптимизированные для производительности алгоритмы для токенизации, частеречной разметки, именованных сущностей (NER), синтаксического анализа и векторизации текста. Одним из преимуществ SpaCy является высокая скорость обработки текстовых данных и возможность интеграции с готовыми моделями для различных языков.\n",
        "\n",
        "### 3. Transformers (Hugging Face)\n",
        "\n",
        "**Transformers**, разработанные командой Hugging Face, представляют собой библиотеку, сфокусированную на современных моделях глубокого обучения для обработки естественного языка. Она включает в себя реализации популярных архитектур, таких как BERT, GPT и других трансформерных моделей. Transformers предоставляет удобный интерфейс для использования предобученных моделей, а также возможности для дообучения на специфических данных и задачах NLP.\n",
        "\n",
        "### 4. Gensim\n",
        "\n",
        "**Gensim** — это библиотека для тематического моделирования текстов и векторного представления слов на Python. Она предоставляет инструменты для создания векторных моделей слов (Word2Vec, FastText), а также для построения и использования тематических моделей, таких как Latent Dirichlet Allocation (LDA).\n",
        "\n",
        "### 5. AllenNLP\n",
        "\n",
        "**AllenNLP** — это библиотека, разработанная на языке Python с использованием фреймворка PyTorch, которая предоставляет инструменты для разработки и оценки глубоких моделей для задач обработки естественного языка. AllenNLP уделяет особое внимание архитектуре моделей, исследованию и интерпретации результатов, что делает её популярным выбором среди исследователей и разработчиков NLP.\n",
        "\n",
        "### 6. TensorFlow и PyTorch\n",
        "\n",
        "**TensorFlow** и **PyTorch** — это два ведущих фреймворка глубокого обучения, которые также широко используются для разработки моделей NLP. Оба фреймворка предоставляют богатый набор инструментов для работы с текстовыми данными, включая реализации трансформерных архитектур, LSTM, CNN и других моделей. Они также поддерживают возможности для распределенного обучения и использования графических процессоров для ускорения вычислений.\n",
        "\n",
        "\n",
        "В последок можно сказать, что библиотеки и фреймворки для работы с NLP представляют собой мощные инструменты, которые значительно упрощают разработку и исследование в области обработки естественного языка. Выбор конкретной библиотеки зависит от задачи, уровня опыта и предпочтений разработчика, но каждая из перечисленных выше библиотек обеспечивает широкие возможности для работы с текстовыми данными и применения современных методов NLP."
      ],
      "metadata": {
        "id": "v0WehK_11bPl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Корпуса и датасеты для практической работы в NLP\n",
        "\n",
        "#### Введение в корпуса и датасеты в обработке естественного языка (NLP)\n",
        "\n",
        "Обработка естественного языка (Natural Language Processing, NLP) основывается на использовании разнообразных корпусов и датасетов для обучения и оценки моделей. В данной лекции мы рассмотрим, что такое корпуса и датасеты, и как они используются в практических задачах NLP.\n",
        "\n",
        "####  Корпуса в NLP\n",
        "\n",
        "**Что такое корпус в NLP?**\n",
        "\n",
        "Корпус (Corpus) — это большой набор текстов, собранных для анализа и исследования на естественных языках. Корпусы используются для обучения моделей, оценки языковых явлений и разработки новых методов в NLP.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#### Корпуса\n",
        "\n",
        "**1. Английский язык**\n",
        "\n",
        "- **Brown Corpus**: Один из первых корпусов английского языка, разделённый на категории по темам, таким как новости, научные статьи и т.д.\n",
        "  - [Информация о Brown Corpus](https://en.wikipedia.org/wiki/Brown_Corpus)\n",
        "\n",
        "- **Reuters Corpus**: Корпус новостных статей, используемый для задач классификации текстов.\n",
        "  - [Информация о Reuters Corpus](https://tac.nist.gov/data/reuters/reuters.html)\n",
        "\n",
        "- **Wikipedia Corpus**: Корпус текстов, извлечённых из статей Википедии, широко используемый для различных задач NLP.\n",
        "  - [Информация о Wikipedia Corpus](https://dumps.wikimedia.org/)\n",
        "\n",
        "**2. Русский язык**\n",
        "\n",
        "- **Russian National Corpus (RNC)**: Крупнейший корпус русского языка, содержащий тексты различных жанров и стилей.\n",
        "  - [Информация о Russian National Corpus](http://ruscorpora.ru/)\n",
        "\n",
        "- **SynTagRus**: Корпус аннотированных синтаксических деревьев для русского языка.\n",
        "  - [Информация о SynTagRus](https://universaldependencies.org/treebanks/ru_syntagrus/index.html)\n",
        "\n",
        "- **Taiga Corpus**: Открытый корпус текстов на русском языке из интернета, включая новости, блоги, социальные сети и др.\n",
        "  - [Информация о Taiga Corpus](https://tatianashavrina.github.io/taiga_site/)\n",
        "\n",
        "**3. Татарский язык**\n",
        "\n",
        "- **Tatar National Corpus (TNC)**: Одно из основных корпусов татарского языка, содержащее разнообразные тексты.\n",
        "  - [Информация о Tatar National Corpus](http://www.tatar-corpus.ru/)\n",
        "\n",
        "- **Tatar Text Corpus**: Открытый корпус текстов на татарском языке, собранный из различных источников.\n",
        "  - [Информация о Tatar Text Corpus](https://tat-corpus.ru/)\n",
        "\n",
        "#### Датасеты\n",
        "\n",
        "\n",
        "**Что такое датасет в NLP?**\n",
        "\n",
        "Датасет (Dataset) — это конкретный набор данных, который используется для обучения и тестирования моделей в области NLP. Датасеты часто содержат размеченные примеры для различных задач, таких как классификация текстов, машинный перевод, вопросно-ответные системы и другие.\n",
        "\n",
        "\n",
        "**1. Английский язык**\n",
        "\n",
        "- **IMDb Movie Reviews**: Датасет отзывов о фильмах с разметкой на позитивные и негативные отзывы.\n",
        "  - [IMDb Movie Reviews Dataset](https://ai.stanford.edu/~amaas/data/sentiment/)\n",
        "\n",
        "- **SNLI Dataset**: Датасет для задачи распознавания семантической схожести предложений на английском языке.\n",
        "  - [SNLI Dataset](https://nlp.stanford.edu/projects/snli/)\n",
        "\n",
        "**2. Русский язык**\n",
        "\n",
        "- **RuSentiment**: Датасет для задачи анализа тональности текстов на русском языке.\n",
        "  - [RuSentiment Dataset](https://www.kaggle.com/c/sentiment-analysis-of-russian-twitter/data)\n",
        "\n",
        "- **Russian Language Models Corpus (RuLMC)**: Датасет для оценки языковых моделей на русском языке.\n",
        "  - [Информация о RuLMC](http://rulmccorpora.uni-stuttgart.de/)\n",
        "\n",
        "**3. Татарский язык**\n",
        "\n",
        "- **Tatar Paraphrase Corpus**: Корпус перефразировок на татарском языке, используемый для задач генерации и анализа текстов.\n",
        "  - [Информация о Tatar Paraphrase Corpus](https://tat-corpus.ru/tatar-paraphrase-corpus)\n",
        "\n",
        "- **Tatar Poetry Corpus**: Корпус поэзии на татарском языке, включающий стихотворения различных авторов.\n",
        "  - [Информация о Tatar Poetry Corpus](https://tat-corpus.ru/tatar-poetry-corpus)\n",
        "\n",
        "#### Применение корпусов и датасетов в практических задачах NLP\n",
        "\n",
        "**Использование корпусов**\n",
        "\n",
        "- **Лингвистические исследования**: анализ частотности слов, изучение языковых явлений.\n",
        "- **Тематическое моделирование**: выявление основных тем в текстах.\n",
        "\n",
        "**Применение датасетов**\n",
        "\n",
        "- **Обучение моделей машинного обучения**: разработка и оценка моделей для различных задач NLP.\n",
        "- **Оценка качества моделей**: использование размеченных данных для оценки точности и полноты моделей.\n",
        "\n",
        "#### Заключение\n",
        "\n",
        "Корпуса и датасеты играют ключевую роль в развитии и исследованиях в области NLP, предоставляя необходимые данные для обучения и оценки моделей. Понимание доступных ресурсов и их применение является важным аспектом успешной работы с естественными языками.\n",
        "\n",
        "#### Ресурсы и ссылки для дополнительного чтения\n",
        "\n",
        "- [NLTK Datasets](https://www.nltk.org/nltk_data/)\n",
        "- [Kaggle Datasets](https://www.kaggle.com/datasets)\n",
        "- [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php)\n",
        "\n",
        "Эти ресурсы предлагают широкий выбор корпусов и датасетов для различных задач в NLP, от классических лингвистических исследований до современных задач машинного обучения."
      ],
      "metadata": {
        "id": "VB4NqNWu8sEi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Виды анализа текста в NLP\n",
        "\n",
        "\n",
        "#### 1. Морфологический анализ\n",
        "Морфологический анализ включает разбор слов на морфемы, их грамматические характеристики (часть речи, число, падеж и т.д.). Это начальный этап обработки текста, который позволяет понять структуру слов.\n",
        "\n",
        "**Примеры:**\n",
        "- Лемматизация: Приведение слова к его базовой форме (лемме). Например, слова \"running\" и \"ran\" будут приведены к \"run\".\n",
        "- Стемминг: Усечение слова до его корневой формы. Например, слова \"fishing\" и \"fished\" могут быть усечены до \"fish\".\n",
        "\n",
        "**Инструменты:**\n",
        "- NLTK (Natural Language Toolkit)\n",
        "- SpaCy\n",
        "\n",
        "#### 2. Синтаксический анализ\n",
        "Синтаксический анализ (парсинг) направлен на изучение структуры предложения и выявление отношений между словами.\n",
        "\n",
        "**Примеры:**\n",
        "- Синтаксические деревья (parse trees), которые показывают иерархические отношения между словами в предложении.\n",
        "- Чанкеры (chunkers) для выделения фраз (например, именных или глагольных).\n",
        "\n",
        "**Инструменты:**\n",
        "- Stanford Parser\n",
        "- SpaCy\n",
        "\n",
        "#### 3. Семантический анализ\n",
        "Семантический анализ нацелен на понимание значений слов и предложений, а также на выявление смысловых отношений между ними.\n",
        "\n",
        "**Примеры:**\n",
        "- Распознавание именованных сущностей (Named Entity Recognition, NER): Определение имен собственных, таких как имена людей, организации, географические названия и т.д.\n",
        "- Разрешение анафор (coreference resolution): Определение, к каким объектам относятся местоимения в тексте.\n",
        "\n",
        "**Инструменты:**\n",
        "- SpaCy\n",
        "- Stanford NER\n",
        "\n",
        "#### 4. Прагматический анализ\n",
        "Прагматический анализ изучает контекст использования языка, включая намерения говорящего и влияние внешних факторов на интерпретацию текста.\n",
        "\n",
        "**Примеры:**\n",
        "- Анализ тональности (sentiment analysis): Определение эмоциональной окраски текста (позитивная, негативная, нейтральная).\n",
        "- Анализ дискурса: Изучение структуры и логики текста, понимание связей между предложениями и частями текста.\n",
        "\n",
        "**Инструменты:**\n",
        "- TextBlob\n",
        "- VADER (Valence Aware Dictionary and sEntiment Reasoner)\n",
        "\n",
        "#### 5. Тематическое моделирование\n",
        "Тематическое моделирование используется для выявления скрытых тем в коллекции документов.\n",
        "\n",
        "**Примеры:**\n",
        "- LDA (Latent Dirichlet Allocation): Модель, которая идентифицирует темы в тексте и распределяет слова по этим темам.\n",
        "- NMF (Non-negative Matrix Factorization): Альтернативный метод тематического моделирования.\n",
        "\n",
        "**Инструменты:**\n",
        "- Gensim\n",
        "- Scikit-learn\n",
        "\n",
        "#### 6. Анализ стилистики\n",
        "Анализ стилистики фокусируется на определении стиля текста, что может включать в себя анализ метрик, таких как частота использования определенных грамматических конструкций или слов.\n",
        "\n",
        "**Примеры:**\n",
        "- Определение авторства: Использование лингвистических признаков для определения автора текста.\n",
        "- Анализ художественного стиля: Изучение особенностей языка в литературных произведениях.\n",
        "\n",
        "**Инструменты:**\n",
        "- Stylo package (для R)\n",
        "- Lingua::EN::Fathom (для Perl)\n",
        "\n",
        "#### 7. Извлечение информации\n",
        "Извлечение информации направлено на получение структурированной информации из неструктурированного текста.\n",
        "\n",
        "**Примеры:**\n",
        "- Извлечение фактов: Определение конкретных данных, таких как даты, суммы денег, имена и т.д.\n",
        "- Заполнение шаблонов: Автоматическое извлечение информации для заполнения баз данных.\n",
        "\n",
        "**Инструменты:**\n",
        "- OpenIE (Open Information Extraction)\n",
        "- SpaCy\n",
        "\n",
        "#### Заключение\n",
        "Анализ текста в NLP охватывает широкий спектр методов и подходов, каждый из которых направлен на решение конкретных задач. В зависимости от поставленной задачи и типа текста, могут быть применены различные виды анализа, начиная от морфологического и синтаксического, заканчивая прагматическим анализом и тематическим моделированием. Для успешной реализации этих методов существуют разнообразные инструменты и библиотеки, облегчающие работу исследователей и разработчиков."
      ],
      "metadata": {
        "id": "fYaHZN03EncP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Регулярные выражения (Regular Expressions, Regex)\n",
        "\n",
        "Регулярные выражения (Regular Expressions, Regex) представляют собой мощный инструмент в обработке естественного языка (NLP), используемый для поиска и манипуляций с текстом на основе заданных шаблонов. В контексте NLP регулярные выражения играют важную роль в различных задачах обработки и анализа текстовых данных. Вот несколько ключевых областей их применения:\n",
        "\n",
        "### 1. Токенизация текста\n",
        "\n",
        "Регулярные выражения используются для разделения текста на токены (отдельные слова, числа, знаки препинания и т.д.). Например, можно использовать выражение `\\w+` для извлечения всех слов из текста. Это позволяет эффективно проводить первичную обработку текста перед его дальнейшим анализом.\n",
        "\n",
        "### 2. Поиск и извлечение информации\n",
        "\n",
        "С помощью регулярных выражений можно осуществлять поиск и извлечение определенных паттернов или информации из текста. Например, можно найти все даты в тексте, используя соответствующее регулярное выражение для распознавания дат в различных форматах (например, `\\d{1,2}/\\d{1,2}/\\d{4}`).\n",
        "\n",
        "### 3. Удаление шума и нормализация текста\n",
        "\n",
        "Регулярные выражения помогают удалять нежелательные символы, пробелы, специальные символы и другие шумовые элементы из текста, что важно для очистки данных перед анализом. Например, можно удалить все знаки пунктуации с помощью выражения `[^\\w\\s]`.\n",
        "\n",
        "### 4. Поиск и замена\n",
        "\n",
        "Регулярные выражения позволяют осуществлять поиск определенных паттернов в тексте и их замену другими строками. Это полезно для стандартизации текстовых данных или для замены специфических выражений на другие формы. Например, можно заменить все упоминания чисел на специальные токены, чтобы обработать их отдельно.\n",
        "\n",
        "### Примеры использования:\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NkXHrwQW2D7x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Пример 1: Токенизация с использованием регулярных выражений"
      ],
      "metadata": {
        "id": "eF82xHq02lz0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "text = \"Hello, world! This is a sample text.\"\n",
        "tokens = re.findall(r'\\w+', text)\n",
        "print(tokens)\n",
        "# Output: ['Hello', 'world', 'This', 'is', 'a', 'sample', 'text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofC7OHxC2qXY",
        "outputId": "38c65521-21f6-4871-f90f-771e5349440f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', 'world', 'This', 'is', 'a', 'sample', 'text']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "В этом примере re.findall(r'\\w+', text) ищет все последовательности букв и цифр в строке text, формируя список токенов.\n",
        "\n",
        "Пример 2: Извлечение дат из текста"
      ],
      "metadata": {
        "id": "IE5KV0_62wiI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "text = \"The event will take place on 10/25/2024 and 11/05/2024.\"\n",
        "dates = re.findall(r'\\d{1,2}/\\d{1,2}/\\d{4}', text)\n",
        "print(dates)\n",
        "# Output: ['10/25/2024', '11/05/2024']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEchlkU82zVY",
        "outputId": "035feb16-6077-4c4f-e2af-599fc370a87e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['10/25/2024', '11/05/2024']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Объяснение использованных регулярных выражений:\n",
        "\n",
        "- В примере 1 (`r'\\w+'`):\n",
        "  - `\\w` соответствует любой букве (включая заглавные и строчные) или цифре.\n",
        "  - `+` означает, что должно быть одно или более вхождений предыдущего шаблона.\n",
        "\n",
        "- В примере 2 (`r'\\d{1,2}/\\d{1,2}/\\d{4}'`):\n",
        "  - `\\d{1,2}` соответствует одной или двум цифрам.\n",
        "  - `/` соответствует символу `/`.\n",
        "  - `\\d{4}` соответствует четырем цифрам (год в формате YYYY).\n",
        "\n",
        "Эти примеры демонстрируют простое, но мощное использование регулярных выражений для обработки текстовых данных в NLP."
      ],
      "metadata": {
        "id": "obDTwZmZ22D7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Пример 3: Поиск и извлечение информации (найти все email-адреса в тексте)"
      ],
      "metadata": {
        "id": "kyOJjUJM28IL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "text = \"Contact us at email@example.com or support@example.org for more information.\"\n",
        "emails = re.findall(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', text)\n",
        "print(emails)\n",
        "# Output: ['email@example.com', 'support@example.org']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJ9SU6TX3I-k",
        "outputId": "0628429c-9746-4e67-8018-8af08639fd9d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['email@example.com', 'support@example.org']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "В этом примере `re.findall(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', text)` ищет все валидные email-адреса в тексте `text`. Регулярное выражение состоит из нескольких частей:\n",
        "- `\\b[A-Za-z0-9._%+-]+` - начало email адреса, начинающегося с буквы, цифры или символов `_`, `.`, `%`, `+` и `-`.\n",
        "- `@[A-Za-z0-9.-]+` - символ `@`, за которым следуют буквы, цифры, символы `.` и `-`.\n",
        "- `\\.[A-Z|a-z]{2,}\\b` - точка, доменное имя (2 или более символов), завершающаяся на границе слова."
      ],
      "metadata": {
        "id": "KzkrDwuI3inP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Пример 4: Удаление шума и нормализация текста (удалить все знаки пунктуации)"
      ],
      "metadata": {
        "id": "EFwzvWKU3L2f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "text = \"Hello! How are you? I'm doing well, thanks.\"\n",
        "clean_text = re.sub(r'[^\\w\\s]', '', text)\n",
        "print(clean_text)\n",
        "# Output: 'Hello How are you Im doing well thanks'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGmCBrN03O22",
        "outputId": "547a289c-3de0-431a-d6a4-677923a39b04"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello How are you Im doing well thanks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Здесь `re.sub(r'[^\\w\\s]', '', text)` заменяет все знаки пунктуации в строке `text` на пустую строку. Регулярное выражение `[^\\w\\s]` соответствует любым символам, которые не являются буквами, цифрами или пробелами."
      ],
      "metadata": {
        "id": "ZTwy3DMn3oSx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Пример 5: Поиск и замена (заменить все числа на слово \"NUMBER\")"
      ],
      "metadata": {
        "id": "BgsW1BQq3WU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "text = \"There are 10 apples and 20 oranges in the basket.\"\n",
        "normalized_text = re.sub(r'\\d+', 'NUMBER', text)\n",
        "print(normalized_text)\n",
        "# Output: 'There are NUMBER apples and NUMBER oranges in the basket.'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QssdHi6m3Xxu",
        "outputId": "025c254d-8122-484c-e26d-072bf7b1ae88"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are NUMBER apples and NUMBER oranges in the basket.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Здесь `re.sub(r'\\d+', 'NUMBER', text)` заменяет все последовательности цифр в строке `text` на слово \"NUMBER\". Регулярное выражение `\\d+` соответствует одной или более цифрам."
      ],
      "metadata": {
        "id": "XRutcOLV3r5Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Объяснение использованных регулярных выражений:\n",
        "\n",
        "- В примере 2 (`r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'`):\n",
        "  - `\\b` - граница слова.\n",
        "  - `[A-Za-z0-9._%+-]+` - имя пользователя email адреса.\n",
        "  - `@[A-Za-z0-9.-]+` - символ `@` и доменное имя.\n",
        "  - `\\.[A-Z|a-z]{2,}` - доменная часть email адреса (например, `.com`, `.org`).\n",
        "  - `\\b` - граница слова.\n",
        "\n",
        "- В примере 3 (`r'[^\\w\\s]'`):\n",
        "  - `[^\\w\\s]` - любой символ, который не является буквой, цифрой или пробелом.\n",
        "\n",
        "- В примере 4 (`r'\\d+'`):\n",
        "  - `\\d+` - одна или более цифр.\n",
        "\n",
        "Эти примеры демонстрируют, как можно использовать регулярные выражения для эффективной обработки текстовых данных в NLP, включая поиск, извлечение, нормализацию и замену информации в тексте."
      ],
      "metadata": {
        "id": "zCTkOf-p3RAo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Пример 6: Найти все вопросы в тексте"
      ],
      "metadata": {
        "id": "aIh5iHPM6XDD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "text = \"\"\"\n",
        "1. Какие бывают виды обработки естественного языка?\n",
        "2. Как работают рекуррентные нейронные сети в NLP?\n",
        "3. Что такое частеречная разметка?\n",
        "4. Почему важна токенизация текста?\n",
        "\"\"\"\n",
        "\n",
        "questions = re.findall(r'(?<=\\d\\.\\s).*[?]', text)\n",
        "for question in questions:\n",
        "    print(question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7VmflFm6YXs",
        "outputId": "2d27c070-7656-4985-d4d8-5b112482d2ee"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Какие бывают виды обработки естественного языка?\n",
            "Как работают рекуррентные нейронные сети в NLP?\n",
            "Что такое частеречная разметка?\n",
            "Почему важна токенизация текста?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Пример 7: Найти все утверждения в тексте"
      ],
      "metadata": {
        "id": "IdHEvzJz6kep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "text = \"\"\"\n",
        "1. Какие бывают виды обработки естественного языка?\n",
        "2. Рекуррентные нейронные сети применяются для анализа последовательностей.\n",
        "3. Частеречная разметка определяет части речи слов в тексте.\n",
        "4. Токенизация текста делит текст на отдельные слова или токены.\n",
        "\"\"\"\n",
        "\n",
        "statements = re.findall(r'(?<=\\d\\.\\s)[^.?]+', text)\n",
        "for statement in statements:\n",
        "    print(statement.strip())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVcsmqM06luD",
        "outputId": "7659dbf3-a6f0-4146-f1f7-b7b70c915a05"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Какие бывают виды обработки естественного языка\n",
            "Рекуррентные нейронные сети применяются для анализа последовательностей\n",
            "Частеречная разметка определяет части речи слов в тексте\n",
            "Токенизация текста делит текст на отдельные слова или токены\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Регулярные выражения представляют собой мощный инструмент для обработки текстовых данных в NLP, позволяя осуществлять различные операции от токенизации до поиска и замены паттернов. Однако их использование требует хорошего понимания синтаксиса и возможностей, а также учитывает особенности естественного языка, что помогает создавать эффективные и точные системы для работы с текстом."
      ],
      "metadata": {
        "id": "pa9pFWdg2mDG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Вопросы для закрепление темы\n",
        "\n",
        "1. Что такое Natural Language Processing (NLP)?\n",
        "2. Какова основная цель NLP?\n",
        "3. Какие области применения NLP существуют?\n",
        "4. Что такое машинный перевод в контексте NLP?\n",
        "5. Что включает в себя автоматическая обработка текстов?\n",
        "6. Какие задачи решает анализ тональности в NLP?\n",
        "7. Что такое Named Entity Recognition (NER)?\n",
        "8. Какие системы можно отнести к диалоговым системам в NLP?\n",
        "9. Какие основные исторические этапы развития NLP можно выделить?\n",
        "10. Какую роль сыграла система ELIZA в развитии NLP?\n",
        "11. Чем была значима программа SHRDLU в контексте NLP?\n",
        "12. Какие технологии способствовали развитию NLP в 1990-е годы?\n",
        "13. Как глубокое обучение изменило сферу NLP в 2000-х годах?\n",
        "14. Какие ключевые компоненты включают системы NLP?\n",
        "15. Что такое токенизация и как она используется в NLP?\n",
        "16. Зачем нужна частеречная разметка в NLP?\n",
        "17. Какие задачи решает синтаксический анализ в NLP?\n",
        "18. Что включает в себя семантический анализ текста?\n",
        "19. Какие проблемы возникают при обработке естественного языка?\n",
        "20. Какие библиотеки Python широко используются для анализа естественного языка?"
      ],
      "metadata": {
        "id": "HGKl5eQA7Iqs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задачи для самостоятельной работы"
      ],
      "metadata": {
        "id": "7V9qRl4X4Vwl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. **Поиск всех email-адресов в тексте**:\n",
        "   - Напишите программу, которая находит и выводит все email-адреса, содержащиеся в заданном тексте.\n",
        "\n",
        "2. **Извлечение всех URL из веб-страницы**:\n",
        "   - Напишите скрипт для извлечения всех URL из HTML-кода веб-страницы с использованием регулярных выражений.\n",
        "\n",
        "3. **Поиск всех хэштегов в социальных медиа**:\n",
        "   - Напишите программу для извлечения всех хэштегов (начинающихся с символа `#`) из текстов, например, из твитов или постов в Instagram.\n",
        "\n",
        "4. **Извлечение всех чисел из текста**:\n",
        "   - Напишите функцию для извлечения всех чисел (целых и десятичных) из заданного текста с использованием регулярных выражений.\n",
        "\n",
        "5. **Поиск всех дат в тексте**:\n",
        "   - Разработайте программу для нахождения и вывода всех дат в формате DD/MM/YYYY из текста.\n",
        "\n",
        "6. **Извлечение всех временных меток из лог-файла**:\n",
        "   - Напишите скрипт для извлечения всех временных меток (например, формат HH:MM:SS) из лог-файла.\n",
        "\n",
        "7. **Поиск всех номеров телефонов**:\n",
        "   - Создайте программу для извлечения всех номеров телефонов из текста, используя различные форматы (например, (XXX) XXX-XXXX или XXX-XXX-XXXX).\n",
        "\n",
        "8. **Извлечение всех IP-адресов из текста**:\n",
        "   - Напишите скрипт для извлечения всех IP-адресов (IPv4 и IPv6) из текста.\n",
        "\n",
        "9. **Поиск всех идентификаторов пользователя в формате username**:\n",
        "   - Разработайте программу для поиска всех идентификаторов пользователей (например, @username) в тексте.\n",
        "\n",
        "10. **Поиск всех прописных слов (заглавных букв) в предложениях**:\n",
        "    - Напишите функцию для поиска всех слов, написанных заглавными буквами, в предложениях текста.\n",
        "\n",
        "11. **Извлечение всех доменных имен из списка URL**:\n",
        "    - Создайте скрипт для извлечения всех доменных имен (например, example.com) из списка URL.\n",
        "\n",
        "12. **Поиск всех сокращений (акронимов) в тексте**:\n",
        "    - Напишите программу для извлечения всех сокращений (например, U.S.A.) из текста.\n",
        "\n",
        "13. **Поиск всех слов, начинающихся с определенной буквы**:\n",
        "    - Разработайте скрипт для поиска всех слов в тексте, начинающихся с определенной буквы (например, слова на букву \"A\").\n",
        "\n",
        "14. **Извлечение всех адресов на почтовых отделениях из текста**:\n",
        "    - Напишите программу для извлечения всех адресов на почтовых отделениях (например, 12345) из текста.\n",
        "\n",
        "15. **Поиск всех HTML-тегов в веб-странице**:\n",
        "    - Создайте скрипт для извлечения всех HTML-тегов (например, `<div>`, `<a>`) из HTML-кода веб-страницы.\n",
        "\n",
        "16. **Извлечение всех заголовков (заглавных слов) из текста**:\n",
        "    - Напишите функцию для извлечения всех заголовков (слов, написанных заглавными буквами и окруженных пробелами) из текста.\n",
        "\n",
        "17. **Поиск всех буквенных аббревиатур (например, NASA)**:\n",
        "    - Разработайте скрипт для поиска всех буквенных аббревиатур (например, NASA) в тексте.\n",
        "\n",
        "18. **Извлечение всех ISBN-кодов (книжных кодов) из текста**:\n",
        "    - Напишите программу для извлечения всех ISBN-кодов (например, ISBN-13 или ISBN-10) из текста.\n",
        "\n",
        "19. **Поиск всех подстрок в заданном формате (например, AB123)**:\n",
        "    - Создайте скрипт для поиска всех подстрок в заданном формате (например, две буквы и три цифры) в тексте.\n",
        "\n",
        "20. **Извлечение всех слов с определенным окончанием (например, -tion)**:\n",
        "    - Напишите функцию для извлечения всех слов с определенным окончанием (например, -tion) из текста.\n"
      ],
      "metadata": {
        "id": "TxR6q2I44ZgP"
      }
    }
  ]
}